{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question1_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl9KfcjsB09Q",
        "colab_type": "code",
        "outputId": "0f39dc94-f8ea-4e92-e5d6-090a23abc284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Colab has two versions of TensorFlow installed: a 1.x version and a 2.x version. \n",
        "# Colab currently uses TF 1.x by default\n",
        "# To enable TF2 execute the following code\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxTKyjAPy2s4",
        "colab_type": "text"
      },
      "source": [
        "### Importing the necessary Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1I7TLooA7uG",
        "colab_type": "code",
        "outputId": "ed0e5a47-c32c-4162-9c9c-1fb01de260bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Importing the libraries \n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5IC5A4lyaJA",
        "colab_type": "text"
      },
      "source": [
        "### Creation of some useful functions that would be utilized in our TensorFlow Program "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcbRgsUAlNt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------------------------------CODE TO PREPARE THE DATASET---------------------------------------------------- \n",
        "\n",
        "def prepare_dataset(fashion_mnist):\n",
        "  # load the training and test data    \n",
        "  (tr_x, tr_y), (te_x, te_y) = fashion_mnist.load_data()\n",
        "  # reshape the feature data\n",
        "  tr_x = tr_x.reshape(tr_x.shape[0], 784)\n",
        "  te_x = te_x.reshape(te_x.shape[0], 784)\n",
        "  # noramlise feature data\n",
        "  tr_x = tr_x / 255.0\n",
        "  te_x = te_x / 255.0\n",
        "  # one hot encode the training labels and get the transpose\n",
        "  tr_y = np_utils.to_categorical(tr_y,10)\n",
        "  tr_y = tr_y.T\n",
        "  # one hot encode the test labels and get the transpose\n",
        "  te_y = np_utils.to_categorical(te_y,10)\n",
        "  te_y = te_y.T\n",
        "  return tr_x, tr_y, te_x, te_y\n",
        "\n",
        "# -----------------------------------CODE TO CALCULATE THE PROBABILITY OF EACH CLASS GIVEN THE TRAINING INSTANCE--------------------------------------\n",
        "\n",
        "def forward_pass(X_train, weight_matrix, bias_matrix):\n",
        "  \"\"\"\n",
        "  Return the predicted 10 class probabilities matrix for each of the training instances given the training feature matrix and weights matrix \n",
        "  \"\"\"\n",
        "  # Calculate the pre-activation outputs for each of the 10 neurons in the softmax layer for each of the training instance \n",
        "  # Will get 10 outputs for a single training instance in the form of (10*60000) matrix \n",
        "  # The size of the weight matrix is (10*784)\n",
        "  # The size of the training feature matrix is (784*60000)\n",
        "  # The size of the bias matrix is (10*1)\n",
        "  preActivation_output_matrix=  tf.matmul(weight_matrix, X_train) + bias_matrix\n",
        "  # Calculate a new matrix where each element is e to the power of pre-activation outputs \n",
        "  exponential_matrix= tf.math.exp(preActivation_output_matrix)\n",
        "  # Calculation of the final probabilities of each of the 10 classes for each instance in the training set \n",
        "  # Column wise sum calculation \n",
        "  column_sum= tf.reduce_sum(exponential_matrix, 0)\n",
        "  # Divide each element by the column sum so that each column is the probability of each class of a single instance \n",
        "  probability_matrix= exponential_matrix/column_sum \n",
        "  \n",
        "  return probability_matrix\n",
        "\n",
        "# -------------------------------- CODE TO CALCULATE THE LOSS FOR THE CURRENT SET OF TUNABLE PARAMETERS / WEIGHTS-------------------------------------\n",
        "\n",
        "def cross_entropy(y_train, y_pred_matrix):\n",
        "  \"\"\"\n",
        "  Return the loss value given the predicted probabilities matrix and the actual probabilities matrix\n",
        "  \"\"\"\n",
        "  # Compute the log of each element of the prediction matrix \n",
        "  log_matrix= tf.math.log(y_pred_matrix)\n",
        "  # Multiply each element of the actual labels matrix with the log matrix \n",
        "  product_matrix= y_train *log_matrix\n",
        "  # Take the negation of each element in the product matrix \n",
        "  negated_product_matrix= -1*(product_matrix)\n",
        "  # Compute the cross entropy loss for each of the training instances \n",
        "  # This will contain individual loss for the all training instances \n",
        "  # This operation will perform the column wise sum \n",
        "  single_loss_matrix= tf.reduce_sum(negated_product_matrix, 0)\n",
        "  # Compute the mean cross entropy loss \n",
        "  mean_loss= tf.reduce_mean(single_loss_matrix)\n",
        "\n",
        "  return mean_loss\n",
        "\n",
        "# ----------------------------------------- CALCULATION OF THE TRAINING AND TEST SET ACCURACY------------------------------------------------------\n",
        "\n",
        "def return_labels(matrix):\n",
        "  \"\"\"\n",
        "  Return the corrosponding class label for each vector of probability instance \n",
        "  \"\"\" \n",
        "  class_labels= tf.argmax(matrix) \n",
        "  \n",
        "  return class_labels\n",
        "\n",
        "def calculate_accuracy(feature_data, label_data, weight_matrix, bias_matrix):\n",
        "  \"\"\" \n",
        "  Return the accuracy value (applicable for both train and the test set) for the given set of weights and the biases \n",
        "  \"\"\"\n",
        "  # Calculate the matrix of predicted probabilities through calling of forward pass \n",
        "  predicted_matrix= forward_pass(feature_data, weight_matrix, bias_matrix)\n",
        "  # Get the class labels of the actual labels \n",
        "  actual_labels= return_labels(label_data)\n",
        "  # Get the class labels of the predicted probabilities \n",
        "  predicted_labels= return_labels(predicted_matrix)\n",
        "  # Get the correct prediction in the form of boolean array where 1 is correct prediction and 0 is the wrong prediction \n",
        "  correct_predictions= tf.cast(tf.equal(predicted_labels, actual_labels), tf.float32)\n",
        "  # Calculate the accuracy \n",
        "  accuracy= tf.reduce_mean(correct_predictions)\n",
        "\n",
        "  return accuracy \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNiW8V60zO6w",
        "colab_type": "text"
      },
      "source": [
        "### Beginning of our TensorFlow Program "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_fmLOG-mR1o",
        "colab_type": "code",
        "outputId": "cdb87fe3-93d4-46ab-bb5e-71ab6b0c51c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Loading the fashion MNIST data-set \n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Prepare the dataset \n",
        "train_features, train_labels, test_features, test_labels= prepare_dataset(fashion_mnist)\n",
        "\n",
        "# Get the transpose of feature data \n",
        "train_features= train_features.T \n",
        "test_features= test_features.T\n",
        "\n",
        "# Print the shape of our 4 data structures \n",
        "print( \"Shape of training features \", train_features.shape)\n",
        "print (\"Shape of training labels \", train_labels.shape)\n",
        "print()\n",
        "print( \"Shape of test features \", test_features.shape)\n",
        "print (\"Shape of test labels \", test_labels.shape)\n",
        "print()\n",
        "print(\"The training process of our Softmax Neural Network begins.....\")\n",
        "print()\n",
        "\n",
        "X_train= tf.cast(train_features, tf.float32)\n",
        "y_train= tf.cast(train_labels, tf.float32)\n",
        "X_test= tf.cast(test_features, tf.float32)\n",
        "y_test= tf.cast(test_labels, tf.float32)\n",
        "\n",
        "# Set the Number of features\n",
        "num_features=  X_train.shape[0]\n",
        "# We now specify the size of output layer \n",
        "output_neurons= 10 \n",
        "\n",
        "# Initialize the weight_matrix and bias_matrix \n",
        "# Each row of this matrix represents the 784 weights of a single neuron in the softmax layer \n",
        "weight_matrix= tf.Variable(tf.random.normal([output_neurons, num_features], mean=0.0, stddev=0.05))\n",
        "# It is a column vector where each row/element represents the bias value for a single neuron in the softmax layer \n",
        "bias_matrix= tf.Variable(tf.random.normal([output_neurons, 1], mean=0.0, stddev=0.05))\n",
        "\n",
        "# Set the learning rate and the number of iterations \n",
        "learning_rate= 0.01 \n",
        "num_iterations= 6000\n",
        "\n",
        "# Adam optimizer to update the weights of the neural network \n",
        "adam_optimizer= tf.keras.optimizers.Adam()\n",
        "\n",
        "# Create the list to store the training accuracy and loss with each iteration \n",
        "training_loss= []\n",
        "training_acc= []\n",
        "# Create the list to store the test accuracy and loss with each iteration \n",
        "test_loss= []\n",
        "test_acc= []\n",
        "\n",
        "# Run the gradient descent to num_iterations number of times \n",
        "for iteration in range(num_iterations):\n",
        "\n",
        "  # Create an instance of GradientTape to monitor the forward pass and loss calculations\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Calculate the predicted probability matrix for the current weights and the biases for the training set\n",
        "    y_pred_matrix= forward_pass(X_train, weight_matrix, bias_matrix)\n",
        "    # Calculate the predicted probability matrix for the current weights and the biases for the test set\n",
        "    y_pred_test= forward_pass(X_test, weight_matrix, bias_matrix)\n",
        "    # Calculate the current training loss with the current predictions and the actual labels of the training set \n",
        "    current_loss_training= cross_entropy(y_train, y_pred_matrix)\n",
        "    # Calculate the current test loss with the current prediction and the actual labels of the test set \n",
        "    current_loss_test= cross_entropy(y_test, y_pred_test)\n",
        "  \n",
        "  # Calculate the gradients (partial derivates) of the loss with respect to each of the tunable weights \n",
        "  gradients= tape.gradient(current_loss_training, [weight_matrix, bias_matrix])\n",
        "\n",
        "  # Calculate the training accuracy with each iteration \n",
        "  training_accuracy= calculate_accuracy(X_train, y_train, weight_matrix, bias_matrix)\n",
        "\n",
        "  # Calculate the test accuracy with each each iteration \n",
        "  test_accuracy= calculate_accuracy(X_test, y_test, weight_matrix, bias_matrix)\n",
        "\n",
        "  # Print out the current iteration, current loss and current training accuracy \n",
        "  print(\"Iteration \",iteration, \": Loss = \",current_loss_training.numpy(),\" Acc: \", training_accuracy.numpy(),   'Val_loss = ',current_loss_test.numpy(),   'Val_acc = ', test_accuracy.numpy())\n",
        "\n",
        "  # Apply the Adam optimizer to update the weights and biases \n",
        "  adam_optimizer.apply_gradients(zip(gradients, [weight_matrix, bias_matrix]))\n",
        "\n",
        "  # Append the 4 values (train loss, train acc, test loss, test acc) with the each current iteration for the plotting \n",
        "  training_loss.append(current_loss_training.numpy())\n",
        "  training_acc.append(training_accuracy.numpy())\n",
        "  test_loss.append(current_loss_test.numpy())\n",
        "  test_acc.append(test_accuracy.numpy())\n",
        "\n",
        "# Calculate the test accuracy with the final updated weights and the biases through adam optimizer after running for certain number of iterations \n",
        "final_test_accuracy= calculate_accuracy(X_test, y_test, weight_matrix, bias_matrix)\n",
        "\n",
        "# Print the test accuracy \n",
        "print()\n",
        "print(\"The final test accuracy of the Fashion MNIST dataset is {}\".format(final_test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration  1003 : Loss =  0.4264263  Acc:  0.85758334 Val_loss =  0.46910346 Val_acc =  0.8377\n",
            "Iteration  1004 : Loss =  0.42636007  Acc:  0.8576 Val_loss =  0.46905473 Val_acc =  0.8379\n",
            "Iteration  1005 : Loss =  0.4262939  Acc:  0.85763335 Val_loss =  0.46900615 Val_acc =  0.8379\n",
            "Iteration  1006 : Loss =  0.42622787  Acc:  0.85765 Val_loss =  0.4689576 Val_acc =  0.8379\n",
            "Iteration  1007 : Loss =  0.42616192  Acc:  0.8576667 Val_loss =  0.46890917 Val_acc =  0.8379\n",
            "Iteration  1008 : Loss =  0.42609602  Acc:  0.85768336 Val_loss =  0.46886083 Val_acc =  0.8379\n",
            "Iteration  1009 : Loss =  0.42603028  Acc:  0.85768336 Val_loss =  0.46881258 Val_acc =  0.8379\n",
            "Iteration  1010 : Loss =  0.42596465  Acc:  0.8577167 Val_loss =  0.46876445 Val_acc =  0.8379\n",
            "Iteration  1011 : Loss =  0.42589903  Acc:  0.8577 Val_loss =  0.46871635 Val_acc =  0.8379\n",
            "Iteration  1012 : Loss =  0.42583352  Acc:  0.8577333 Val_loss =  0.46866837 Val_acc =  0.8379\n",
            "Iteration  1013 : Loss =  0.42576817  Acc:  0.85775 Val_loss =  0.46862042 Val_acc =  0.8379\n",
            "Iteration  1014 : Loss =  0.42570287  Acc:  0.8577167 Val_loss =  0.46857262 Val_acc =  0.838\n",
            "Iteration  1015 : Loss =  0.4256377  Acc:  0.8577167 Val_loss =  0.46852484 Val_acc =  0.838\n",
            "Iteration  1016 : Loss =  0.42557254  Acc:  0.8577333 Val_loss =  0.46847725 Val_acc =  0.838\n",
            "Iteration  1017 : Loss =  0.42550755  Acc:  0.8577667 Val_loss =  0.46842963 Val_acc =  0.838\n",
            "Iteration  1018 : Loss =  0.42544264  Acc:  0.8578333 Val_loss =  0.46838218 Val_acc =  0.838\n",
            "Iteration  1019 : Loss =  0.4253778  Acc:  0.8578333 Val_loss =  0.46833476 Val_acc =  0.838\n",
            "Iteration  1020 : Loss =  0.42531306  Acc:  0.85785 Val_loss =  0.46828744 Val_acc =  0.8381\n",
            "Iteration  1021 : Loss =  0.4252484  Acc:  0.85786664 Val_loss =  0.46824023 Val_acc =  0.8381\n",
            "Iteration  1022 : Loss =  0.42518383  Acc:  0.8579 Val_loss =  0.46819302 Val_acc =  0.8381\n",
            "Iteration  1023 : Loss =  0.42511937  Acc:  0.85793334 Val_loss =  0.468146 Val_acc =  0.8382\n",
            "Iteration  1024 : Loss =  0.42505503  Acc:  0.85793334 Val_loss =  0.46809903 Val_acc =  0.8382\n",
            "Iteration  1025 : Loss =  0.42499068  Acc:  0.85793334 Val_loss =  0.46805206 Val_acc =  0.8382\n",
            "Iteration  1026 : Loss =  0.42492652  Acc:  0.85793334 Val_loss =  0.46800527 Val_acc =  0.8382\n",
            "Iteration  1027 : Loss =  0.42486244  Acc:  0.85796666 Val_loss =  0.46795854 Val_acc =  0.8382\n",
            "Iteration  1028 : Loss =  0.4247984  Acc:  0.85796666 Val_loss =  0.46791193 Val_acc =  0.8382\n",
            "Iteration  1029 : Loss =  0.4247345  Acc:  0.85798335 Val_loss =  0.46786532 Val_acc =  0.8381\n",
            "Iteration  1030 : Loss =  0.42467064  Acc:  0.85803336 Val_loss =  0.46781886 Val_acc =  0.8381\n",
            "Iteration  1031 : Loss =  0.4246069  Acc:  0.85805 Val_loss =  0.46777245 Val_acc =  0.8381\n",
            "Iteration  1032 : Loss =  0.42454326  Acc:  0.8581167 Val_loss =  0.46772608 Val_acc =  0.8381\n",
            "Iteration  1033 : Loss =  0.4244797  Acc:  0.8581833 Val_loss =  0.4676799 Val_acc =  0.8381\n",
            "Iteration  1034 : Loss =  0.4244162  Acc:  0.85821664 Val_loss =  0.46763375 Val_acc =  0.8381\n",
            "Iteration  1035 : Loss =  0.42435282  Acc:  0.85821664 Val_loss =  0.46758765 Val_acc =  0.8381\n",
            "Iteration  1036 : Loss =  0.42428955  Acc:  0.85823333 Val_loss =  0.46754166 Val_acc =  0.8381\n",
            "Iteration  1037 : Loss =  0.4242263  Acc:  0.85821664 Val_loss =  0.4674957 Val_acc =  0.8382\n",
            "Iteration  1038 : Loss =  0.4241632  Acc:  0.85821664 Val_loss =  0.4674499 Val_acc =  0.8382\n",
            "Iteration  1039 : Loss =  0.42410016  Acc:  0.85821664 Val_loss =  0.4674041 Val_acc =  0.8382\n",
            "Iteration  1040 : Loss =  0.42403722  Acc:  0.8582 Val_loss =  0.4673585 Val_acc =  0.8381\n",
            "Iteration  1041 : Loss =  0.42397434  Acc:  0.85821664 Val_loss =  0.4673129 Val_acc =  0.8381\n",
            "Iteration  1042 : Loss =  0.4239116  Acc:  0.85825 Val_loss =  0.46726733 Val_acc =  0.8381\n",
            "Iteration  1043 : Loss =  0.4238489  Acc:  0.8583 Val_loss =  0.4672219 Val_acc =  0.838\n",
            "Iteration  1044 : Loss =  0.42378625  Acc:  0.8583 Val_loss =  0.46717656 Val_acc =  0.8381\n",
            "Iteration  1045 : Loss =  0.42372376  Acc:  0.85831666 Val_loss =  0.46713126 Val_acc =  0.8381\n",
            "Iteration  1046 : Loss =  0.42366132  Acc:  0.85838336 Val_loss =  0.46708608 Val_acc =  0.8381\n",
            "Iteration  1047 : Loss =  0.42359903  Acc:  0.85838336 Val_loss =  0.46704093 Val_acc =  0.838\n",
            "Iteration  1048 : Loss =  0.42353675  Acc:  0.85838336 Val_loss =  0.4669959 Val_acc =  0.838\n",
            "Iteration  1049 : Loss =  0.4234746  Acc:  0.8584 Val_loss =  0.46695098 Val_acc =  0.8381\n",
            "Iteration  1050 : Loss =  0.4234125  Acc:  0.8584167 Val_loss =  0.4669061 Val_acc =  0.838\n",
            "Iteration  1051 : Loss =  0.4233505  Acc:  0.8584333 Val_loss =  0.46686128 Val_acc =  0.8379\n",
            "Iteration  1052 : Loss =  0.4232886  Acc:  0.8584167 Val_loss =  0.4668165 Val_acc =  0.8379\n",
            "Iteration  1053 : Loss =  0.42322674  Acc:  0.8584167 Val_loss =  0.46677187 Val_acc =  0.8379\n",
            "Iteration  1054 : Loss =  0.423165  Acc:  0.8584167 Val_loss =  0.46672735 Val_acc =  0.8379\n",
            "Iteration  1055 : Loss =  0.42310336  Acc:  0.8584333 Val_loss =  0.46668285 Val_acc =  0.8379\n",
            "Iteration  1056 : Loss =  0.4230418  Acc:  0.8584833 Val_loss =  0.4666384 Val_acc =  0.8378\n",
            "Iteration  1057 : Loss =  0.4229803  Acc:  0.8585167 Val_loss =  0.46659404 Val_acc =  0.8379\n",
            "Iteration  1058 : Loss =  0.4229189  Acc:  0.8585333 Val_loss =  0.4665498 Val_acc =  0.8379\n",
            "Iteration  1059 : Loss =  0.42285755  Acc:  0.8585333 Val_loss =  0.46650556 Val_acc =  0.8379\n",
            "Iteration  1060 : Loss =  0.4227963  Acc:  0.85855 Val_loss =  0.4664615 Val_acc =  0.8379\n",
            "Iteration  1061 : Loss =  0.42273515  Acc:  0.85861665 Val_loss =  0.46641743 Val_acc =  0.8379\n",
            "Iteration  1062 : Loss =  0.4226741  Acc:  0.85863334 Val_loss =  0.46637347 Val_acc =  0.8379\n",
            "Iteration  1063 : Loss =  0.42261308  Acc:  0.85863334 Val_loss =  0.4663296 Val_acc =  0.8379\n",
            "Iteration  1064 : Loss =  0.42255217  Acc:  0.85868335 Val_loss =  0.4662858 Val_acc =  0.8379\n",
            "Iteration  1065 : Loss =  0.42249137  Acc:  0.85868335 Val_loss =  0.46624207 Val_acc =  0.838\n",
            "Iteration  1066 : Loss =  0.4224306  Acc:  0.85866666 Val_loss =  0.46619844 Val_acc =  0.838\n",
            "Iteration  1067 : Loss =  0.42236996  Acc:  0.85868335 Val_loss =  0.46615478 Val_acc =  0.8382\n",
            "Iteration  1068 : Loss =  0.42230937  Acc:  0.85866666 Val_loss =  0.46611133 Val_acc =  0.8382\n",
            "Iteration  1069 : Loss =  0.4222489  Acc:  0.85866666 Val_loss =  0.4660679 Val_acc =  0.8382\n",
            "Iteration  1070 : Loss =  0.42218843  Acc:  0.8587 Val_loss =  0.46602452 Val_acc =  0.8383\n",
            "Iteration  1071 : Loss =  0.4221281  Acc:  0.8587 Val_loss =  0.46598125 Val_acc =  0.8383\n",
            "Iteration  1072 : Loss =  0.42206788  Acc:  0.8587 Val_loss =  0.46593803 Val_acc =  0.8384\n",
            "Iteration  1073 : Loss =  0.42200768  Acc:  0.85873336 Val_loss =  0.46589488 Val_acc =  0.8384\n",
            "Iteration  1074 : Loss =  0.4219476  Acc:  0.8587667 Val_loss =  0.46585184 Val_acc =  0.8384\n",
            "Iteration  1075 : Loss =  0.4218876  Acc:  0.8588 Val_loss =  0.46580884 Val_acc =  0.8383\n",
            "Iteration  1076 : Loss =  0.42182767  Acc:  0.8588 Val_loss =  0.46576592 Val_acc =  0.8383\n",
            "Iteration  1077 : Loss =  0.42176777  Acc:  0.8587667 Val_loss =  0.46572304 Val_acc =  0.8383\n",
            "Iteration  1078 : Loss =  0.42170805  Acc:  0.8588333 Val_loss =  0.46568033 Val_acc =  0.8383\n",
            "Iteration  1079 : Loss =  0.42164838  Acc:  0.8589 Val_loss =  0.4656376 Val_acc =  0.8383\n",
            "Iteration  1080 : Loss =  0.42158872  Acc:  0.85895 Val_loss =  0.46559498 Val_acc =  0.8384\n",
            "Iteration  1081 : Loss =  0.42152917  Acc:  0.85896665 Val_loss =  0.46555245 Val_acc =  0.8384\n",
            "Iteration  1082 : Loss =  0.42146972  Acc:  0.85898334 Val_loss =  0.46550995 Val_acc =  0.8384\n",
            "Iteration  1083 : Loss =  0.42141035  Acc:  0.85898334 Val_loss =  0.46546757 Val_acc =  0.8383\n",
            "Iteration  1084 : Loss =  0.42135105  Acc:  0.859 Val_loss =  0.4654252 Val_acc =  0.8383\n",
            "Iteration  1085 : Loss =  0.42129183  Acc:  0.85903335 Val_loss =  0.46538296 Val_acc =  0.8383\n",
            "Iteration  1086 : Loss =  0.42123267  Acc:  0.85903335 Val_loss =  0.46534073 Val_acc =  0.8384\n",
            "Iteration  1087 : Loss =  0.42117363  Acc:  0.85905 Val_loss =  0.46529862 Val_acc =  0.8384\n",
            "Iteration  1088 : Loss =  0.42111465  Acc:  0.85906667 Val_loss =  0.4652566 Val_acc =  0.8384\n",
            "Iteration  1089 : Loss =  0.42105573  Acc:  0.85908335 Val_loss =  0.4652146 Val_acc =  0.8384\n",
            "Iteration  1090 : Loss =  0.4209969  Acc:  0.85908335 Val_loss =  0.4651727 Val_acc =  0.8383\n",
            "Iteration  1091 : Loss =  0.42093816  Acc:  0.8591 Val_loss =  0.46513087 Val_acc =  0.8383\n",
            "Iteration  1092 : Loss =  0.42087948  Acc:  0.8591167 Val_loss =  0.4650891 Val_acc =  0.8384\n",
            "Iteration  1093 : Loss =  0.4208209  Acc:  0.8591167 Val_loss =  0.46504742 Val_acc =  0.8384\n",
            "Iteration  1094 : Loss =  0.4207624  Acc:  0.85913336 Val_loss =  0.46500576 Val_acc =  0.8384\n",
            "Iteration  1095 : Loss =  0.42070392  Acc:  0.8591167 Val_loss =  0.46496427 Val_acc =  0.8384\n",
            "Iteration  1096 : Loss =  0.42064556  Acc:  0.8591 Val_loss =  0.46492276 Val_acc =  0.8385\n",
            "Iteration  1097 : Loss =  0.4205873  Acc:  0.8591667 Val_loss =  0.46488136 Val_acc =  0.8385\n",
            "Iteration  1098 : Loss =  0.4205291  Acc:  0.8591833 Val_loss =  0.46484 Val_acc =  0.8385\n",
            "Iteration  1099 : Loss =  0.42047092  Acc:  0.8592 Val_loss =  0.46479872 Val_acc =  0.8385\n",
            "Iteration  1100 : Loss =  0.4204129  Acc:  0.8592333 Val_loss =  0.46475753 Val_acc =  0.8385\n",
            "Iteration  1101 : Loss =  0.42035487  Acc:  0.85925 Val_loss =  0.4647164 Val_acc =  0.8385\n",
            "Iteration  1102 : Loss =  0.420297  Acc:  0.85925 Val_loss =  0.46467534 Val_acc =  0.8385\n",
            "Iteration  1103 : Loss =  0.42023915  Acc:  0.8593 Val_loss =  0.4646344 Val_acc =  0.8385\n",
            "Iteration  1104 : Loss =  0.42018142  Acc:  0.8593 Val_loss =  0.4645934 Val_acc =  0.8385\n",
            "Iteration  1105 : Loss =  0.4201237  Acc:  0.8593 Val_loss =  0.46455258 Val_acc =  0.8385\n",
            "Iteration  1106 : Loss =  0.42006612  Acc:  0.85931665 Val_loss =  0.46451178 Val_acc =  0.8387\n",
            "Iteration  1107 : Loss =  0.42000857  Acc:  0.85933334 Val_loss =  0.46447104 Val_acc =  0.8387\n",
            "Iteration  1108 : Loss =  0.4199511  Acc:  0.85936666 Val_loss =  0.46443036 Val_acc =  0.8386\n",
            "Iteration  1109 : Loss =  0.4198937  Acc:  0.85933334 Val_loss =  0.4643898 Val_acc =  0.8386\n",
            "Iteration  1110 : Loss =  0.4198364  Acc:  0.85936666 Val_loss =  0.46434933 Val_acc =  0.8386\n",
            "Iteration  1111 : Loss =  0.41977918  Acc:  0.85938334 Val_loss =  0.46430883 Val_acc =  0.8387\n",
            "Iteration  1112 : Loss =  0.419722  Acc:  0.85938334 Val_loss =  0.46426845 Val_acc =  0.8386\n",
            "Iteration  1113 : Loss =  0.41966492  Acc:  0.85938334 Val_loss =  0.46422812 Val_acc =  0.8387\n",
            "Iteration  1114 : Loss =  0.4196079  Acc:  0.85936666 Val_loss =  0.4641879 Val_acc =  0.8387\n",
            "Iteration  1115 : Loss =  0.41955096  Acc:  0.85936666 Val_loss =  0.46414775 Val_acc =  0.8387\n",
            "Iteration  1116 : Loss =  0.41949406  Acc:  0.85935 Val_loss =  0.46410757 Val_acc =  0.8387\n",
            "Iteration  1117 : Loss =  0.41943732  Acc:  0.85931665 Val_loss =  0.46406758 Val_acc =  0.8387\n",
            "Iteration  1118 : Loss =  0.41938058  Acc:  0.85936666 Val_loss =  0.46402758 Val_acc =  0.8386\n",
            "Iteration  1119 : Loss =  0.41932392  Acc:  0.85936666 Val_loss =  0.4639877 Val_acc =  0.8386\n",
            "Iteration  1120 : Loss =  0.41926736  Acc:  0.8594 Val_loss =  0.46394786 Val_acc =  0.8386\n",
            "Iteration  1121 : Loss =  0.41921085  Acc:  0.85941666 Val_loss =  0.46390802 Val_acc =  0.8386\n",
            "Iteration  1122 : Loss =  0.4191544  Acc:  0.8594 Val_loss =  0.46386832 Val_acc =  0.8386\n",
            "Iteration  1123 : Loss =  0.41909805  Acc:  0.85943335 Val_loss =  0.46382865 Val_acc =  0.8385\n",
            "Iteration  1124 : Loss =  0.41904175  Acc:  0.8594667 Val_loss =  0.46378908 Val_acc =  0.8385\n",
            "Iteration  1125 : Loss =  0.41898555  Acc:  0.8595 Val_loss =  0.46374956 Val_acc =  0.8385\n",
            "Iteration  1126 : Loss =  0.4189294  Acc:  0.8595333 Val_loss =  0.46371016 Val_acc =  0.8385\n",
            "Iteration  1127 : Loss =  0.4188733  Acc:  0.8595333 Val_loss =  0.4636707 Val_acc =  0.8386\n",
            "Iteration  1128 : Loss =  0.4188173  Acc:  0.8595667 Val_loss =  0.4636314 Val_acc =  0.8386\n",
            "Iteration  1129 : Loss =  0.41876137  Acc:  0.85961664 Val_loss =  0.46359214 Val_acc =  0.8386\n",
            "Iteration  1130 : Loss =  0.41870552  Acc:  0.8596333 Val_loss =  0.46355292 Val_acc =  0.8386\n",
            "Iteration  1131 : Loss =  0.41864973  Acc:  0.8596333 Val_loss =  0.46351382 Val_acc =  0.8386\n",
            "Iteration  1132 : Loss =  0.418594  Acc:  0.85966665 Val_loss =  0.46347475 Val_acc =  0.8386\n",
            "Iteration  1133 : Loss =  0.41853833  Acc:  0.85971665 Val_loss =  0.46343574 Val_acc =  0.8385\n",
            "Iteration  1134 : Loss =  0.4184828  Acc:  0.85973334 Val_loss =  0.46339682 Val_acc =  0.8385\n",
            "Iteration  1135 : Loss =  0.4184273  Acc:  0.85976666 Val_loss =  0.46335796 Val_acc =  0.8385\n",
            "Iteration  1136 : Loss =  0.4183718  Acc:  0.85978335 Val_loss =  0.46331915 Val_acc =  0.8386\n",
            "Iteration  1137 : Loss =  0.41831648  Acc:  0.8598 Val_loss =  0.4632804 Val_acc =  0.8386\n",
            "Iteration  1138 : Loss =  0.4182612  Acc:  0.85978335 Val_loss =  0.46324176 Val_acc =  0.8386\n",
            "Iteration  1139 : Loss =  0.41820592  Acc:  0.85976666 Val_loss =  0.46320313 Val_acc =  0.8387\n",
            "Iteration  1140 : Loss =  0.41815078  Acc:  0.85973334 Val_loss =  0.46316454 Val_acc =  0.8387\n",
            "Iteration  1141 : Loss =  0.4180957  Acc:  0.85978335 Val_loss =  0.46312606 Val_acc =  0.8387\n",
            "Iteration  1142 : Loss =  0.41804066  Acc:  0.8598167 Val_loss =  0.4630876 Val_acc =  0.8388\n",
            "Iteration  1143 : Loss =  0.4179857  Acc:  0.85983336 Val_loss =  0.46304932 Val_acc =  0.8388\n",
            "Iteration  1144 : Loss =  0.41793084  Acc:  0.8598833 Val_loss =  0.46301094 Val_acc =  0.8388\n",
            "Iteration  1145 : Loss =  0.41787598  Acc:  0.8598667 Val_loss =  0.46297276 Val_acc =  0.8388\n",
            "Iteration  1146 : Loss =  0.4178213  Acc:  0.8598833 Val_loss =  0.46293458 Val_acc =  0.839\n",
            "Iteration  1147 : Loss =  0.4177666  Acc:  0.8599 Val_loss =  0.4628965 Val_acc =  0.839\n",
            "Iteration  1148 : Loss =  0.41771197  Acc:  0.8598833 Val_loss =  0.4628584 Val_acc =  0.839\n",
            "Iteration  1149 : Loss =  0.41765743  Acc:  0.8598833 Val_loss =  0.4628204 Val_acc =  0.8392\n",
            "Iteration  1150 : Loss =  0.41760296  Acc:  0.8599 Val_loss =  0.46278253 Val_acc =  0.8392\n",
            "Iteration  1151 : Loss =  0.41754854  Acc:  0.8599 Val_loss =  0.46274462 Val_acc =  0.8393\n",
            "Iteration  1152 : Loss =  0.4174942  Acc:  0.8599 Val_loss =  0.46270683 Val_acc =  0.8393\n",
            "Iteration  1153 : Loss =  0.4174399  Acc:  0.8599333 Val_loss =  0.4626691 Val_acc =  0.8393\n",
            "Iteration  1154 : Loss =  0.41738576  Acc:  0.8599333 Val_loss =  0.46263143 Val_acc =  0.8393\n",
            "Iteration  1155 : Loss =  0.41733158  Acc:  0.8599833 Val_loss =  0.4625938 Val_acc =  0.8393\n",
            "Iteration  1156 : Loss =  0.41727754  Acc:  0.8599833 Val_loss =  0.46255624 Val_acc =  0.8393\n",
            "Iteration  1157 : Loss =  0.4172235  Acc:  0.86 Val_loss =  0.46251875 Val_acc =  0.8395\n",
            "Iteration  1158 : Loss =  0.4171696  Acc:  0.86003333 Val_loss =  0.4624813 Val_acc =  0.8395\n",
            "Iteration  1159 : Loss =  0.4171157  Acc:  0.86006665 Val_loss =  0.46244395 Val_acc =  0.8396\n",
            "Iteration  1160 : Loss =  0.41706192  Acc:  0.8601 Val_loss =  0.46240664 Val_acc =  0.8396\n",
            "Iteration  1161 : Loss =  0.41700813  Acc:  0.86015 Val_loss =  0.46236938 Val_acc =  0.8396\n",
            "Iteration  1162 : Loss =  0.4169545  Acc:  0.8602 Val_loss =  0.4623322 Val_acc =  0.8396\n",
            "Iteration  1163 : Loss =  0.41690087  Acc:  0.8602167 Val_loss =  0.46229506 Val_acc =  0.8396\n",
            "Iteration  1164 : Loss =  0.41684732  Acc:  0.8602167 Val_loss =  0.462258 Val_acc =  0.8396\n",
            "Iteration  1165 : Loss =  0.41679388  Acc:  0.8602 Val_loss =  0.462221 Val_acc =  0.8397\n",
            "Iteration  1166 : Loss =  0.41674048  Acc:  0.8602 Val_loss =  0.46218404 Val_acc =  0.8397\n",
            "Iteration  1167 : Loss =  0.4166871  Acc:  0.8602 Val_loss =  0.46214718 Val_acc =  0.8397\n",
            "Iteration  1168 : Loss =  0.41663384  Acc:  0.8602167 Val_loss =  0.4621103 Val_acc =  0.8397\n",
            "Iteration  1169 : Loss =  0.41658062  Acc:  0.86025 Val_loss =  0.46207353 Val_acc =  0.8397\n",
            "Iteration  1170 : Loss =  0.41652748  Acc:  0.86025 Val_loss =  0.46203682 Val_acc =  0.8398\n",
            "Iteration  1171 : Loss =  0.41647437  Acc:  0.8603167 Val_loss =  0.4620002 Val_acc =  0.8398\n",
            "Iteration  1172 : Loss =  0.41642135  Acc:  0.86038333 Val_loss =  0.46196356 Val_acc =  0.8398\n",
            "Iteration  1173 : Loss =  0.41636842  Acc:  0.86036664 Val_loss =  0.46192706 Val_acc =  0.8398\n",
            "Iteration  1174 : Loss =  0.4163155  Acc:  0.86038333 Val_loss =  0.46189052 Val_acc =  0.8398\n",
            "Iteration  1175 : Loss =  0.4162627  Acc:  0.86041665 Val_loss =  0.4618541 Val_acc =  0.8398\n",
            "Iteration  1176 : Loss =  0.41620997  Acc:  0.86041665 Val_loss =  0.46181777 Val_acc =  0.8399\n",
            "Iteration  1177 : Loss =  0.41615722  Acc:  0.86045 Val_loss =  0.4617815 Val_acc =  0.8399\n",
            "Iteration  1178 : Loss =  0.4161046  Acc:  0.86048335 Val_loss =  0.4617452 Val_acc =  0.8399\n",
            "Iteration  1179 : Loss =  0.416052  Acc:  0.8605 Val_loss =  0.46170908 Val_acc =  0.84\n",
            "Iteration  1180 : Loss =  0.4159995  Acc:  0.8605 Val_loss =  0.46167296 Val_acc =  0.84\n",
            "Iteration  1181 : Loss =  0.41594708  Acc:  0.86045 Val_loss =  0.46163687 Val_acc =  0.8401\n",
            "Iteration  1182 : Loss =  0.4158947  Acc:  0.86048335 Val_loss =  0.46160087 Val_acc =  0.8401\n",
            "Iteration  1183 : Loss =  0.41584238  Acc:  0.8605 Val_loss =  0.4615649 Val_acc =  0.8401\n",
            "Iteration  1184 : Loss =  0.41579014  Acc:  0.86055 Val_loss =  0.46152902 Val_acc =  0.8401\n",
            "Iteration  1185 : Loss =  0.41573796  Acc:  0.86055 Val_loss =  0.46149316 Val_acc =  0.84\n",
            "Iteration  1186 : Loss =  0.4156858  Acc:  0.86055 Val_loss =  0.46145743 Val_acc =  0.84\n",
            "Iteration  1187 : Loss =  0.41563377  Acc:  0.86053336 Val_loss =  0.46142167 Val_acc =  0.84\n",
            "Iteration  1188 : Loss =  0.41558173  Acc:  0.86055 Val_loss =  0.461386 Val_acc =  0.84\n",
            "Iteration  1189 : Loss =  0.41552982  Acc:  0.8606333 Val_loss =  0.46135038 Val_acc =  0.84\n",
            "Iteration  1190 : Loss =  0.41547793  Acc:  0.8607 Val_loss =  0.46131486 Val_acc =  0.84\n",
            "Iteration  1191 : Loss =  0.4154261  Acc:  0.86073333 Val_loss =  0.46127933 Val_acc =  0.84\n",
            "Iteration  1192 : Loss =  0.41537434  Acc:  0.86073333 Val_loss =  0.46124396 Val_acc =  0.84\n",
            "Iteration  1193 : Loss =  0.41532266  Acc:  0.86075 Val_loss =  0.46120855 Val_acc =  0.84\n",
            "Iteration  1194 : Loss =  0.415271  Acc:  0.86076665 Val_loss =  0.4611732 Val_acc =  0.84\n",
            "Iteration  1195 : Loss =  0.41521946  Acc:  0.86073333 Val_loss =  0.46113795 Val_acc =  0.84\n",
            "Iteration  1196 : Loss =  0.41516796  Acc:  0.86073333 Val_loss =  0.46110272 Val_acc =  0.84\n",
            "Iteration  1197 : Loss =  0.41511652  Acc:  0.86071664 Val_loss =  0.4610676 Val_acc =  0.84\n",
            "Iteration  1198 : Loss =  0.41506514  Acc:  0.86071664 Val_loss =  0.46103248 Val_acc =  0.8401\n",
            "Iteration  1199 : Loss =  0.41501382  Acc:  0.8607 Val_loss =  0.46099746 Val_acc =  0.8401\n",
            "Iteration  1200 : Loss =  0.41496253  Acc:  0.86073333 Val_loss =  0.4609624 Val_acc =  0.8402\n",
            "Iteration  1201 : Loss =  0.41491133  Acc:  0.86073333 Val_loss =  0.4609275 Val_acc =  0.8402\n",
            "Iteration  1202 : Loss =  0.41486022  Acc:  0.86078334 Val_loss =  0.46089262 Val_acc =  0.8401\n",
            "Iteration  1203 : Loss =  0.4148091  Acc:  0.86081666 Val_loss =  0.4608578 Val_acc =  0.8401\n",
            "Iteration  1204 : Loss =  0.41475812  Acc:  0.86081666 Val_loss =  0.46082306 Val_acc =  0.8401\n",
            "Iteration  1205 : Loss =  0.41470715  Acc:  0.86083335 Val_loss =  0.46078828 Val_acc =  0.8401\n",
            "Iteration  1206 : Loss =  0.41465625  Acc:  0.8608 Val_loss =  0.4607537 Val_acc =  0.8402\n",
            "Iteration  1207 : Loss =  0.4146054  Acc:  0.86081666 Val_loss =  0.46071905 Val_acc =  0.8402\n",
            "Iteration  1208 : Loss =  0.41455463  Acc:  0.8608 Val_loss =  0.4606845 Val_acc =  0.8402\n",
            "Iteration  1209 : Loss =  0.4145039  Acc:  0.8608 Val_loss =  0.46065006 Val_acc =  0.8402\n",
            "Iteration  1210 : Loss =  0.41445327  Acc:  0.86083335 Val_loss =  0.46061563 Val_acc =  0.8402\n",
            "Iteration  1211 : Loss =  0.41440263  Acc:  0.8609 Val_loss =  0.4605812 Val_acc =  0.8403\n",
            "Iteration  1212 : Loss =  0.4143521  Acc:  0.8609167 Val_loss =  0.46054688 Val_acc =  0.8403\n",
            "Iteration  1213 : Loss =  0.41430163  Acc:  0.86095 Val_loss =  0.4605126 Val_acc =  0.8403\n",
            "Iteration  1214 : Loss =  0.41425118  Acc:  0.8609333 Val_loss =  0.46047843 Val_acc =  0.8403\n",
            "Iteration  1215 : Loss =  0.41420084  Acc:  0.86095 Val_loss =  0.46044424 Val_acc =  0.8403\n",
            "Iteration  1216 : Loss =  0.4141505  Acc:  0.8609833 Val_loss =  0.46041015 Val_acc =  0.8403\n",
            "Iteration  1217 : Loss =  0.41410026  Acc:  0.8609667 Val_loss =  0.46037608 Val_acc =  0.8403\n",
            "Iteration  1218 : Loss =  0.4140501  Acc:  0.8609667 Val_loss =  0.46034205 Val_acc =  0.8403\n",
            "Iteration  1219 : Loss =  0.41399997  Acc:  0.86095 Val_loss =  0.4603081 Val_acc =  0.8403\n",
            "Iteration  1220 : Loss =  0.41394988  Acc:  0.8609833 Val_loss =  0.46027422 Val_acc =  0.8403\n",
            "Iteration  1221 : Loss =  0.41389987  Acc:  0.8609833 Val_loss =  0.46024033 Val_acc =  0.8404\n",
            "Iteration  1222 : Loss =  0.41384992  Acc:  0.8609833 Val_loss =  0.46020654 Val_acc =  0.8404\n",
            "Iteration  1223 : Loss =  0.4138  Acc:  0.8609667 Val_loss =  0.4601728 Val_acc =  0.8404\n",
            "Iteration  1224 : Loss =  0.4137502  Acc:  0.8610833 Val_loss =  0.46013916 Val_acc =  0.8404\n",
            "Iteration  1225 : Loss =  0.4137004  Acc:  0.86106664 Val_loss =  0.4601055 Val_acc =  0.8405\n",
            "Iteration  1226 : Loss =  0.41365072  Acc:  0.86106664 Val_loss =  0.46007192 Val_acc =  0.8406\n",
            "Iteration  1227 : Loss =  0.41360104  Acc:  0.8610833 Val_loss =  0.46003842 Val_acc =  0.8407\n",
            "Iteration  1228 : Loss =  0.41355142  Acc:  0.8611 Val_loss =  0.46000493 Val_acc =  0.8407\n",
            "Iteration  1229 : Loss =  0.4135019  Acc:  0.8611 Val_loss =  0.4599715 Val_acc =  0.8407\n",
            "Iteration  1230 : Loss =  0.41345236  Acc:  0.86115 Val_loss =  0.4599382 Val_acc =  0.8407\n",
            "Iteration  1231 : Loss =  0.41340292  Acc:  0.8612 Val_loss =  0.45990482 Val_acc =  0.8407\n",
            "Iteration  1232 : Loss =  0.4133536  Acc:  0.86121666 Val_loss =  0.4598716 Val_acc =  0.8407\n",
            "Iteration  1233 : Loss =  0.41330424  Acc:  0.86123335 Val_loss =  0.4598384 Val_acc =  0.8406\n",
            "Iteration  1234 : Loss =  0.41325498  Acc:  0.86123335 Val_loss =  0.4598052 Val_acc =  0.8407\n",
            "Iteration  1235 : Loss =  0.41320577  Acc:  0.86123335 Val_loss =  0.4597721 Val_acc =  0.8407\n",
            "Iteration  1236 : Loss =  0.41315663  Acc:  0.86121666 Val_loss =  0.459739 Val_acc =  0.8408\n",
            "Iteration  1237 : Loss =  0.41310754  Acc:  0.86123335 Val_loss =  0.45970607 Val_acc =  0.8407\n",
            "Iteration  1238 : Loss =  0.4130585  Acc:  0.86123335 Val_loss =  0.45967305 Val_acc =  0.8407\n",
            "Iteration  1239 : Loss =  0.4130095  Acc:  0.86123335 Val_loss =  0.45964015 Val_acc =  0.8407\n",
            "Iteration  1240 : Loss =  0.41296062  Acc:  0.8612667 Val_loss =  0.45960733 Val_acc =  0.8407\n",
            "Iteration  1241 : Loss =  0.4129117  Acc:  0.8613 Val_loss =  0.45957455 Val_acc =  0.8408\n",
            "Iteration  1242 : Loss =  0.4128629  Acc:  0.86128336 Val_loss =  0.4595418 Val_acc =  0.8408\n",
            "Iteration  1243 : Loss =  0.41281414  Acc:  0.8613 Val_loss =  0.45950907 Val_acc =  0.8408\n",
            "Iteration  1244 : Loss =  0.41276544  Acc:  0.8613333 Val_loss =  0.4594764 Val_acc =  0.8408\n",
            "Iteration  1245 : Loss =  0.4127168  Acc:  0.8613833 Val_loss =  0.45944384 Val_acc =  0.8408\n",
            "Iteration  1246 : Loss =  0.4126682  Acc:  0.8613833 Val_loss =  0.4594113 Val_acc =  0.8408\n",
            "Iteration  1247 : Loss =  0.41261965  Acc:  0.8614333 Val_loss =  0.4593788 Val_acc =  0.8408\n",
            "Iteration  1248 : Loss =  0.4125712  Acc:  0.86141664 Val_loss =  0.45934632 Val_acc =  0.8407\n",
            "Iteration  1249 : Loss =  0.41252276  Acc:  0.8614333 Val_loss =  0.45931396 Val_acc =  0.8407\n",
            "Iteration  1250 : Loss =  0.41247442  Acc:  0.86146665 Val_loss =  0.45928165 Val_acc =  0.8408\n",
            "Iteration  1251 : Loss =  0.41242608  Acc:  0.86148334 Val_loss =  0.45924932 Val_acc =  0.8408\n",
            "Iteration  1252 : Loss =  0.41237783  Acc:  0.86146665 Val_loss =  0.4592171 Val_acc =  0.8408\n",
            "Iteration  1253 : Loss =  0.4123296  Acc:  0.86146665 Val_loss =  0.4591849 Val_acc =  0.8407\n",
            "Iteration  1254 : Loss =  0.41228145  Acc:  0.86156666 Val_loss =  0.45915273 Val_acc =  0.8407\n",
            "Iteration  1255 : Loss =  0.41223332  Acc:  0.8616 Val_loss =  0.45912066 Val_acc =  0.8407\n",
            "Iteration  1256 : Loss =  0.4121853  Acc:  0.86158335 Val_loss =  0.45908862 Val_acc =  0.8407\n",
            "Iteration  1257 : Loss =  0.41213733  Acc:  0.86156666 Val_loss =  0.45905665 Val_acc =  0.8407\n",
            "Iteration  1258 : Loss =  0.41208938  Acc:  0.8616 Val_loss =  0.4590247 Val_acc =  0.8407\n",
            "Iteration  1259 : Loss =  0.41204154  Acc:  0.8616 Val_loss =  0.45899278 Val_acc =  0.8407\n",
            "Iteration  1260 : Loss =  0.41199368  Acc:  0.8616167 Val_loss =  0.45896098 Val_acc =  0.8407\n",
            "Iteration  1261 : Loss =  0.4119459  Acc:  0.86163336 Val_loss =  0.4589292 Val_acc =  0.8407\n",
            "Iteration  1262 : Loss =  0.41189817  Acc:  0.8616667 Val_loss =  0.4588974 Val_acc =  0.8408\n",
            "Iteration  1263 : Loss =  0.4118505  Acc:  0.8616667 Val_loss =  0.45886573 Val_acc =  0.8408\n",
            "Iteration  1264 : Loss =  0.41180292  Acc:  0.8617 Val_loss =  0.45883408 Val_acc =  0.8408\n",
            "Iteration  1265 : Loss =  0.41175535  Acc:  0.8617167 Val_loss =  0.45880243 Val_acc =  0.8408\n",
            "Iteration  1266 : Loss =  0.41170782  Acc:  0.86175 Val_loss =  0.45877096 Val_acc =  0.8408\n",
            "Iteration  1267 : Loss =  0.41166037  Acc:  0.8617833 Val_loss =  0.4587394 Val_acc =  0.8409\n",
            "Iteration  1268 : Loss =  0.41161302  Acc:  0.8617667 Val_loss =  0.45870796 Val_acc =  0.841\n",
            "Iteration  1269 : Loss =  0.41156563  Acc:  0.86175 Val_loss =  0.45867658 Val_acc =  0.8411\n",
            "Iteration  1270 : Loss =  0.41151837  Acc:  0.86175 Val_loss =  0.45864522 Val_acc =  0.8411\n",
            "Iteration  1271 : Loss =  0.4114711  Acc:  0.8617833 Val_loss =  0.45861387 Val_acc =  0.8411\n",
            "Iteration  1272 : Loss =  0.41142392  Acc:  0.8617833 Val_loss =  0.4585826 Val_acc =  0.8411\n",
            "Iteration  1273 : Loss =  0.4113768  Acc:  0.86183333 Val_loss =  0.45855147 Val_acc =  0.8411\n",
            "Iteration  1274 : Loss =  0.41132972  Acc:  0.86185 Val_loss =  0.45852026 Val_acc =  0.841\n",
            "Iteration  1275 : Loss =  0.4112827  Acc:  0.86185 Val_loss =  0.45848915 Val_acc =  0.8409\n",
            "Iteration  1276 : Loss =  0.4112357  Acc:  0.86183333 Val_loss =  0.4584581 Val_acc =  0.8409\n",
            "Iteration  1277 : Loss =  0.4111888  Acc:  0.86183333 Val_loss =  0.45842704 Val_acc =  0.8409\n",
            "Iteration  1278 : Loss =  0.4111419  Acc:  0.86185 Val_loss =  0.4583961 Val_acc =  0.8409\n",
            "Iteration  1279 : Loss =  0.41109505  Acc:  0.86185 Val_loss =  0.45836514 Val_acc =  0.8409\n",
            "Iteration  1280 : Loss =  0.41104835  Acc:  0.86185 Val_loss =  0.45833427 Val_acc =  0.8409\n",
            "Iteration  1281 : Loss =  0.41100162  Acc:  0.86185 Val_loss =  0.45830348 Val_acc =  0.8409\n",
            "Iteration  1282 : Loss =  0.41095492  Acc:  0.8618 Val_loss =  0.4582727 Val_acc =  0.841\n",
            "Iteration  1283 : Loss =  0.4109083  Acc:  0.86185 Val_loss =  0.45824194 Val_acc =  0.8411\n",
            "Iteration  1284 : Loss =  0.4108618  Acc:  0.86186665 Val_loss =  0.45821127 Val_acc =  0.8412\n",
            "Iteration  1285 : Loss =  0.41081524  Acc:  0.86186665 Val_loss =  0.4581806 Val_acc =  0.8412\n",
            "Iteration  1286 : Loss =  0.41076878  Acc:  0.86191666 Val_loss =  0.45815006 Val_acc =  0.8413\n",
            "Iteration  1287 : Loss =  0.4107224  Acc:  0.86193335 Val_loss =  0.45811948 Val_acc =  0.8413\n",
            "Iteration  1288 : Loss =  0.410676  Acc:  0.86193335 Val_loss =  0.45808896 Val_acc =  0.8414\n",
            "Iteration  1289 : Loss =  0.4106297  Acc:  0.86196667 Val_loss =  0.45805854 Val_acc =  0.8415\n",
            "Iteration  1290 : Loss =  0.41058344  Acc:  0.86193335 Val_loss =  0.45802814 Val_acc =  0.8415\n",
            "Iteration  1291 : Loss =  0.41053724  Acc:  0.86195 Val_loss =  0.45799774 Val_acc =  0.8414\n",
            "Iteration  1292 : Loss =  0.41049108  Acc:  0.8620167 Val_loss =  0.4579675 Val_acc =  0.8414\n",
            "Iteration  1293 : Loss =  0.41044495  Acc:  0.8620333 Val_loss =  0.4579372 Val_acc =  0.8414\n",
            "Iteration  1294 : Loss =  0.4103989  Acc:  0.8620333 Val_loss =  0.457907 Val_acc =  0.8413\n",
            "Iteration  1295 : Loss =  0.4103529  Acc:  0.8620333 Val_loss =  0.45787677 Val_acc =  0.8413\n",
            "Iteration  1296 : Loss =  0.41030696  Acc:  0.8620667 Val_loss =  0.45784667 Val_acc =  0.8413\n",
            "Iteration  1297 : Loss =  0.41026103  Acc:  0.8620833 Val_loss =  0.45781654 Val_acc =  0.8412\n",
            "Iteration  1298 : Loss =  0.41021517  Acc:  0.8621 Val_loss =  0.45778653 Val_acc =  0.8412\n",
            "Iteration  1299 : Loss =  0.4101694  Acc:  0.8620833 Val_loss =  0.45775655 Val_acc =  0.8412\n",
            "Iteration  1300 : Loss =  0.41012365  Acc:  0.8620833 Val_loss =  0.45772657 Val_acc =  0.8412\n",
            "Iteration  1301 : Loss =  0.41007793  Acc:  0.8620833 Val_loss =  0.45769674 Val_acc =  0.8412\n",
            "Iteration  1302 : Loss =  0.41003227  Acc:  0.8621 Val_loss =  0.45766684 Val_acc =  0.8411\n",
            "Iteration  1303 : Loss =  0.40998664  Acc:  0.86215 Val_loss =  0.457637 Val_acc =  0.841\n",
            "Iteration  1304 : Loss =  0.40994108  Acc:  0.86215 Val_loss =  0.45760727 Val_acc =  0.841\n",
            "Iteration  1305 : Loss =  0.40989557  Acc:  0.86216664 Val_loss =  0.45757753 Val_acc =  0.841\n",
            "Iteration  1306 : Loss =  0.40985012  Acc:  0.8622 Val_loss =  0.4575479 Val_acc =  0.841\n",
            "Iteration  1307 : Loss =  0.40980476  Acc:  0.86218333 Val_loss =  0.45751825 Val_acc =  0.841\n",
            "Iteration  1308 : Loss =  0.40975937  Acc:  0.86218333 Val_loss =  0.4574887 Val_acc =  0.841\n",
            "Iteration  1309 : Loss =  0.40971407  Acc:  0.86218333 Val_loss =  0.45745912 Val_acc =  0.841\n",
            "Iteration  1310 : Loss =  0.4096688  Acc:  0.86216664 Val_loss =  0.45742965 Val_acc =  0.841\n",
            "Iteration  1311 : Loss =  0.40962356  Acc:  0.86216664 Val_loss =  0.4574002 Val_acc =  0.8409\n",
            "Iteration  1312 : Loss =  0.4095784  Acc:  0.86218333 Val_loss =  0.4573708 Val_acc =  0.8409\n",
            "Iteration  1313 : Loss =  0.4095333  Acc:  0.86218333 Val_loss =  0.4573414 Val_acc =  0.8409\n",
            "Iteration  1314 : Loss =  0.40948826  Acc:  0.8622 Val_loss =  0.4573121 Val_acc =  0.841\n",
            "Iteration  1315 : Loss =  0.40944323  Acc:  0.8622 Val_loss =  0.4572828 Val_acc =  0.841\n",
            "Iteration  1316 : Loss =  0.40939823  Acc:  0.86221665 Val_loss =  0.4572536 Val_acc =  0.841\n",
            "Iteration  1317 : Loss =  0.40935332  Acc:  0.86226666 Val_loss =  0.45722443 Val_acc =  0.8411\n",
            "Iteration  1318 : Loss =  0.40930846  Acc:  0.86231667 Val_loss =  0.4571953 Val_acc =  0.8411\n",
            "Iteration  1319 : Loss =  0.40926364  Acc:  0.8623833 Val_loss =  0.45716622 Val_acc =  0.8411\n",
            "Iteration  1320 : Loss =  0.40921885  Acc:  0.8624 Val_loss =  0.45713717 Val_acc =  0.8411\n",
            "Iteration  1321 : Loss =  0.4091741  Acc:  0.8624167 Val_loss =  0.45710814 Val_acc =  0.8411\n",
            "Iteration  1322 : Loss =  0.40912944  Acc:  0.8624333 Val_loss =  0.4570792 Val_acc =  0.841\n",
            "Iteration  1323 : Loss =  0.40908483  Acc:  0.8624333 Val_loss =  0.45705023 Val_acc =  0.841\n",
            "Iteration  1324 : Loss =  0.40904024  Acc:  0.8624167 Val_loss =  0.4570214 Val_acc =  0.841\n",
            "Iteration  1325 : Loss =  0.40899572  Acc:  0.8624 Val_loss =  0.45699257 Val_acc =  0.841\n",
            "Iteration  1326 : Loss =  0.40895116  Acc:  0.8624167 Val_loss =  0.45696378 Val_acc =  0.841\n",
            "Iteration  1327 : Loss =  0.40890676  Acc:  0.8624167 Val_loss =  0.45693502 Val_acc =  0.841\n",
            "Iteration  1328 : Loss =  0.40886238  Acc:  0.8624167 Val_loss =  0.45690635 Val_acc =  0.841\n",
            "Iteration  1329 : Loss =  0.408818  Acc:  0.8624333 Val_loss =  0.45687768 Val_acc =  0.841\n",
            "Iteration  1330 : Loss =  0.4087737  Acc:  0.8624667 Val_loss =  0.456849 Val_acc =  0.841\n",
            "Iteration  1331 : Loss =  0.40872943  Acc:  0.8624667 Val_loss =  0.45682052 Val_acc =  0.841\n",
            "Iteration  1332 : Loss =  0.4086852  Acc:  0.86245 Val_loss =  0.456792 Val_acc =  0.841\n",
            "Iteration  1333 : Loss =  0.40864104  Acc:  0.86245 Val_loss =  0.45676348 Val_acc =  0.841\n",
            "Iteration  1334 : Loss =  0.40859693  Acc:  0.8624333 Val_loss =  0.45673501 Val_acc =  0.841\n",
            "Iteration  1335 : Loss =  0.40855286  Acc:  0.8624833 Val_loss =  0.45670664 Val_acc =  0.841\n",
            "Iteration  1336 : Loss =  0.40850887  Acc:  0.86251664 Val_loss =  0.45667833 Val_acc =  0.841\n",
            "Iteration  1337 : Loss =  0.40846488  Acc:  0.86251664 Val_loss =  0.45664996 Val_acc =  0.8411\n",
            "Iteration  1338 : Loss =  0.40842095  Acc:  0.8625 Val_loss =  0.45662168 Val_acc =  0.8411\n",
            "Iteration  1339 : Loss =  0.40837708  Acc:  0.86251664 Val_loss =  0.45659345 Val_acc =  0.8411\n",
            "Iteration  1340 : Loss =  0.40833327  Acc:  0.86253333 Val_loss =  0.4565653 Val_acc =  0.8411\n",
            "Iteration  1341 : Loss =  0.40828946  Acc:  0.86255 Val_loss =  0.4565371 Val_acc =  0.841\n",
            "Iteration  1342 : Loss =  0.4082457  Acc:  0.86258334 Val_loss =  0.45650902 Val_acc =  0.8411\n",
            "Iteration  1343 : Loss =  0.40820202  Acc:  0.86258334 Val_loss =  0.45648095 Val_acc =  0.8411\n",
            "Iteration  1344 : Loss =  0.40815833  Acc:  0.8626 Val_loss =  0.45645294 Val_acc =  0.8411\n",
            "Iteration  1345 : Loss =  0.40811473  Acc:  0.86258334 Val_loss =  0.45642495 Val_acc =  0.8411\n",
            "Iteration  1346 : Loss =  0.40807116  Acc:  0.86258334 Val_loss =  0.45639703 Val_acc =  0.8412\n",
            "Iteration  1347 : Loss =  0.40802768  Acc:  0.86258334 Val_loss =  0.45636913 Val_acc =  0.8412\n",
            "Iteration  1348 : Loss =  0.40798417  Acc:  0.86263335 Val_loss =  0.4563413 Val_acc =  0.8412\n",
            "Iteration  1349 : Loss =  0.40794075  Acc:  0.86263335 Val_loss =  0.4563135 Val_acc =  0.8412\n",
            "Iteration  1350 : Loss =  0.40789738  Acc:  0.8627 Val_loss =  0.4562857 Val_acc =  0.8412\n",
            "Iteration  1351 : Loss =  0.40785408  Acc:  0.8627167 Val_loss =  0.456258 Val_acc =  0.8412\n",
            "Iteration  1352 : Loss =  0.40781075  Acc:  0.86275 Val_loss =  0.4562303 Val_acc =  0.8412\n",
            "Iteration  1353 : Loss =  0.4077675  Acc:  0.86275 Val_loss =  0.4562027 Val_acc =  0.8412\n",
            "Iteration  1354 : Loss =  0.40772432  Acc:  0.8628167 Val_loss =  0.4561751 Val_acc =  0.8412\n",
            "Iteration  1355 : Loss =  0.4076812  Acc:  0.8628333 Val_loss =  0.45614752 Val_acc =  0.8411\n",
            "Iteration  1356 : Loss =  0.40763804  Acc:  0.86285 Val_loss =  0.45612 Val_acc =  0.8411\n",
            "Iteration  1357 : Loss =  0.40759498  Acc:  0.86285 Val_loss =  0.45609248 Val_acc =  0.8411\n",
            "Iteration  1358 : Loss =  0.40755197  Acc:  0.8628333 Val_loss =  0.4560651 Val_acc =  0.8411\n",
            "Iteration  1359 : Loss =  0.407509  Acc:  0.8628333 Val_loss =  0.4560377 Val_acc =  0.8412\n",
            "Iteration  1360 : Loss =  0.40746608  Acc:  0.8628333 Val_loss =  0.45601034 Val_acc =  0.8412\n",
            "Iteration  1361 : Loss =  0.40742317  Acc:  0.8628333 Val_loss =  0.455983 Val_acc =  0.8412\n",
            "Iteration  1362 : Loss =  0.40738034  Acc:  0.8628833 Val_loss =  0.45595577 Val_acc =  0.8412\n",
            "Iteration  1363 : Loss =  0.40733755  Acc:  0.86295 Val_loss =  0.4559285 Val_acc =  0.8413\n",
            "Iteration  1364 : Loss =  0.40729478  Acc:  0.86296666 Val_loss =  0.45590132 Val_acc =  0.8414\n",
            "Iteration  1365 : Loss =  0.40725207  Acc:  0.86296666 Val_loss =  0.45587417 Val_acc =  0.8416\n",
            "Iteration  1366 : Loss =  0.4072094  Acc:  0.86301666 Val_loss =  0.45584708 Val_acc =  0.8417\n",
            "Iteration  1367 : Loss =  0.4071668  Acc:  0.86303335 Val_loss =  0.45582002 Val_acc =  0.8417\n",
            "Iteration  1368 : Loss =  0.40712422  Acc:  0.86301666 Val_loss =  0.45579296 Val_acc =  0.8417\n",
            "Iteration  1369 : Loss =  0.4070817  Acc:  0.8630667 Val_loss =  0.45576596 Val_acc =  0.8417\n",
            "Iteration  1370 : Loss =  0.4070392  Acc:  0.86308336 Val_loss =  0.45573905 Val_acc =  0.8417\n",
            "Iteration  1371 : Loss =  0.40699676  Acc:  0.8631 Val_loss =  0.4557121 Val_acc =  0.8418\n",
            "Iteration  1372 : Loss =  0.40695432  Acc:  0.86308336 Val_loss =  0.45568526 Val_acc =  0.8418\n",
            "Iteration  1373 : Loss =  0.40691197  Acc:  0.86308336 Val_loss =  0.4556584 Val_acc =  0.8418\n",
            "Iteration  1374 : Loss =  0.40686965  Acc:  0.8630667 Val_loss =  0.45563164 Val_acc =  0.8418\n",
            "Iteration  1375 : Loss =  0.40682742  Acc:  0.8631333 Val_loss =  0.45560488 Val_acc =  0.8418\n",
            "Iteration  1376 : Loss =  0.40678516  Acc:  0.8631667 Val_loss =  0.45557818 Val_acc =  0.8418\n",
            "Iteration  1377 : Loss =  0.40674296  Acc:  0.86321664 Val_loss =  0.4555515 Val_acc =  0.8418\n",
            "Iteration  1378 : Loss =  0.40670085  Acc:  0.86325 Val_loss =  0.4555249 Val_acc =  0.8418\n",
            "Iteration  1379 : Loss =  0.40665874  Acc:  0.8633 Val_loss =  0.45549828 Val_acc =  0.8418\n",
            "Iteration  1380 : Loss =  0.40661666  Acc:  0.86331666 Val_loss =  0.45547172 Val_acc =  0.8418\n",
            "Iteration  1381 : Loss =  0.40657467  Acc:  0.8633 Val_loss =  0.4554452 Val_acc =  0.8418\n",
            "Iteration  1382 : Loss =  0.40653268  Acc:  0.86331666 Val_loss =  0.45541874 Val_acc =  0.8418\n",
            "Iteration  1383 : Loss =  0.40649077  Acc:  0.86331666 Val_loss =  0.45539227 Val_acc =  0.8418\n",
            "Iteration  1384 : Loss =  0.4064489  Acc:  0.86333334 Val_loss =  0.45536593 Val_acc =  0.8418\n",
            "Iteration  1385 : Loss =  0.40640703  Acc:  0.86335 Val_loss =  0.45533955 Val_acc =  0.8418\n",
            "Iteration  1386 : Loss =  0.40636525  Acc:  0.86331666 Val_loss =  0.4553133 Val_acc =  0.8418\n",
            "Iteration  1387 : Loss =  0.40632346  Acc:  0.86331666 Val_loss =  0.455287 Val_acc =  0.8418\n",
            "Iteration  1388 : Loss =  0.40628177  Acc:  0.86331666 Val_loss =  0.45526075 Val_acc =  0.8418\n",
            "Iteration  1389 : Loss =  0.4062401  Acc:  0.86331666 Val_loss =  0.45523453 Val_acc =  0.8419\n",
            "Iteration  1390 : Loss =  0.40619844  Acc:  0.86331666 Val_loss =  0.4552084 Val_acc =  0.8419\n",
            "Iteration  1391 : Loss =  0.4061569  Acc:  0.8633 Val_loss =  0.45518228 Val_acc =  0.8418\n",
            "Iteration  1392 : Loss =  0.4061153  Acc:  0.86331666 Val_loss =  0.4551562 Val_acc =  0.8418\n",
            "Iteration  1393 : Loss =  0.40607384  Acc:  0.86335 Val_loss =  0.45513013 Val_acc =  0.8418\n",
            "Iteration  1394 : Loss =  0.40603235  Acc:  0.86335 Val_loss =  0.4551041 Val_acc =  0.8418\n",
            "Iteration  1395 : Loss =  0.40599093  Acc:  0.86333334 Val_loss =  0.45507818 Val_acc =  0.8418\n",
            "Iteration  1396 : Loss =  0.40594953  Acc:  0.86335 Val_loss =  0.45505226 Val_acc =  0.8418\n",
            "Iteration  1397 : Loss =  0.4059082  Acc:  0.86335 Val_loss =  0.45502636 Val_acc =  0.8418\n",
            "Iteration  1398 : Loss =  0.4058669  Acc:  0.86336666 Val_loss =  0.4550005 Val_acc =  0.8418\n",
            "Iteration  1399 : Loss =  0.40582564  Acc:  0.86343336 Val_loss =  0.4549747 Val_acc =  0.8418\n",
            "Iteration  1400 : Loss =  0.40578443  Acc:  0.86345 Val_loss =  0.45494887 Val_acc =  0.8418\n",
            "Iteration  1401 : Loss =  0.40574324  Acc:  0.8634833 Val_loss =  0.45492315 Val_acc =  0.8419\n",
            "Iteration  1402 : Loss =  0.40570214  Acc:  0.8635 Val_loss =  0.45489746 Val_acc =  0.8419\n",
            "Iteration  1403 : Loss =  0.40566105  Acc:  0.8635 Val_loss =  0.45487183 Val_acc =  0.8419\n",
            "Iteration  1404 : Loss =  0.40561998  Acc:  0.8634833 Val_loss =  0.4548462 Val_acc =  0.8419\n",
            "Iteration  1405 : Loss =  0.40557897  Acc:  0.86343336 Val_loss =  0.4548206 Val_acc =  0.8419\n",
            "Iteration  1406 : Loss =  0.40553802  Acc:  0.8634667 Val_loss =  0.45479503 Val_acc =  0.8419\n",
            "Iteration  1407 : Loss =  0.4054971  Acc:  0.8634667 Val_loss =  0.45476952 Val_acc =  0.8419\n",
            "Iteration  1408 : Loss =  0.4054562  Acc:  0.8635 Val_loss =  0.45474404 Val_acc =  0.8419\n",
            "Iteration  1409 : Loss =  0.40541533  Acc:  0.8635333 Val_loss =  0.4547186 Val_acc =  0.8419\n",
            "Iteration  1410 : Loss =  0.40537456  Acc:  0.86355 Val_loss =  0.45469326 Val_acc =  0.8419\n",
            "Iteration  1411 : Loss =  0.4053338  Acc:  0.86355 Val_loss =  0.45466787 Val_acc =  0.8419\n",
            "Iteration  1412 : Loss =  0.40529308  Acc:  0.86355 Val_loss =  0.45464256 Val_acc =  0.8419\n",
            "Iteration  1413 : Loss =  0.40525237  Acc:  0.8635833 Val_loss =  0.4546173 Val_acc =  0.8419\n",
            "Iteration  1414 : Loss =  0.40521172  Acc:  0.8635833 Val_loss =  0.454592 Val_acc =  0.8419\n",
            "Iteration  1415 : Loss =  0.40517116  Acc:  0.8635833 Val_loss =  0.4545668 Val_acc =  0.8419\n",
            "Iteration  1416 : Loss =  0.4051306  Acc:  0.8635833 Val_loss =  0.4545416 Val_acc =  0.8419\n",
            "Iteration  1417 : Loss =  0.40509003  Acc:  0.8635833 Val_loss =  0.45451644 Val_acc =  0.8419\n",
            "Iteration  1418 : Loss =  0.40504956  Acc:  0.8636 Val_loss =  0.4544914 Val_acc =  0.8419\n",
            "Iteration  1419 : Loss =  0.40500912  Acc:  0.8636 Val_loss =  0.4544663 Val_acc =  0.8419\n",
            "Iteration  1420 : Loss =  0.40496874  Acc:  0.86361665 Val_loss =  0.4544413 Val_acc =  0.8419\n",
            "Iteration  1421 : Loss =  0.40492836  Acc:  0.86363333 Val_loss =  0.4544163 Val_acc =  0.8419\n",
            "Iteration  1422 : Loss =  0.40488803  Acc:  0.86365 Val_loss =  0.45439136 Val_acc =  0.8419\n",
            "Iteration  1423 : Loss =  0.4048478  Acc:  0.86366665 Val_loss =  0.45436645 Val_acc =  0.8418\n",
            "Iteration  1424 : Loss =  0.4048075  Acc:  0.8637 Val_loss =  0.45434156 Val_acc =  0.8418\n",
            "Iteration  1425 : Loss =  0.4047673  Acc:  0.86368334 Val_loss =  0.4543167 Val_acc =  0.8418\n",
            "Iteration  1426 : Loss =  0.40472716  Acc:  0.86366665 Val_loss =  0.45429188 Val_acc =  0.8418\n",
            "Iteration  1427 : Loss =  0.40468702  Acc:  0.86366665 Val_loss =  0.45426714 Val_acc =  0.8419\n",
            "Iteration  1428 : Loss =  0.40464693  Acc:  0.86365 Val_loss =  0.45424238 Val_acc =  0.8419\n",
            "Iteration  1429 : Loss =  0.4046069  Acc:  0.86363333 Val_loss =  0.45421767 Val_acc =  0.8419\n",
            "Iteration  1430 : Loss =  0.4045669  Acc:  0.86366665 Val_loss =  0.45419303 Val_acc =  0.842\n",
            "Iteration  1431 : Loss =  0.40452695  Acc:  0.86366665 Val_loss =  0.4541684 Val_acc =  0.842\n",
            "Iteration  1432 : Loss =  0.404487  Acc:  0.86366665 Val_loss =  0.45414385 Val_acc =  0.842\n",
            "Iteration  1433 : Loss =  0.40444714  Acc:  0.86366665 Val_loss =  0.45411924 Val_acc =  0.842\n",
            "Iteration  1434 : Loss =  0.4044073  Acc:  0.86365 Val_loss =  0.45409474 Val_acc =  0.842\n",
            "Iteration  1435 : Loss =  0.40436745  Acc:  0.86361665 Val_loss =  0.4540702 Val_acc =  0.8419\n",
            "Iteration  1436 : Loss =  0.4043277  Acc:  0.8636 Val_loss =  0.4540458 Val_acc =  0.8419\n",
            "Iteration  1437 : Loss =  0.40428796  Acc:  0.86361665 Val_loss =  0.45402142 Val_acc =  0.8421\n",
            "Iteration  1438 : Loss =  0.40424824  Acc:  0.86363333 Val_loss =  0.45399708 Val_acc =  0.8421\n",
            "Iteration  1439 : Loss =  0.4042086  Acc:  0.86363333 Val_loss =  0.4539727 Val_acc =  0.8421\n",
            "Iteration  1440 : Loss =  0.40416896  Acc:  0.86368334 Val_loss =  0.45394838 Val_acc =  0.8421\n",
            "Iteration  1441 : Loss =  0.40412942  Acc:  0.8637 Val_loss =  0.45392412 Val_acc =  0.8421\n",
            "Iteration  1442 : Loss =  0.4040899  Acc:  0.86373335 Val_loss =  0.4538999 Val_acc =  0.8421\n",
            "Iteration  1443 : Loss =  0.40405032  Acc:  0.86371666 Val_loss =  0.4538757 Val_acc =  0.8421\n",
            "Iteration  1444 : Loss =  0.40401095  Acc:  0.86371666 Val_loss =  0.45385152 Val_acc =  0.8421\n",
            "Iteration  1445 : Loss =  0.4039715  Acc:  0.86371666 Val_loss =  0.45382738 Val_acc =  0.8421\n",
            "Iteration  1446 : Loss =  0.4039321  Acc:  0.86373335 Val_loss =  0.45380333 Val_acc =  0.8421\n",
            "Iteration  1447 : Loss =  0.40389276  Acc:  0.86371666 Val_loss =  0.4537793 Val_acc =  0.8421\n",
            "Iteration  1448 : Loss =  0.40385342  Acc:  0.86378336 Val_loss =  0.45375517 Val_acc =  0.8422\n",
            "Iteration  1449 : Loss =  0.40381417  Acc:  0.8638167 Val_loss =  0.45373124 Val_acc =  0.8422\n",
            "Iteration  1450 : Loss =  0.40377495  Acc:  0.8638 Val_loss =  0.45370728 Val_acc =  0.8422\n",
            "Iteration  1451 : Loss =  0.40373576  Acc:  0.8638 Val_loss =  0.4536834 Val_acc =  0.8422\n",
            "Iteration  1452 : Loss =  0.40369654  Acc:  0.86378336 Val_loss =  0.45365947 Val_acc =  0.8422\n",
            "Iteration  1453 : Loss =  0.40365744  Acc:  0.8638167 Val_loss =  0.45363563 Val_acc =  0.8422\n",
            "Iteration  1454 : Loss =  0.4036184  Acc:  0.8638333 Val_loss =  0.45361182 Val_acc =  0.8422\n",
            "Iteration  1455 : Loss =  0.4035793  Acc:  0.8638167 Val_loss =  0.45358804 Val_acc =  0.8422\n",
            "Iteration  1456 : Loss =  0.4035403  Acc:  0.8638333 Val_loss =  0.45356432 Val_acc =  0.8422\n",
            "Iteration  1457 : Loss =  0.40350133  Acc:  0.8638333 Val_loss =  0.45354062 Val_acc =  0.8422\n",
            "Iteration  1458 : Loss =  0.40346244  Acc:  0.8638333 Val_loss =  0.45351693 Val_acc =  0.8422\n",
            "Iteration  1459 : Loss =  0.4034235  Acc:  0.86385 Val_loss =  0.45349327 Val_acc =  0.8422\n",
            "Iteration  1460 : Loss =  0.40338463  Acc:  0.8638833 Val_loss =  0.45346972 Val_acc =  0.8423\n",
            "Iteration  1461 : Loss =  0.40334582  Acc:  0.8638833 Val_loss =  0.45344615 Val_acc =  0.8423\n",
            "Iteration  1462 : Loss =  0.40330705  Acc:  0.8638833 Val_loss =  0.4534226 Val_acc =  0.8424\n",
            "Iteration  1463 : Loss =  0.40326834  Acc:  0.8638833 Val_loss =  0.45339906 Val_acc =  0.8424\n",
            "Iteration  1464 : Loss =  0.40322962  Acc:  0.8638833 Val_loss =  0.45337558 Val_acc =  0.8424\n",
            "Iteration  1465 : Loss =  0.40319094  Acc:  0.8639333 Val_loss =  0.45335218 Val_acc =  0.8424\n",
            "Iteration  1466 : Loss =  0.4031523  Acc:  0.8639333 Val_loss =  0.45332876 Val_acc =  0.8424\n",
            "Iteration  1467 : Loss =  0.40311366  Acc:  0.86395 Val_loss =  0.45330542 Val_acc =  0.8423\n",
            "Iteration  1468 : Loss =  0.40307513  Acc:  0.86395 Val_loss =  0.4532821 Val_acc =  0.8424\n",
            "Iteration  1469 : Loss =  0.4030366  Acc:  0.86396664 Val_loss =  0.45325878 Val_acc =  0.8424\n",
            "Iteration  1470 : Loss =  0.40299812  Acc:  0.86398333 Val_loss =  0.4532355 Val_acc =  0.8424\n",
            "Iteration  1471 : Loss =  0.40295967  Acc:  0.86403334 Val_loss =  0.4532123 Val_acc =  0.8424\n",
            "Iteration  1472 : Loss =  0.40292126  Acc:  0.86406666 Val_loss =  0.4531891 Val_acc =  0.8424\n",
            "Iteration  1473 : Loss =  0.40288287  Acc:  0.86408335 Val_loss =  0.45316598 Val_acc =  0.8424\n",
            "Iteration  1474 : Loss =  0.40284452  Acc:  0.86403334 Val_loss =  0.45314276 Val_acc =  0.8424\n",
            "Iteration  1475 : Loss =  0.40280625  Acc:  0.86406666 Val_loss =  0.45311972 Val_acc =  0.8424\n",
            "Iteration  1476 : Loss =  0.40276796  Acc:  0.86408335 Val_loss =  0.4530967 Val_acc =  0.8424\n",
            "Iteration  1477 : Loss =  0.40272972  Acc:  0.8641 Val_loss =  0.45307362 Val_acc =  0.8424\n",
            "Iteration  1478 : Loss =  0.40269154  Acc:  0.86408335 Val_loss =  0.45305064 Val_acc =  0.8424\n",
            "Iteration  1479 : Loss =  0.4026534  Acc:  0.86411667 Val_loss =  0.45302764 Val_acc =  0.8424\n",
            "Iteration  1480 : Loss =  0.40261525  Acc:  0.86413336 Val_loss =  0.45300475 Val_acc =  0.8424\n",
            "Iteration  1481 : Loss =  0.40257716  Acc:  0.8641 Val_loss =  0.45298183 Val_acc =  0.8424\n",
            "Iteration  1482 : Loss =  0.40253913  Acc:  0.86411667 Val_loss =  0.45295897 Val_acc =  0.8424\n",
            "Iteration  1483 : Loss =  0.40250108  Acc:  0.86415 Val_loss =  0.45293614 Val_acc =  0.8424\n",
            "Iteration  1484 : Loss =  0.40246308  Acc:  0.8641667 Val_loss =  0.45291337 Val_acc =  0.8423\n",
            "Iteration  1485 : Loss =  0.40242517  Acc:  0.86415 Val_loss =  0.45289057 Val_acc =  0.8423\n",
            "Iteration  1486 : Loss =  0.40238723  Acc:  0.8641667 Val_loss =  0.45286787 Val_acc =  0.8423\n",
            "Iteration  1487 : Loss =  0.40234935  Acc:  0.86415 Val_loss =  0.45284516 Val_acc =  0.8423\n",
            "Iteration  1488 : Loss =  0.40231153  Acc:  0.86413336 Val_loss =  0.4528225 Val_acc =  0.8423\n",
            "Iteration  1489 : Loss =  0.40227374  Acc:  0.86415 Val_loss =  0.45279992 Val_acc =  0.8427\n",
            "Iteration  1490 : Loss =  0.40223593  Acc:  0.8641667 Val_loss =  0.45277724 Val_acc =  0.8427\n",
            "Iteration  1491 : Loss =  0.4021982  Acc:  0.8642 Val_loss =  0.45275468 Val_acc =  0.8427\n",
            "Iteration  1492 : Loss =  0.40216056  Acc:  0.8642167 Val_loss =  0.45273218 Val_acc =  0.8428\n",
            "Iteration  1493 : Loss =  0.40212286  Acc:  0.8642167 Val_loss =  0.45270967 Val_acc =  0.8429\n",
            "Iteration  1494 : Loss =  0.40208524  Acc:  0.8642167 Val_loss =  0.4526872 Val_acc =  0.8429\n",
            "Iteration  1495 : Loss =  0.40204766  Acc:  0.86425 Val_loss =  0.4526648 Val_acc =  0.8429\n",
            "Iteration  1496 : Loss =  0.40201008  Acc:  0.8642833 Val_loss =  0.45264238 Val_acc =  0.8429\n",
            "Iteration  1497 : Loss =  0.4019726  Acc:  0.8642833 Val_loss =  0.45262003 Val_acc =  0.8429\n",
            "Iteration  1498 : Loss =  0.4019351  Acc:  0.8642833 Val_loss =  0.45259765 Val_acc =  0.843\n",
            "Iteration  1499 : Loss =  0.4018976  Acc:  0.8643 Val_loss =  0.4525754 Val_acc =  0.843\n",
            "Iteration  1500 : Loss =  0.4018602  Acc:  0.8643 Val_loss =  0.45255306 Val_acc =  0.843\n",
            "Iteration  1501 : Loss =  0.4018228  Acc:  0.86435 Val_loss =  0.45253086 Val_acc =  0.8431\n",
            "Iteration  1502 : Loss =  0.4017855  Acc:  0.86435 Val_loss =  0.4525086 Val_acc =  0.8431\n",
            "Iteration  1503 : Loss =  0.40174818  Acc:  0.86438334 Val_loss =  0.45248643 Val_acc =  0.8432\n",
            "Iteration  1504 : Loss =  0.40171087  Acc:  0.86441666 Val_loss =  0.4524643 Val_acc =  0.8432\n",
            "Iteration  1505 : Loss =  0.40167364  Acc:  0.86438334 Val_loss =  0.4524422 Val_acc =  0.8431\n",
            "Iteration  1506 : Loss =  0.40163645  Acc:  0.8644 Val_loss =  0.45242012 Val_acc =  0.8431\n",
            "Iteration  1507 : Loss =  0.4015993  Acc:  0.8644 Val_loss =  0.45239806 Val_acc =  0.8431\n",
            "Iteration  1508 : Loss =  0.4015621  Acc:  0.86441666 Val_loss =  0.45237607 Val_acc =  0.8431\n",
            "Iteration  1509 : Loss =  0.401525  Acc:  0.8644 Val_loss =  0.45235404 Val_acc =  0.8432\n",
            "Iteration  1510 : Loss =  0.40148795  Acc:  0.86445 Val_loss =  0.45233214 Val_acc =  0.8432\n",
            "Iteration  1511 : Loss =  0.4014509  Acc:  0.86446667 Val_loss =  0.4523102 Val_acc =  0.8433\n",
            "Iteration  1512 : Loss =  0.4014139  Acc:  0.86446667 Val_loss =  0.45228833 Val_acc =  0.8433\n",
            "Iteration  1513 : Loss =  0.40137696  Acc:  0.86446667 Val_loss =  0.45226645 Val_acc =  0.8433\n",
            "Iteration  1514 : Loss =  0.40133998  Acc:  0.86448336 Val_loss =  0.45224464 Val_acc =  0.8433\n",
            "Iteration  1515 : Loss =  0.4013031  Acc:  0.86448336 Val_loss =  0.45222285 Val_acc =  0.8433\n",
            "Iteration  1516 : Loss =  0.40126625  Acc:  0.8645 Val_loss =  0.45220107 Val_acc =  0.8433\n",
            "Iteration  1517 : Loss =  0.40122938  Acc:  0.8645333 Val_loss =  0.45217928 Val_acc =  0.8433\n",
            "Iteration  1518 : Loss =  0.4011926  Acc:  0.86455 Val_loss =  0.45215762 Val_acc =  0.8434\n",
            "Iteration  1519 : Loss =  0.40115583  Acc:  0.8645667 Val_loss =  0.45213595 Val_acc =  0.8434\n",
            "Iteration  1520 : Loss =  0.4011191  Acc:  0.8646 Val_loss =  0.45211434 Val_acc =  0.8434\n",
            "Iteration  1521 : Loss =  0.4010824  Acc:  0.8646333 Val_loss =  0.45209274 Val_acc =  0.8435\n",
            "Iteration  1522 : Loss =  0.40104577  Acc:  0.86465 Val_loss =  0.4520711 Val_acc =  0.8435\n",
            "Iteration  1523 : Loss =  0.4010091  Acc:  0.8646333 Val_loss =  0.45204955 Val_acc =  0.8435\n",
            "Iteration  1524 : Loss =  0.40097252  Acc:  0.8646167 Val_loss =  0.45202807 Val_acc =  0.8434\n",
            "Iteration  1525 : Loss =  0.40093598  Acc:  0.8646167 Val_loss =  0.45200658 Val_acc =  0.8434\n",
            "Iteration  1526 : Loss =  0.4008994  Acc:  0.8646167 Val_loss =  0.45198515 Val_acc =  0.8435\n",
            "Iteration  1527 : Loss =  0.40086293  Acc:  0.8646167 Val_loss =  0.45196372 Val_acc =  0.8436\n",
            "Iteration  1528 : Loss =  0.40082642  Acc:  0.8646333 Val_loss =  0.45194232 Val_acc =  0.8437\n",
            "Iteration  1529 : Loss =  0.40079004  Acc:  0.8646333 Val_loss =  0.451921 Val_acc =  0.8437\n",
            "Iteration  1530 : Loss =  0.40075365  Acc:  0.86465 Val_loss =  0.45189962 Val_acc =  0.8437\n",
            "Iteration  1531 : Loss =  0.4007173  Acc:  0.86466664 Val_loss =  0.4518783 Val_acc =  0.8437\n",
            "Iteration  1532 : Loss =  0.40068096  Acc:  0.86465 Val_loss =  0.45185703 Val_acc =  0.8438\n",
            "Iteration  1533 : Loss =  0.40064466  Acc:  0.86466664 Val_loss =  0.45183584 Val_acc =  0.8438\n",
            "Iteration  1534 : Loss =  0.4006084  Acc:  0.86468333 Val_loss =  0.4518146 Val_acc =  0.8439\n",
            "Iteration  1535 : Loss =  0.40057212  Acc:  0.86471665 Val_loss =  0.45179346 Val_acc =  0.8439\n",
            "Iteration  1536 : Loss =  0.40053597  Acc:  0.86473334 Val_loss =  0.4517723 Val_acc =  0.8439\n",
            "Iteration  1537 : Loss =  0.4004998  Acc:  0.86478335 Val_loss =  0.45175117 Val_acc =  0.8439\n",
            "Iteration  1538 : Loss =  0.40046367  Acc:  0.86478335 Val_loss =  0.45173007 Val_acc =  0.8439\n",
            "Iteration  1539 : Loss =  0.40042755  Acc:  0.86476666 Val_loss =  0.4517091 Val_acc =  0.8439\n",
            "Iteration  1540 : Loss =  0.40039146  Acc:  0.86478335 Val_loss =  0.451688 Val_acc =  0.8438\n",
            "Iteration  1541 : Loss =  0.40035546  Acc:  0.86478335 Val_loss =  0.45166698 Val_acc =  0.8438\n",
            "Iteration  1542 : Loss =  0.40031943  Acc:  0.86481667 Val_loss =  0.45164606 Val_acc =  0.8438\n",
            "Iteration  1543 : Loss =  0.40028346  Acc:  0.8648 Val_loss =  0.45162514 Val_acc =  0.8438\n",
            "Iteration  1544 : Loss =  0.4002475  Acc:  0.8648 Val_loss =  0.4516042 Val_acc =  0.8438\n",
            "Iteration  1545 : Loss =  0.40021166  Acc:  0.86481667 Val_loss =  0.4515833 Val_acc =  0.8438\n",
            "Iteration  1546 : Loss =  0.40017572  Acc:  0.86485 Val_loss =  0.4515625 Val_acc =  0.8437\n",
            "Iteration  1547 : Loss =  0.4001399  Acc:  0.86485 Val_loss =  0.4515417 Val_acc =  0.8437\n",
            "Iteration  1548 : Loss =  0.4001041  Acc:  0.8648833 Val_loss =  0.45152086 Val_acc =  0.8437\n",
            "Iteration  1549 : Loss =  0.4000683  Acc:  0.8648833 Val_loss =  0.45150015 Val_acc =  0.8437\n",
            "Iteration  1550 : Loss =  0.40003258  Acc:  0.8648833 Val_loss =  0.4514794 Val_acc =  0.8437\n",
            "Iteration  1551 : Loss =  0.3999969  Acc:  0.8649 Val_loss =  0.4514587 Val_acc =  0.8437\n",
            "Iteration  1552 : Loss =  0.3999612  Acc:  0.8648833 Val_loss =  0.45143804 Val_acc =  0.8437\n",
            "Iteration  1553 : Loss =  0.39992553  Acc:  0.8648667 Val_loss =  0.4514174 Val_acc =  0.8437\n",
            "Iteration  1554 : Loss =  0.39988992  Acc:  0.8648833 Val_loss =  0.45139682 Val_acc =  0.8438\n",
            "Iteration  1555 : Loss =  0.39985436  Acc:  0.8649167 Val_loss =  0.45137623 Val_acc =  0.8438\n",
            "Iteration  1556 : Loss =  0.39981878  Acc:  0.8649667 Val_loss =  0.45135567 Val_acc =  0.8438\n",
            "Iteration  1557 : Loss =  0.39978325  Acc:  0.86501664 Val_loss =  0.45133516 Val_acc =  0.8438\n",
            "Iteration  1558 : Loss =  0.3997478  Acc:  0.86501664 Val_loss =  0.45131466 Val_acc =  0.8438\n",
            "Iteration  1559 : Loss =  0.39971232  Acc:  0.86505 Val_loss =  0.45129424 Val_acc =  0.8438\n",
            "Iteration  1560 : Loss =  0.3996769  Acc:  0.86505 Val_loss =  0.45127377 Val_acc =  0.8438\n",
            "Iteration  1561 : Loss =  0.39964154  Acc:  0.86505 Val_loss =  0.45125335 Val_acc =  0.8438\n",
            "Iteration  1562 : Loss =  0.39960614  Acc:  0.86505 Val_loss =  0.451233 Val_acc =  0.8438\n",
            "Iteration  1563 : Loss =  0.39957082  Acc:  0.8650333 Val_loss =  0.45121264 Val_acc =  0.8438\n",
            "Iteration  1564 : Loss =  0.3995355  Acc:  0.86501664 Val_loss =  0.45119238 Val_acc =  0.8438\n",
            "Iteration  1565 : Loss =  0.39950025  Acc:  0.8650333 Val_loss =  0.45117208 Val_acc =  0.8438\n",
            "Iteration  1566 : Loss =  0.399465  Acc:  0.86511666 Val_loss =  0.45115185 Val_acc =  0.8437\n",
            "Iteration  1567 : Loss =  0.39942983  Acc:  0.86511666 Val_loss =  0.45113158 Val_acc =  0.8437\n",
            "Iteration  1568 : Loss =  0.39939463  Acc:  0.86513335 Val_loss =  0.45111138 Val_acc =  0.8437\n",
            "Iteration  1569 : Loss =  0.3993595  Acc:  0.86513335 Val_loss =  0.4510912 Val_acc =  0.8437\n",
            "Iteration  1570 : Loss =  0.39932436  Acc:  0.86515 Val_loss =  0.45107108 Val_acc =  0.8437\n",
            "Iteration  1571 : Loss =  0.3992893  Acc:  0.86515 Val_loss =  0.45105097 Val_acc =  0.8437\n",
            "Iteration  1572 : Loss =  0.39925423  Acc:  0.86515 Val_loss =  0.45103085 Val_acc =  0.8437\n",
            "Iteration  1573 : Loss =  0.39921924  Acc:  0.86518335 Val_loss =  0.45101085 Val_acc =  0.8438\n",
            "Iteration  1574 : Loss =  0.39918426  Acc:  0.8652 Val_loss =  0.45099083 Val_acc =  0.8438\n",
            "Iteration  1575 : Loss =  0.3991493  Acc:  0.8652167 Val_loss =  0.4509708 Val_acc =  0.8438\n",
            "Iteration  1576 : Loss =  0.39911437  Acc:  0.86523336 Val_loss =  0.4509509 Val_acc =  0.8438\n",
            "Iteration  1577 : Loss =  0.39907947  Acc:  0.86523336 Val_loss =  0.4509309 Val_acc =  0.8438\n",
            "Iteration  1578 : Loss =  0.3990446  Acc:  0.8652167 Val_loss =  0.450911 Val_acc =  0.8439\n",
            "Iteration  1579 : Loss =  0.39900976  Acc:  0.8652167 Val_loss =  0.4508911 Val_acc =  0.8439\n",
            "Iteration  1580 : Loss =  0.39897496  Acc:  0.8652167 Val_loss =  0.45087123 Val_acc =  0.8439\n",
            "Iteration  1581 : Loss =  0.3989402  Acc:  0.8652167 Val_loss =  0.4508514 Val_acc =  0.8439\n",
            "Iteration  1582 : Loss =  0.39890543  Acc:  0.86525 Val_loss =  0.45083165 Val_acc =  0.8439\n",
            "Iteration  1583 : Loss =  0.39887077  Acc:  0.8652667 Val_loss =  0.45081186 Val_acc =  0.8439\n",
            "Iteration  1584 : Loss =  0.39883608  Acc:  0.8652833 Val_loss =  0.45079213 Val_acc =  0.8439\n",
            "Iteration  1585 : Loss =  0.39880145  Acc:  0.8653 Val_loss =  0.4507724 Val_acc =  0.8439\n",
            "Iteration  1586 : Loss =  0.3987668  Acc:  0.8653167 Val_loss =  0.45075274 Val_acc =  0.8439\n",
            "Iteration  1587 : Loss =  0.3987322  Acc:  0.8653333 Val_loss =  0.4507331 Val_acc =  0.8439\n",
            "Iteration  1588 : Loss =  0.39869764  Acc:  0.8653167 Val_loss =  0.4507135 Val_acc =  0.8439\n",
            "Iteration  1589 : Loss =  0.39866307  Acc:  0.8653167 Val_loss =  0.45069385 Val_acc =  0.8439\n",
            "Iteration  1590 : Loss =  0.3986286  Acc:  0.8653167 Val_loss =  0.45067433 Val_acc =  0.8439\n",
            "Iteration  1591 : Loss =  0.39859414  Acc:  0.8653167 Val_loss =  0.45065475 Val_acc =  0.8439\n",
            "Iteration  1592 : Loss =  0.3985597  Acc:  0.86535 Val_loss =  0.4506352 Val_acc =  0.8439\n",
            "Iteration  1593 : Loss =  0.3985253  Acc:  0.86535 Val_loss =  0.45061573 Val_acc =  0.8439\n",
            "Iteration  1594 : Loss =  0.39849088  Acc:  0.8653167 Val_loss =  0.45059624 Val_acc =  0.8439\n",
            "Iteration  1595 : Loss =  0.39845657  Acc:  0.8653333 Val_loss =  0.45057684 Val_acc =  0.8439\n",
            "Iteration  1596 : Loss =  0.39842224  Acc:  0.8653167 Val_loss =  0.4505574 Val_acc =  0.8439\n",
            "Iteration  1597 : Loss =  0.39838797  Acc:  0.8653 Val_loss =  0.45053804 Val_acc =  0.8439\n",
            "Iteration  1598 : Loss =  0.39835373  Acc:  0.8653167 Val_loss =  0.4505187 Val_acc =  0.8439\n",
            "Iteration  1599 : Loss =  0.39831945  Acc:  0.86536664 Val_loss =  0.45049942 Val_acc =  0.8439\n",
            "Iteration  1600 : Loss =  0.3982852  Acc:  0.86541665 Val_loss =  0.45048007 Val_acc =  0.8439\n",
            "Iteration  1601 : Loss =  0.39825112  Acc:  0.86546665 Val_loss =  0.45046085 Val_acc =  0.8439\n",
            "Iteration  1602 : Loss =  0.39821693  Acc:  0.86546665 Val_loss =  0.4504416 Val_acc =  0.8438\n",
            "Iteration  1603 : Loss =  0.3981828  Acc:  0.86551666 Val_loss =  0.45042238 Val_acc =  0.8438\n",
            "Iteration  1604 : Loss =  0.39814878  Acc:  0.86551666 Val_loss =  0.45040318 Val_acc =  0.8438\n",
            "Iteration  1605 : Loss =  0.3981147  Acc:  0.86551666 Val_loss =  0.45038408 Val_acc =  0.8438\n",
            "Iteration  1606 : Loss =  0.39808068  Acc:  0.86551666 Val_loss =  0.4503649 Val_acc =  0.8438\n",
            "Iteration  1607 : Loss =  0.39804667  Acc:  0.86553335 Val_loss =  0.4503458 Val_acc =  0.8438\n",
            "Iteration  1608 : Loss =  0.3980127  Acc:  0.86551666 Val_loss =  0.4503267 Val_acc =  0.8439\n",
            "Iteration  1609 : Loss =  0.39797878  Acc:  0.86551666 Val_loss =  0.45030773 Val_acc =  0.844\n",
            "Iteration  1610 : Loss =  0.3979449  Acc:  0.86548334 Val_loss =  0.45028868 Val_acc =  0.844\n",
            "Iteration  1611 : Loss =  0.397911  Acc:  0.86546665 Val_loss =  0.45026964 Val_acc =  0.844\n",
            "Iteration  1612 : Loss =  0.39787716  Acc:  0.86548334 Val_loss =  0.4502507 Val_acc =  0.844\n",
            "Iteration  1613 : Loss =  0.39784333  Acc:  0.8655 Val_loss =  0.45023173 Val_acc =  0.8439\n",
            "Iteration  1614 : Loss =  0.39780957  Acc:  0.86553335 Val_loss =  0.45021284 Val_acc =  0.8439\n",
            "Iteration  1615 : Loss =  0.39777577  Acc:  0.86551666 Val_loss =  0.450194 Val_acc =  0.8439\n",
            "Iteration  1616 : Loss =  0.39774206  Acc:  0.8655 Val_loss =  0.4501751 Val_acc =  0.8439\n",
            "Iteration  1617 : Loss =  0.39770833  Acc:  0.86548334 Val_loss =  0.45015624 Val_acc =  0.8439\n",
            "Iteration  1618 : Loss =  0.39767468  Acc:  0.86548334 Val_loss =  0.45013744 Val_acc =  0.8439\n",
            "Iteration  1619 : Loss =  0.397641  Acc:  0.8655 Val_loss =  0.45011866 Val_acc =  0.844\n",
            "Iteration  1620 : Loss =  0.39760742  Acc:  0.86548334 Val_loss =  0.45009995 Val_acc =  0.844\n",
            "Iteration  1621 : Loss =  0.39757383  Acc:  0.86548334 Val_loss =  0.4500812 Val_acc =  0.8441\n",
            "Iteration  1622 : Loss =  0.39754027  Acc:  0.86548334 Val_loss =  0.4500625 Val_acc =  0.844\n",
            "Iteration  1623 : Loss =  0.39750674  Acc:  0.86548334 Val_loss =  0.45004386 Val_acc =  0.844\n",
            "Iteration  1624 : Loss =  0.39747325  Acc:  0.86546665 Val_loss =  0.4500252 Val_acc =  0.844\n",
            "Iteration  1625 : Loss =  0.39743978  Acc:  0.86553335 Val_loss =  0.45000654 Val_acc =  0.844\n",
            "Iteration  1626 : Loss =  0.3974063  Acc:  0.86553335 Val_loss =  0.44998798 Val_acc =  0.8439\n",
            "Iteration  1627 : Loss =  0.39737293  Acc:  0.8655 Val_loss =  0.44996944 Val_acc =  0.844\n",
            "Iteration  1628 : Loss =  0.39733952  Acc:  0.86548334 Val_loss =  0.44995087 Val_acc =  0.844\n",
            "Iteration  1629 : Loss =  0.39730617  Acc:  0.86555 Val_loss =  0.44993237 Val_acc =  0.8439\n",
            "Iteration  1630 : Loss =  0.39727286  Acc:  0.8655667 Val_loss =  0.44991386 Val_acc =  0.8439\n",
            "Iteration  1631 : Loss =  0.3972395  Acc:  0.86558336 Val_loss =  0.4498954 Val_acc =  0.8439\n",
            "Iteration  1632 : Loss =  0.39720625  Acc:  0.8655667 Val_loss =  0.44987696 Val_acc =  0.8439\n",
            "Iteration  1633 : Loss =  0.39717302  Acc:  0.8656 Val_loss =  0.4498586 Val_acc =  0.8439\n",
            "Iteration  1634 : Loss =  0.3971398  Acc:  0.8656167 Val_loss =  0.4498402 Val_acc =  0.8439\n",
            "Iteration  1635 : Loss =  0.39710662  Acc:  0.8656167 Val_loss =  0.4498219 Val_acc =  0.8439\n",
            "Iteration  1636 : Loss =  0.39707345  Acc:  0.8656 Val_loss =  0.4498035 Val_acc =  0.8439\n",
            "Iteration  1637 : Loss =  0.3970403  Acc:  0.86558336 Val_loss =  0.4497852 Val_acc =  0.8439\n",
            "Iteration  1638 : Loss =  0.3970072  Acc:  0.86558336 Val_loss =  0.44976693 Val_acc =  0.8439\n",
            "Iteration  1639 : Loss =  0.39697412  Acc:  0.8656167 Val_loss =  0.4497487 Val_acc =  0.8439\n",
            "Iteration  1640 : Loss =  0.3969411  Acc:  0.8656667 Val_loss =  0.44973046 Val_acc =  0.844\n",
            "Iteration  1641 : Loss =  0.39690807  Acc:  0.8656333 Val_loss =  0.44971225 Val_acc =  0.8439\n",
            "Iteration  1642 : Loss =  0.39687505  Acc:  0.86565 Val_loss =  0.4496941 Val_acc =  0.8439\n",
            "Iteration  1643 : Loss =  0.3968421  Acc:  0.8656833 Val_loss =  0.44967592 Val_acc =  0.844\n",
            "Iteration  1644 : Loss =  0.3968092  Acc:  0.8656833 Val_loss =  0.4496578 Val_acc =  0.844\n",
            "Iteration  1645 : Loss =  0.39677623  Acc:  0.8657167 Val_loss =  0.44963974 Val_acc =  0.8441\n",
            "Iteration  1646 : Loss =  0.3967434  Acc:  0.8657333 Val_loss =  0.44962162 Val_acc =  0.8441\n",
            "Iteration  1647 : Loss =  0.39671052  Acc:  0.86575 Val_loss =  0.44960356 Val_acc =  0.8441\n",
            "Iteration  1648 : Loss =  0.39667767  Acc:  0.8657333 Val_loss =  0.4495856 Val_acc =  0.8441\n",
            "Iteration  1649 : Loss =  0.3966449  Acc:  0.8657333 Val_loss =  0.4495676 Val_acc =  0.8441\n",
            "Iteration  1650 : Loss =  0.3966121  Acc:  0.86575 Val_loss =  0.44954962 Val_acc =  0.8441\n",
            "Iteration  1651 : Loss =  0.39657936  Acc:  0.8657333 Val_loss =  0.4495317 Val_acc =  0.8441\n",
            "Iteration  1652 : Loss =  0.3965467  Acc:  0.86575 Val_loss =  0.44951376 Val_acc =  0.8441\n",
            "Iteration  1653 : Loss =  0.39651397  Acc:  0.86581665 Val_loss =  0.4494959 Val_acc =  0.8441\n",
            "Iteration  1654 : Loss =  0.3964813  Acc:  0.8658 Val_loss =  0.44947803 Val_acc =  0.8441\n",
            "Iteration  1655 : Loss =  0.39644867  Acc:  0.8658 Val_loss =  0.44946015 Val_acc =  0.844\n",
            "Iteration  1656 : Loss =  0.39641604  Acc:  0.86585 Val_loss =  0.4494424 Val_acc =  0.844\n",
            "Iteration  1657 : Loss =  0.3963835  Acc:  0.86585 Val_loss =  0.44942456 Val_acc =  0.844\n",
            "Iteration  1658 : Loss =  0.39635092  Acc:  0.86585 Val_loss =  0.44940677 Val_acc =  0.844\n",
            "Iteration  1659 : Loss =  0.3963184  Acc:  0.86585 Val_loss =  0.44938907 Val_acc =  0.844\n",
            "Iteration  1660 : Loss =  0.3962859  Acc:  0.86586666 Val_loss =  0.4493714 Val_acc =  0.844\n",
            "Iteration  1661 : Loss =  0.39625344  Acc:  0.86586666 Val_loss =  0.44935367 Val_acc =  0.844\n",
            "Iteration  1662 : Loss =  0.39622095  Acc:  0.86588335 Val_loss =  0.449336 Val_acc =  0.844\n",
            "Iteration  1663 : Loss =  0.39618853  Acc:  0.86591667 Val_loss =  0.44931835 Val_acc =  0.844\n",
            "Iteration  1664 : Loss =  0.3961562  Acc:  0.8659 Val_loss =  0.44930074 Val_acc =  0.844\n",
            "Iteration  1665 : Loss =  0.39612383  Acc:  0.86593336 Val_loss =  0.44928315 Val_acc =  0.844\n",
            "Iteration  1666 : Loss =  0.39609146  Acc:  0.866 Val_loss =  0.44926563 Val_acc =  0.844\n",
            "Iteration  1667 : Loss =  0.3960592  Acc:  0.8660333 Val_loss =  0.44924805 Val_acc =  0.844\n",
            "Iteration  1668 : Loss =  0.39602688  Acc:  0.8660667 Val_loss =  0.44923055 Val_acc =  0.844\n",
            "Iteration  1669 : Loss =  0.39599463  Acc:  0.86605 Val_loss =  0.44921303 Val_acc =  0.844\n",
            "Iteration  1670 : Loss =  0.39596236  Acc:  0.86605 Val_loss =  0.4491956 Val_acc =  0.8441\n",
            "Iteration  1671 : Loss =  0.39593017  Acc:  0.86605 Val_loss =  0.44917813 Val_acc =  0.8442\n",
            "Iteration  1672 : Loss =  0.395898  Acc:  0.86605 Val_loss =  0.44916075 Val_acc =  0.8442\n",
            "Iteration  1673 : Loss =  0.39586586  Acc:  0.8660333 Val_loss =  0.44914335 Val_acc =  0.8442\n",
            "Iteration  1674 : Loss =  0.39583373  Acc:  0.8660333 Val_loss =  0.44912598 Val_acc =  0.8442\n",
            "Iteration  1675 : Loss =  0.39580163  Acc:  0.8660333 Val_loss =  0.44910863 Val_acc =  0.8443\n",
            "Iteration  1676 : Loss =  0.3957696  Acc:  0.8660333 Val_loss =  0.44909132 Val_acc =  0.8443\n",
            "Iteration  1677 : Loss =  0.3957375  Acc:  0.8660333 Val_loss =  0.44907403 Val_acc =  0.8443\n",
            "Iteration  1678 : Loss =  0.3957055  Acc:  0.8660333 Val_loss =  0.44905677 Val_acc =  0.8443\n",
            "Iteration  1679 : Loss =  0.3956735  Acc:  0.8660333 Val_loss =  0.44903955 Val_acc =  0.8443\n",
            "Iteration  1680 : Loss =  0.39564154  Acc:  0.8660667 Val_loss =  0.44902232 Val_acc =  0.8443\n",
            "Iteration  1681 : Loss =  0.39560965  Acc:  0.86605 Val_loss =  0.44900507 Val_acc =  0.8443\n",
            "Iteration  1682 : Loss =  0.3955777  Acc:  0.8660833 Val_loss =  0.448988 Val_acc =  0.8443\n",
            "Iteration  1683 : Loss =  0.3955458  Acc:  0.8661 Val_loss =  0.4489708 Val_acc =  0.8443\n",
            "Iteration  1684 : Loss =  0.39551395  Acc:  0.8661 Val_loss =  0.44895372 Val_acc =  0.8443\n",
            "Iteration  1685 : Loss =  0.39548212  Acc:  0.86611664 Val_loss =  0.4489366 Val_acc =  0.8443\n",
            "Iteration  1686 : Loss =  0.39545032  Acc:  0.8660833 Val_loss =  0.44891953 Val_acc =  0.8443\n",
            "Iteration  1687 : Loss =  0.39541855  Acc:  0.86611664 Val_loss =  0.4489025 Val_acc =  0.8443\n",
            "Iteration  1688 : Loss =  0.3953868  Acc:  0.86611664 Val_loss =  0.44888544 Val_acc =  0.8443\n",
            "Iteration  1689 : Loss =  0.39535505  Acc:  0.8661 Val_loss =  0.44886845 Val_acc =  0.8444\n",
            "Iteration  1690 : Loss =  0.39532334  Acc:  0.8661 Val_loss =  0.44885147 Val_acc =  0.8444\n",
            "Iteration  1691 : Loss =  0.39529166  Acc:  0.8661 Val_loss =  0.44883457 Val_acc =  0.8444\n",
            "Iteration  1692 : Loss =  0.39526004  Acc:  0.86611664 Val_loss =  0.44881764 Val_acc =  0.8444\n",
            "Iteration  1693 : Loss =  0.3952284  Acc:  0.86613333 Val_loss =  0.44880074 Val_acc =  0.8445\n",
            "Iteration  1694 : Loss =  0.39519677  Acc:  0.86613333 Val_loss =  0.44878384 Val_acc =  0.8445\n",
            "Iteration  1695 : Loss =  0.3951652  Acc:  0.86616665 Val_loss =  0.448767 Val_acc =  0.8445\n",
            "Iteration  1696 : Loss =  0.39513364  Acc:  0.86616665 Val_loss =  0.4487502 Val_acc =  0.8445\n",
            "Iteration  1697 : Loss =  0.39510214  Acc:  0.8662 Val_loss =  0.44873336 Val_acc =  0.8445\n",
            "Iteration  1698 : Loss =  0.39507064  Acc:  0.86618334 Val_loss =  0.44871655 Val_acc =  0.8445\n",
            "Iteration  1699 : Loss =  0.3950392  Acc:  0.86621666 Val_loss =  0.4486998 Val_acc =  0.8445\n",
            "Iteration  1700 : Loss =  0.39500773  Acc:  0.86621666 Val_loss =  0.44868305 Val_acc =  0.8445\n",
            "Iteration  1701 : Loss =  0.3949763  Acc:  0.86623335 Val_loss =  0.44866636 Val_acc =  0.8446\n",
            "Iteration  1702 : Loss =  0.39494488  Acc:  0.8662 Val_loss =  0.4486497 Val_acc =  0.8446\n",
            "Iteration  1703 : Loss =  0.39491355  Acc:  0.86618334 Val_loss =  0.44863302 Val_acc =  0.8446\n",
            "Iteration  1704 : Loss =  0.39488217  Acc:  0.86618334 Val_loss =  0.44861642 Val_acc =  0.8446\n",
            "Iteration  1705 : Loss =  0.39485085  Acc:  0.86618334 Val_loss =  0.4485997 Val_acc =  0.8446\n",
            "Iteration  1706 : Loss =  0.39481956  Acc:  0.86618334 Val_loss =  0.44858316 Val_acc =  0.8446\n",
            "Iteration  1707 : Loss =  0.3947883  Acc:  0.86618334 Val_loss =  0.44856662 Val_acc =  0.8446\n",
            "Iteration  1708 : Loss =  0.39475706  Acc:  0.86621666 Val_loss =  0.44855005 Val_acc =  0.8445\n",
            "Iteration  1709 : Loss =  0.39472586  Acc:  0.86621666 Val_loss =  0.4485335 Val_acc =  0.8446\n",
            "Iteration  1710 : Loss =  0.39469463  Acc:  0.86621666 Val_loss =  0.448517 Val_acc =  0.8447\n",
            "Iteration  1711 : Loss =  0.39466348  Acc:  0.86621666 Val_loss =  0.44850054 Val_acc =  0.8447\n",
            "Iteration  1712 : Loss =  0.39463237  Acc:  0.86621666 Val_loss =  0.4484841 Val_acc =  0.8448\n",
            "Iteration  1713 : Loss =  0.39460123  Acc:  0.86625 Val_loss =  0.44846767 Val_acc =  0.8446\n",
            "Iteration  1714 : Loss =  0.3945701  Acc:  0.86625 Val_loss =  0.44845128 Val_acc =  0.8447\n",
            "Iteration  1715 : Loss =  0.39453906  Acc:  0.86621666 Val_loss =  0.44843486 Val_acc =  0.8447\n",
            "Iteration  1716 : Loss =  0.394508  Acc:  0.86623335 Val_loss =  0.44841856 Val_acc =  0.8447\n",
            "Iteration  1717 : Loss =  0.394477  Acc:  0.86625 Val_loss =  0.4484022 Val_acc =  0.8448\n",
            "Iteration  1718 : Loss =  0.394446  Acc:  0.86626667 Val_loss =  0.44838583 Val_acc =  0.8447\n",
            "Iteration  1719 : Loss =  0.39441505  Acc:  0.86626667 Val_loss =  0.4483696 Val_acc =  0.8447\n",
            "Iteration  1720 : Loss =  0.3943841  Acc:  0.86623335 Val_loss =  0.44835332 Val_acc =  0.8447\n",
            "Iteration  1721 : Loss =  0.39435318  Acc:  0.86625 Val_loss =  0.44833705 Val_acc =  0.8447\n",
            "Iteration  1722 : Loss =  0.39432228  Acc:  0.86623335 Val_loss =  0.4483209 Val_acc =  0.8447\n",
            "Iteration  1723 : Loss =  0.3942914  Acc:  0.86625 Val_loss =  0.44830468 Val_acc =  0.8447\n",
            "Iteration  1724 : Loss =  0.39426056  Acc:  0.86621666 Val_loss =  0.44828853 Val_acc =  0.8447\n",
            "Iteration  1725 : Loss =  0.39422974  Acc:  0.86621666 Val_loss =  0.44827238 Val_acc =  0.8448\n",
            "Iteration  1726 : Loss =  0.39419895  Acc:  0.86623335 Val_loss =  0.44825625 Val_acc =  0.8447\n",
            "Iteration  1727 : Loss =  0.39416817  Acc:  0.86623335 Val_loss =  0.44824013 Val_acc =  0.8447\n",
            "Iteration  1728 : Loss =  0.39413744  Acc:  0.86621666 Val_loss =  0.44822404 Val_acc =  0.8447\n",
            "Iteration  1729 : Loss =  0.39410672  Acc:  0.86623335 Val_loss =  0.44820794 Val_acc =  0.8446\n",
            "Iteration  1730 : Loss =  0.39407602  Acc:  0.86626667 Val_loss =  0.44819188 Val_acc =  0.8446\n",
            "Iteration  1731 : Loss =  0.39404535  Acc:  0.86626667 Val_loss =  0.44817594 Val_acc =  0.8446\n",
            "Iteration  1732 : Loss =  0.3940147  Acc:  0.86626667 Val_loss =  0.44815996 Val_acc =  0.8445\n",
            "Iteration  1733 : Loss =  0.39398405  Acc:  0.86628336 Val_loss =  0.44814396 Val_acc =  0.8445\n",
            "Iteration  1734 : Loss =  0.39395344  Acc:  0.86628336 Val_loss =  0.448128 Val_acc =  0.8445\n",
            "Iteration  1735 : Loss =  0.3939229  Acc:  0.86628336 Val_loss =  0.4481121 Val_acc =  0.8445\n",
            "Iteration  1736 : Loss =  0.39389235  Acc:  0.86628336 Val_loss =  0.4480962 Val_acc =  0.8445\n",
            "Iteration  1737 : Loss =  0.39386177  Acc:  0.8663 Val_loss =  0.44808033 Val_acc =  0.8445\n",
            "Iteration  1738 : Loss =  0.39383128  Acc:  0.8663167 Val_loss =  0.44806445 Val_acc =  0.8445\n",
            "Iteration  1739 : Loss =  0.39380085  Acc:  0.8663167 Val_loss =  0.44804862 Val_acc =  0.8445\n",
            "Iteration  1740 : Loss =  0.39377037  Acc:  0.8663167 Val_loss =  0.44803283 Val_acc =  0.8446\n",
            "Iteration  1741 : Loss =  0.3937399  Acc:  0.8663167 Val_loss =  0.44801703 Val_acc =  0.8446\n",
            "Iteration  1742 : Loss =  0.39370954  Acc:  0.86635 Val_loss =  0.44800127 Val_acc =  0.8446\n",
            "Iteration  1743 : Loss =  0.39367917  Acc:  0.8663667 Val_loss =  0.44798556 Val_acc =  0.8446\n",
            "Iteration  1744 : Loss =  0.3936488  Acc:  0.8663333 Val_loss =  0.44796982 Val_acc =  0.8446\n",
            "Iteration  1745 : Loss =  0.39361846  Acc:  0.8663333 Val_loss =  0.4479541 Val_acc =  0.8446\n",
            "Iteration  1746 : Loss =  0.39358816  Acc:  0.8663333 Val_loss =  0.44793844 Val_acc =  0.8446\n",
            "Iteration  1747 : Loss =  0.39355788  Acc:  0.8663167 Val_loss =  0.44792277 Val_acc =  0.8446\n",
            "Iteration  1748 : Loss =  0.3935276  Acc:  0.8663333 Val_loss =  0.44790718 Val_acc =  0.8446\n",
            "Iteration  1749 : Loss =  0.39349732  Acc:  0.8663333 Val_loss =  0.44789156 Val_acc =  0.8446\n",
            "Iteration  1750 : Loss =  0.39346716  Acc:  0.8663333 Val_loss =  0.44787598 Val_acc =  0.8446\n",
            "Iteration  1751 : Loss =  0.39343697  Acc:  0.86635 Val_loss =  0.4478604 Val_acc =  0.8446\n",
            "Iteration  1752 : Loss =  0.39340678  Acc:  0.8663667 Val_loss =  0.44784486 Val_acc =  0.8446\n",
            "Iteration  1753 : Loss =  0.39337662  Acc:  0.8663667 Val_loss =  0.44782934 Val_acc =  0.8446\n",
            "Iteration  1754 : Loss =  0.39334655  Acc:  0.8663833 Val_loss =  0.44781387 Val_acc =  0.8446\n",
            "Iteration  1755 : Loss =  0.39331642  Acc:  0.8664 Val_loss =  0.44779834 Val_acc =  0.8446\n",
            "Iteration  1756 : Loss =  0.39328635  Acc:  0.8663833 Val_loss =  0.4477829 Val_acc =  0.8446\n",
            "Iteration  1757 : Loss =  0.3932563  Acc:  0.8663833 Val_loss =  0.44776747 Val_acc =  0.8446\n",
            "Iteration  1758 : Loss =  0.39322627  Acc:  0.86635 Val_loss =  0.44775206 Val_acc =  0.8446\n",
            "Iteration  1759 : Loss =  0.39319628  Acc:  0.8663333 Val_loss =  0.44773668 Val_acc =  0.8446\n",
            "Iteration  1760 : Loss =  0.39316627  Acc:  0.8663333 Val_loss =  0.4477213 Val_acc =  0.8446\n",
            "Iteration  1761 : Loss =  0.39313632  Acc:  0.8663333 Val_loss =  0.44770595 Val_acc =  0.8446\n",
            "Iteration  1762 : Loss =  0.39310637  Acc:  0.8663333 Val_loss =  0.44769064 Val_acc =  0.8446\n",
            "Iteration  1763 : Loss =  0.3930765  Acc:  0.8663167 Val_loss =  0.44767535 Val_acc =  0.8446\n",
            "Iteration  1764 : Loss =  0.39304662  Acc:  0.8663333 Val_loss =  0.44766006 Val_acc =  0.8445\n",
            "Iteration  1765 : Loss =  0.39301676  Acc:  0.8663333 Val_loss =  0.44764483 Val_acc =  0.8444\n",
            "Iteration  1766 : Loss =  0.3929869  Acc:  0.86635 Val_loss =  0.4476296 Val_acc =  0.8445\n",
            "Iteration  1767 : Loss =  0.3929571  Acc:  0.8663667 Val_loss =  0.44761434 Val_acc =  0.8446\n",
            "Iteration  1768 : Loss =  0.3929273  Acc:  0.8663667 Val_loss =  0.44759917 Val_acc =  0.8446\n",
            "Iteration  1769 : Loss =  0.39289752  Acc:  0.8663667 Val_loss =  0.44758397 Val_acc =  0.8446\n",
            "Iteration  1770 : Loss =  0.39286777  Acc:  0.8663667 Val_loss =  0.44756883 Val_acc =  0.8446\n",
            "Iteration  1771 : Loss =  0.3928381  Acc:  0.8663833 Val_loss =  0.44755372 Val_acc =  0.8446\n",
            "Iteration  1772 : Loss =  0.39280838  Acc:  0.8663833 Val_loss =  0.4475386 Val_acc =  0.8446\n",
            "Iteration  1773 : Loss =  0.39277866  Acc:  0.8664 Val_loss =  0.44752353 Val_acc =  0.8446\n",
            "Iteration  1774 : Loss =  0.392749  Acc:  0.8664 Val_loss =  0.44750848 Val_acc =  0.8446\n",
            "Iteration  1775 : Loss =  0.3927194  Acc:  0.8664 Val_loss =  0.44749346 Val_acc =  0.8446\n",
            "Iteration  1776 : Loss =  0.39268976  Acc:  0.8664 Val_loss =  0.44747838 Val_acc =  0.8446\n",
            "Iteration  1777 : Loss =  0.39266023  Acc:  0.8664167 Val_loss =  0.4474634 Val_acc =  0.8446\n",
            "Iteration  1778 : Loss =  0.39263064  Acc:  0.8664167 Val_loss =  0.44744843 Val_acc =  0.8446\n",
            "Iteration  1779 : Loss =  0.3926011  Acc:  0.8664333 Val_loss =  0.4474335 Val_acc =  0.8446\n",
            "Iteration  1780 : Loss =  0.39257163  Acc:  0.86645 Val_loss =  0.44741854 Val_acc =  0.8447\n",
            "Iteration  1781 : Loss =  0.3925421  Acc:  0.8664333 Val_loss =  0.4474036 Val_acc =  0.8447\n",
            "Iteration  1782 : Loss =  0.39251262  Acc:  0.86645 Val_loss =  0.44738877 Val_acc =  0.8449\n",
            "Iteration  1783 : Loss =  0.39248317  Acc:  0.8665 Val_loss =  0.44737384 Val_acc =  0.8449\n",
            "Iteration  1784 : Loss =  0.39245373  Acc:  0.86651665 Val_loss =  0.447359 Val_acc =  0.8449\n",
            "Iteration  1785 : Loss =  0.39242435  Acc:  0.86655 Val_loss =  0.44734418 Val_acc =  0.8449\n",
            "Iteration  1786 : Loss =  0.392395  Acc:  0.86655 Val_loss =  0.4473294 Val_acc =  0.8449\n",
            "Iteration  1787 : Loss =  0.3923656  Acc:  0.86656666 Val_loss =  0.4473146 Val_acc =  0.8448\n",
            "Iteration  1788 : Loss =  0.39233625  Acc:  0.86665 Val_loss =  0.4472998 Val_acc =  0.8448\n",
            "Iteration  1789 : Loss =  0.39230695  Acc:  0.86665 Val_loss =  0.44728506 Val_acc =  0.8448\n",
            "Iteration  1790 : Loss =  0.39227766  Acc:  0.86663336 Val_loss =  0.4472703 Val_acc =  0.8448\n",
            "Iteration  1791 : Loss =  0.39224836  Acc:  0.8666 Val_loss =  0.44725567 Val_acc =  0.8448\n",
            "Iteration  1792 : Loss =  0.39221913  Acc:  0.86663336 Val_loss =  0.44724098 Val_acc =  0.8448\n",
            "Iteration  1793 : Loss =  0.39218992  Acc:  0.86661667 Val_loss =  0.44722632 Val_acc =  0.8448\n",
            "Iteration  1794 : Loss =  0.39216074  Acc:  0.86661667 Val_loss =  0.44721162 Val_acc =  0.8448\n",
            "Iteration  1795 : Loss =  0.39213154  Acc:  0.86663336 Val_loss =  0.44719702 Val_acc =  0.8448\n",
            "Iteration  1796 : Loss =  0.3921024  Acc:  0.86663336 Val_loss =  0.44718242 Val_acc =  0.8447\n",
            "Iteration  1797 : Loss =  0.39207324  Acc:  0.8666 Val_loss =  0.44716787 Val_acc =  0.8447\n",
            "Iteration  1798 : Loss =  0.39204413  Acc:  0.86658335 Val_loss =  0.44715333 Val_acc =  0.8447\n",
            "Iteration  1799 : Loss =  0.39201504  Acc:  0.8666 Val_loss =  0.44713876 Val_acc =  0.8447\n",
            "Iteration  1800 : Loss =  0.391986  Acc:  0.8666 Val_loss =  0.44712427 Val_acc =  0.8447\n",
            "Iteration  1801 : Loss =  0.39195693  Acc:  0.86663336 Val_loss =  0.44710976 Val_acc =  0.8447\n",
            "Iteration  1802 : Loss =  0.39192793  Acc:  0.86658335 Val_loss =  0.44709527 Val_acc =  0.8447\n",
            "Iteration  1803 : Loss =  0.3918989  Acc:  0.86658335 Val_loss =  0.44708085 Val_acc =  0.8447\n",
            "Iteration  1804 : Loss =  0.39186993  Acc:  0.86658335 Val_loss =  0.4470664 Val_acc =  0.8448\n",
            "Iteration  1805 : Loss =  0.391841  Acc:  0.8666 Val_loss =  0.447052 Val_acc =  0.8447\n",
            "Iteration  1806 : Loss =  0.39181203  Acc:  0.86663336 Val_loss =  0.4470376 Val_acc =  0.8447\n",
            "Iteration  1807 : Loss =  0.39178315  Acc:  0.86661667 Val_loss =  0.44702324 Val_acc =  0.8448\n",
            "Iteration  1808 : Loss =  0.39175424  Acc:  0.86665 Val_loss =  0.44700885 Val_acc =  0.8448\n",
            "Iteration  1809 : Loss =  0.3917254  Acc:  0.8666667 Val_loss =  0.44699454 Val_acc =  0.8448\n",
            "Iteration  1810 : Loss =  0.3916965  Acc:  0.8666667 Val_loss =  0.44698024 Val_acc =  0.8448\n",
            "Iteration  1811 : Loss =  0.3916677  Acc:  0.8667 Val_loss =  0.44696593 Val_acc =  0.8449\n",
            "Iteration  1812 : Loss =  0.39163888  Acc:  0.8667167 Val_loss =  0.44695166 Val_acc =  0.8449\n",
            "Iteration  1813 : Loss =  0.3916101  Acc:  0.8667167 Val_loss =  0.44693744 Val_acc =  0.8449\n",
            "Iteration  1814 : Loss =  0.39158136  Acc:  0.8667167 Val_loss =  0.4469232 Val_acc =  0.8449\n",
            "Iteration  1815 : Loss =  0.3915526  Acc:  0.8667333 Val_loss =  0.44690898 Val_acc =  0.8448\n",
            "Iteration  1816 : Loss =  0.3915239  Acc:  0.86675 Val_loss =  0.44689482 Val_acc =  0.8447\n",
            "Iteration  1817 : Loss =  0.39149517  Acc:  0.86675 Val_loss =  0.44688067 Val_acc =  0.8447\n",
            "Iteration  1818 : Loss =  0.39146653  Acc:  0.8667667 Val_loss =  0.4468665 Val_acc =  0.8447\n",
            "Iteration  1819 : Loss =  0.39143786  Acc:  0.86675 Val_loss =  0.44685236 Val_acc =  0.8448\n",
            "Iteration  1820 : Loss =  0.39140925  Acc:  0.8667833 Val_loss =  0.4468383 Val_acc =  0.8449\n",
            "Iteration  1821 : Loss =  0.39138064  Acc:  0.8667833 Val_loss =  0.44682416 Val_acc =  0.8449\n",
            "Iteration  1822 : Loss =  0.39135206  Acc:  0.8668 Val_loss =  0.4468101 Val_acc =  0.8449\n",
            "Iteration  1823 : Loss =  0.3913235  Acc:  0.8668 Val_loss =  0.44679606 Val_acc =  0.8449\n",
            "Iteration  1824 : Loss =  0.39129493  Acc:  0.8667833 Val_loss =  0.44678202 Val_acc =  0.8449\n",
            "Iteration  1825 : Loss =  0.3912664  Acc:  0.8668 Val_loss =  0.44676802 Val_acc =  0.845\n",
            "Iteration  1826 : Loss =  0.39123788  Acc:  0.86681664 Val_loss =  0.446754 Val_acc =  0.8449\n",
            "Iteration  1827 : Loss =  0.39120945  Acc:  0.8668333 Val_loss =  0.4467401 Val_acc =  0.8449\n",
            "Iteration  1828 : Loss =  0.391181  Acc:  0.86685 Val_loss =  0.4467261 Val_acc =  0.8449\n",
            "Iteration  1829 : Loss =  0.39115253  Acc:  0.86691666 Val_loss =  0.4467122 Val_acc =  0.845\n",
            "Iteration  1830 : Loss =  0.3911241  Acc:  0.86691666 Val_loss =  0.44669834 Val_acc =  0.845\n",
            "Iteration  1831 : Loss =  0.3910957  Acc:  0.86691666 Val_loss =  0.44668436 Val_acc =  0.845\n",
            "Iteration  1832 : Loss =  0.39106736  Acc:  0.86691666 Val_loss =  0.44667056 Val_acc =  0.845\n",
            "Iteration  1833 : Loss =  0.39103898  Acc:  0.8669 Val_loss =  0.4466567 Val_acc =  0.845\n",
            "Iteration  1834 : Loss =  0.39101067  Acc:  0.86691666 Val_loss =  0.44664288 Val_acc =  0.845\n",
            "Iteration  1835 : Loss =  0.39098236  Acc:  0.86693335 Val_loss =  0.44662905 Val_acc =  0.845\n",
            "Iteration  1836 : Loss =  0.39095405  Acc:  0.86695 Val_loss =  0.44661528 Val_acc =  0.845\n",
            "Iteration  1837 : Loss =  0.3909258  Acc:  0.86695 Val_loss =  0.4466015 Val_acc =  0.845\n",
            "Iteration  1838 : Loss =  0.39089757  Acc:  0.86695 Val_loss =  0.4465878 Val_acc =  0.845\n",
            "Iteration  1839 : Loss =  0.39086935  Acc:  0.86695 Val_loss =  0.44657403 Val_acc =  0.845\n",
            "Iteration  1840 : Loss =  0.39084113  Acc:  0.86695 Val_loss =  0.44656035 Val_acc =  0.845\n",
            "Iteration  1841 : Loss =  0.39081296  Acc:  0.86696666 Val_loss =  0.44654664 Val_acc =  0.845\n",
            "Iteration  1842 : Loss =  0.39078477  Acc:  0.86696666 Val_loss =  0.44653296 Val_acc =  0.845\n",
            "Iteration  1843 : Loss =  0.39075664  Acc:  0.867 Val_loss =  0.44651935 Val_acc =  0.845\n",
            "Iteration  1844 : Loss =  0.3907285  Acc:  0.8670167 Val_loss =  0.44650567 Val_acc =  0.845\n",
            "Iteration  1845 : Loss =  0.39070043  Acc:  0.8670167 Val_loss =  0.44649205 Val_acc =  0.845\n",
            "Iteration  1846 : Loss =  0.39067233  Acc:  0.86705 Val_loss =  0.44647846 Val_acc =  0.845\n",
            "Iteration  1847 : Loss =  0.39064428  Acc:  0.86705 Val_loss =  0.4464649 Val_acc =  0.845\n",
            "Iteration  1848 : Loss =  0.39061624  Acc:  0.86705 Val_loss =  0.44645137 Val_acc =  0.845\n",
            "Iteration  1849 : Loss =  0.39058822  Acc:  0.86705 Val_loss =  0.4464378 Val_acc =  0.8449\n",
            "Iteration  1850 : Loss =  0.3905602  Acc:  0.86705 Val_loss =  0.44642428 Val_acc =  0.8449\n",
            "Iteration  1851 : Loss =  0.39053223  Acc:  0.86705 Val_loss =  0.4464108 Val_acc =  0.8449\n",
            "Iteration  1852 : Loss =  0.3905043  Acc:  0.86705 Val_loss =  0.4463973 Val_acc =  0.845\n",
            "Iteration  1853 : Loss =  0.39047638  Acc:  0.8670833 Val_loss =  0.4463839 Val_acc =  0.845\n",
            "Iteration  1854 : Loss =  0.39044845  Acc:  0.8671 Val_loss =  0.44637042 Val_acc =  0.845\n",
            "Iteration  1855 : Loss =  0.3904206  Acc:  0.8670833 Val_loss =  0.44635704 Val_acc =  0.845\n",
            "Iteration  1856 : Loss =  0.39039272  Acc:  0.8671167 Val_loss =  0.4463436 Val_acc =  0.845\n",
            "Iteration  1857 : Loss =  0.39036486  Acc:  0.8671167 Val_loss =  0.44633022 Val_acc =  0.845\n",
            "Iteration  1858 : Loss =  0.390337  Acc:  0.86715 Val_loss =  0.4463169 Val_acc =  0.845\n",
            "Iteration  1859 : Loss =  0.39030918  Acc:  0.8671333 Val_loss =  0.44630352 Val_acc =  0.845\n",
            "Iteration  1860 : Loss =  0.39028138  Acc:  0.86715 Val_loss =  0.44629022 Val_acc =  0.845\n",
            "Iteration  1861 : Loss =  0.39025363  Acc:  0.86715 Val_loss =  0.44627684 Val_acc =  0.845\n",
            "Iteration  1862 : Loss =  0.3902259  Acc:  0.86715 Val_loss =  0.4462636 Val_acc =  0.8449\n",
            "Iteration  1863 : Loss =  0.3901981  Acc:  0.8671333 Val_loss =  0.44625038 Val_acc =  0.8449\n",
            "Iteration  1864 : Loss =  0.39017045  Acc:  0.8671333 Val_loss =  0.44623712 Val_acc =  0.8449\n",
            "Iteration  1865 : Loss =  0.39014274  Acc:  0.86715 Val_loss =  0.4462239 Val_acc =  0.845\n",
            "Iteration  1866 : Loss =  0.3901151  Acc:  0.8671833 Val_loss =  0.44621065 Val_acc =  0.845\n",
            "Iteration  1867 : Loss =  0.39008743  Acc:  0.86721665 Val_loss =  0.44619745 Val_acc =  0.8449\n",
            "Iteration  1868 : Loss =  0.39005983  Acc:  0.86721665 Val_loss =  0.44618434 Val_acc =  0.845\n",
            "Iteration  1869 : Loss =  0.39003217  Acc:  0.86721665 Val_loss =  0.4461712 Val_acc =  0.845\n",
            "Iteration  1870 : Loss =  0.39000458  Acc:  0.86723334 Val_loss =  0.44615805 Val_acc =  0.845\n",
            "Iteration  1871 : Loss =  0.389977  Acc:  0.86726665 Val_loss =  0.4461449 Val_acc =  0.8451\n",
            "Iteration  1872 : Loss =  0.38994947  Acc:  0.86726665 Val_loss =  0.4461318 Val_acc =  0.8451\n",
            "Iteration  1873 : Loss =  0.38992196  Acc:  0.86728334 Val_loss =  0.44611874 Val_acc =  0.8451\n",
            "Iteration  1874 : Loss =  0.38989446  Acc:  0.86728334 Val_loss =  0.44610566 Val_acc =  0.8451\n",
            "Iteration  1875 : Loss =  0.38986695  Acc:  0.86728334 Val_loss =  0.44609267 Val_acc =  0.8451\n",
            "Iteration  1876 : Loss =  0.38983953  Acc:  0.8673 Val_loss =  0.44607964 Val_acc =  0.845\n",
            "Iteration  1877 : Loss =  0.38981208  Acc:  0.86731666 Val_loss =  0.4460666 Val_acc =  0.8452\n",
            "Iteration  1878 : Loss =  0.38978463  Acc:  0.86731666 Val_loss =  0.44605365 Val_acc =  0.8452\n",
            "Iteration  1879 : Loss =  0.38975722  Acc:  0.86731666 Val_loss =  0.44604072 Val_acc =  0.8452\n",
            "Iteration  1880 : Loss =  0.38972983  Acc:  0.86733335 Val_loss =  0.44602773 Val_acc =  0.8452\n",
            "Iteration  1881 : Loss =  0.38970247  Acc:  0.86733335 Val_loss =  0.44601485 Val_acc =  0.8452\n",
            "Iteration  1882 : Loss =  0.38967514  Acc:  0.86733335 Val_loss =  0.44600192 Val_acc =  0.8452\n",
            "Iteration  1883 : Loss =  0.38964778  Acc:  0.86733335 Val_loss =  0.445989 Val_acc =  0.8452\n",
            "Iteration  1884 : Loss =  0.3896205  Acc:  0.86733335 Val_loss =  0.4459761 Val_acc =  0.8452\n",
            "Iteration  1885 : Loss =  0.38959318  Acc:  0.86731666 Val_loss =  0.4459633 Val_acc =  0.8452\n",
            "Iteration  1886 : Loss =  0.38956594  Acc:  0.86731666 Val_loss =  0.44595048 Val_acc =  0.8452\n",
            "Iteration  1887 : Loss =  0.38953868  Acc:  0.86731666 Val_loss =  0.44593763 Val_acc =  0.8452\n",
            "Iteration  1888 : Loss =  0.38951147  Acc:  0.86731666 Val_loss =  0.44592485 Val_acc =  0.8452\n",
            "Iteration  1889 : Loss =  0.38948426  Acc:  0.86733335 Val_loss =  0.44591206 Val_acc =  0.8453\n",
            "Iteration  1890 : Loss =  0.38945702  Acc:  0.8673667 Val_loss =  0.4458993 Val_acc =  0.8453\n",
            "Iteration  1891 : Loss =  0.3894299  Acc:  0.8674 Val_loss =  0.44588658 Val_acc =  0.8453\n",
            "Iteration  1892 : Loss =  0.38940275  Acc:  0.8674167 Val_loss =  0.4458739 Val_acc =  0.8453\n",
            "Iteration  1893 : Loss =  0.38937563  Acc:  0.8674167 Val_loss =  0.44586113 Val_acc =  0.8454\n",
            "Iteration  1894 : Loss =  0.3893485  Acc:  0.8674167 Val_loss =  0.44584844 Val_acc =  0.8453\n",
            "Iteration  1895 : Loss =  0.38932142  Acc:  0.8674667 Val_loss =  0.44583574 Val_acc =  0.8453\n",
            "Iteration  1896 : Loss =  0.3892943  Acc:  0.8674667 Val_loss =  0.44582313 Val_acc =  0.8453\n",
            "Iteration  1897 : Loss =  0.38926727  Acc:  0.8674667 Val_loss =  0.4458105 Val_acc =  0.8453\n",
            "Iteration  1898 : Loss =  0.38924024  Acc:  0.8674833 Val_loss =  0.4457979 Val_acc =  0.8453\n",
            "Iteration  1899 : Loss =  0.3892132  Acc:  0.8674833 Val_loss =  0.4457853 Val_acc =  0.8453\n",
            "Iteration  1900 : Loss =  0.38918623  Acc:  0.8674833 Val_loss =  0.44577277 Val_acc =  0.8453\n",
            "Iteration  1901 : Loss =  0.38915923  Acc:  0.8675 Val_loss =  0.44576016 Val_acc =  0.8454\n",
            "Iteration  1902 : Loss =  0.3891323  Acc:  0.8675 Val_loss =  0.4457476 Val_acc =  0.8455\n",
            "Iteration  1903 : Loss =  0.38910538  Acc:  0.8675 Val_loss =  0.4457351 Val_acc =  0.8453\n",
            "Iteration  1904 : Loss =  0.38907844  Acc:  0.8675 Val_loss =  0.4457226 Val_acc =  0.8453\n",
            "Iteration  1905 : Loss =  0.38905156  Acc:  0.8675333 Val_loss =  0.4457101 Val_acc =  0.8454\n",
            "Iteration  1906 : Loss =  0.38902467  Acc:  0.8675333 Val_loss =  0.44569767 Val_acc =  0.8454\n",
            "Iteration  1907 : Loss =  0.38899782  Acc:  0.86755 Val_loss =  0.44568515 Val_acc =  0.8455\n",
            "Iteration  1908 : Loss =  0.38897097  Acc:  0.86755 Val_loss =  0.44567275 Val_acc =  0.8455\n",
            "Iteration  1909 : Loss =  0.38894415  Acc:  0.8675333 Val_loss =  0.4456603 Val_acc =  0.8455\n",
            "Iteration  1910 : Loss =  0.38891736  Acc:  0.86755 Val_loss =  0.44564795 Val_acc =  0.8455\n",
            "Iteration  1911 : Loss =  0.38889056  Acc:  0.86755 Val_loss =  0.44563556 Val_acc =  0.8455\n",
            "Iteration  1912 : Loss =  0.3888638  Acc:  0.86755 Val_loss =  0.44562325 Val_acc =  0.8455\n",
            "Iteration  1913 : Loss =  0.38883704  Acc:  0.8675333 Val_loss =  0.44561085 Val_acc =  0.8455\n",
            "Iteration  1914 : Loss =  0.3888103  Acc:  0.86756665 Val_loss =  0.44559854 Val_acc =  0.8455\n",
            "Iteration  1915 : Loss =  0.38878363  Acc:  0.86756665 Val_loss =  0.44558623 Val_acc =  0.8455\n",
            "Iteration  1916 : Loss =  0.38875696  Acc:  0.86755 Val_loss =  0.44557393 Val_acc =  0.8455\n",
            "Iteration  1917 : Loss =  0.3887303  Acc:  0.8676 Val_loss =  0.44556168 Val_acc =  0.8455\n",
            "Iteration  1918 : Loss =  0.38870364  Acc:  0.86761665 Val_loss =  0.44554943 Val_acc =  0.8455\n",
            "Iteration  1919 : Loss =  0.38867697  Acc:  0.8676 Val_loss =  0.4455372 Val_acc =  0.8455\n",
            "Iteration  1920 : Loss =  0.38865036  Acc:  0.86761665 Val_loss =  0.44552496 Val_acc =  0.8455\n",
            "Iteration  1921 : Loss =  0.3886238  Acc:  0.86765 Val_loss =  0.44551274 Val_acc =  0.8455\n",
            "Iteration  1922 : Loss =  0.3885972  Acc:  0.86763334 Val_loss =  0.44550058 Val_acc =  0.8455\n",
            "Iteration  1923 : Loss =  0.3885707  Acc:  0.86761665 Val_loss =  0.44548842 Val_acc =  0.8455\n",
            "Iteration  1924 : Loss =  0.38854414  Acc:  0.86763334 Val_loss =  0.44547626 Val_acc =  0.8455\n",
            "Iteration  1925 : Loss =  0.38851762  Acc:  0.86763334 Val_loss =  0.4454641 Val_acc =  0.8456\n",
            "Iteration  1926 : Loss =  0.38849112  Acc:  0.86765 Val_loss =  0.445452 Val_acc =  0.8456\n",
            "Iteration  1927 : Loss =  0.38846466  Acc:  0.86765 Val_loss =  0.44543993 Val_acc =  0.8456\n",
            "Iteration  1928 : Loss =  0.38843817  Acc:  0.86766666 Val_loss =  0.44542783 Val_acc =  0.8457\n",
            "Iteration  1929 : Loss =  0.38841176  Acc:  0.8677 Val_loss =  0.44541577 Val_acc =  0.8458\n",
            "Iteration  1930 : Loss =  0.3883853  Acc:  0.86771667 Val_loss =  0.44540372 Val_acc =  0.8458\n",
            "Iteration  1931 : Loss =  0.38835886  Acc:  0.86771667 Val_loss =  0.44539168 Val_acc =  0.8458\n",
            "Iteration  1932 : Loss =  0.3883325  Acc:  0.86775 Val_loss =  0.44537967 Val_acc =  0.8458\n",
            "Iteration  1933 : Loss =  0.3883061  Acc:  0.86775 Val_loss =  0.44536766 Val_acc =  0.8458\n",
            "Iteration  1934 : Loss =  0.38827983  Acc:  0.8677833 Val_loss =  0.44535577 Val_acc =  0.8458\n",
            "Iteration  1935 : Loss =  0.38825345  Acc:  0.8678 Val_loss =  0.44534376 Val_acc =  0.8458\n",
            "Iteration  1936 : Loss =  0.38822713  Acc:  0.8677833 Val_loss =  0.44533184 Val_acc =  0.8458\n",
            "Iteration  1937 : Loss =  0.38820085  Acc:  0.8677833 Val_loss =  0.44531992 Val_acc =  0.8459\n",
            "Iteration  1938 : Loss =  0.38817456  Acc:  0.8677833 Val_loss =  0.445308 Val_acc =  0.8459\n",
            "Iteration  1939 : Loss =  0.3881483  Acc:  0.8677833 Val_loss =  0.44529614 Val_acc =  0.846\n",
            "Iteration  1940 : Loss =  0.38812208  Acc:  0.8677833 Val_loss =  0.44528428 Val_acc =  0.846\n",
            "Iteration  1941 : Loss =  0.38809586  Acc:  0.8677833 Val_loss =  0.44527236 Val_acc =  0.8459\n",
            "Iteration  1942 : Loss =  0.38806966  Acc:  0.8677833 Val_loss =  0.44526055 Val_acc =  0.846\n",
            "Iteration  1943 : Loss =  0.38804346  Acc:  0.8677667 Val_loss =  0.44524872 Val_acc =  0.846\n",
            "Iteration  1944 : Loss =  0.38801733  Acc:  0.8677833 Val_loss =  0.44523692 Val_acc =  0.846\n",
            "Iteration  1945 : Loss =  0.38799116  Acc:  0.8678 Val_loss =  0.44522515 Val_acc =  0.846\n",
            "Iteration  1946 : Loss =  0.38796505  Acc:  0.8678167 Val_loss =  0.44521338 Val_acc =  0.846\n",
            "Iteration  1947 : Loss =  0.38793895  Acc:  0.8678333 Val_loss =  0.44520167 Val_acc =  0.846\n",
            "Iteration  1948 : Loss =  0.38791284  Acc:  0.86785 Val_loss =  0.4451899 Val_acc =  0.8462\n",
            "Iteration  1949 : Loss =  0.38788676  Acc:  0.8678667 Val_loss =  0.44517818 Val_acc =  0.8462\n",
            "Iteration  1950 : Loss =  0.38786072  Acc:  0.8678667 Val_loss =  0.4451665 Val_acc =  0.8461\n",
            "Iteration  1951 : Loss =  0.38783464  Acc:  0.86791664 Val_loss =  0.4451548 Val_acc =  0.8461\n",
            "Iteration  1952 : Loss =  0.38780865  Acc:  0.86793333 Val_loss =  0.44514316 Val_acc =  0.8461\n",
            "Iteration  1953 : Loss =  0.3877826  Acc:  0.86795 Val_loss =  0.44513148 Val_acc =  0.8461\n",
            "Iteration  1954 : Loss =  0.38775668  Acc:  0.86798334 Val_loss =  0.4451199 Val_acc =  0.8461\n",
            "Iteration  1955 : Loss =  0.3877307  Acc:  0.868 Val_loss =  0.44510826 Val_acc =  0.8461\n",
            "Iteration  1956 : Loss =  0.38770476  Acc:  0.868 Val_loss =  0.44509667 Val_acc =  0.8461\n",
            "Iteration  1957 : Loss =  0.3876788  Acc:  0.868 Val_loss =  0.44508505 Val_acc =  0.8461\n",
            "Iteration  1958 : Loss =  0.38765293  Acc:  0.86801666 Val_loss =  0.44507354 Val_acc =  0.8461\n",
            "Iteration  1959 : Loss =  0.387627  Acc:  0.86803335 Val_loss =  0.445062 Val_acc =  0.8461\n",
            "Iteration  1960 : Loss =  0.38760114  Acc:  0.86803335 Val_loss =  0.44505045 Val_acc =  0.8461\n",
            "Iteration  1961 : Loss =  0.3875753  Acc:  0.86805 Val_loss =  0.4450389 Val_acc =  0.8461\n",
            "Iteration  1962 : Loss =  0.38754946  Acc:  0.86806667 Val_loss =  0.44502738 Val_acc =  0.846\n",
            "Iteration  1963 : Loss =  0.38752362  Acc:  0.8681 Val_loss =  0.4450159 Val_acc =  0.846\n",
            "Iteration  1964 : Loss =  0.38749784  Acc:  0.8681 Val_loss =  0.4450045 Val_acc =  0.846\n",
            "Iteration  1965 : Loss =  0.38747203  Acc:  0.86808336 Val_loss =  0.44499308 Val_acc =  0.846\n",
            "Iteration  1966 : Loss =  0.38744628  Acc:  0.8681167 Val_loss =  0.44498163 Val_acc =  0.846\n",
            "Iteration  1967 : Loss =  0.38742054  Acc:  0.8681 Val_loss =  0.44497022 Val_acc =  0.846\n",
            "Iteration  1968 : Loss =  0.3873948  Acc:  0.8681 Val_loss =  0.44495878 Val_acc =  0.846\n",
            "Iteration  1969 : Loss =  0.38736907  Acc:  0.8681 Val_loss =  0.44494745 Val_acc =  0.846\n",
            "Iteration  1970 : Loss =  0.38734335  Acc:  0.8681333 Val_loss =  0.4449361 Val_acc =  0.846\n",
            "Iteration  1971 : Loss =  0.38731772  Acc:  0.8681667 Val_loss =  0.4449247 Val_acc =  0.846\n",
            "Iteration  1972 : Loss =  0.38729206  Acc:  0.8681833 Val_loss =  0.4449134 Val_acc =  0.846\n",
            "Iteration  1973 : Loss =  0.3872664  Acc:  0.8682 Val_loss =  0.44490206 Val_acc =  0.846\n",
            "Iteration  1974 : Loss =  0.38724077  Acc:  0.8682167 Val_loss =  0.44489077 Val_acc =  0.846\n",
            "Iteration  1975 : Loss =  0.38721517  Acc:  0.8682 Val_loss =  0.4448795 Val_acc =  0.846\n",
            "Iteration  1976 : Loss =  0.3871896  Acc:  0.8681833 Val_loss =  0.44486827 Val_acc =  0.846\n",
            "Iteration  1977 : Loss =  0.38716403  Acc:  0.8682167 Val_loss =  0.44485697 Val_acc =  0.8459\n",
            "Iteration  1978 : Loss =  0.3871385  Acc:  0.8681833 Val_loss =  0.44484577 Val_acc =  0.8459\n",
            "Iteration  1979 : Loss =  0.38711292  Acc:  0.8681833 Val_loss =  0.44483456 Val_acc =  0.8459\n",
            "Iteration  1980 : Loss =  0.38708737  Acc:  0.8682 Val_loss =  0.44482335 Val_acc =  0.8459\n",
            "Iteration  1981 : Loss =  0.3870619  Acc:  0.8682167 Val_loss =  0.4448122 Val_acc =  0.8459\n",
            "Iteration  1982 : Loss =  0.38703638  Acc:  0.8682167 Val_loss =  0.44480103 Val_acc =  0.8459\n",
            "Iteration  1983 : Loss =  0.38701093  Acc:  0.8682167 Val_loss =  0.44478986 Val_acc =  0.8459\n",
            "Iteration  1984 : Loss =  0.38698548  Acc:  0.8682333 Val_loss =  0.4447787 Val_acc =  0.8459\n",
            "Iteration  1985 : Loss =  0.3869601  Acc:  0.8682333 Val_loss =  0.44476762 Val_acc =  0.8459\n",
            "Iteration  1986 : Loss =  0.38693464  Acc:  0.8682167 Val_loss =  0.4447565 Val_acc =  0.8459\n",
            "Iteration  1987 : Loss =  0.38690925  Acc:  0.8682167 Val_loss =  0.44474542 Val_acc =  0.846\n",
            "Iteration  1988 : Loss =  0.38688385  Acc:  0.8682167 Val_loss =  0.44473436 Val_acc =  0.846\n",
            "Iteration  1989 : Loss =  0.38685852  Acc:  0.8682167 Val_loss =  0.44472334 Val_acc =  0.846\n",
            "Iteration  1990 : Loss =  0.38683313  Acc:  0.8682167 Val_loss =  0.4447123 Val_acc =  0.846\n",
            "Iteration  1991 : Loss =  0.3868078  Acc:  0.8682167 Val_loss =  0.44470128 Val_acc =  0.846\n",
            "Iteration  1992 : Loss =  0.38678253  Acc:  0.8682167 Val_loss =  0.44469023 Val_acc =  0.846\n",
            "Iteration  1993 : Loss =  0.38675722  Acc:  0.8682 Val_loss =  0.4446793 Val_acc =  0.846\n",
            "Iteration  1994 : Loss =  0.38673195  Acc:  0.8682167 Val_loss =  0.44466826 Val_acc =  0.846\n",
            "Iteration  1995 : Loss =  0.38670668  Acc:  0.8681833 Val_loss =  0.44465733 Val_acc =  0.846\n",
            "Iteration  1996 : Loss =  0.38668144  Acc:  0.8681833 Val_loss =  0.44464645 Val_acc =  0.846\n",
            "Iteration  1997 : Loss =  0.3866562  Acc:  0.8682 Val_loss =  0.4446355 Val_acc =  0.846\n",
            "Iteration  1998 : Loss =  0.38663098  Acc:  0.8682 Val_loss =  0.44462457 Val_acc =  0.846\n",
            "Iteration  1999 : Loss =  0.3866058  Acc:  0.8682 Val_loss =  0.44461367 Val_acc =  0.846\n",
            "Iteration  2000 : Loss =  0.38658065  Acc:  0.8682 Val_loss =  0.44460282 Val_acc =  0.846\n",
            "Iteration  2001 : Loss =  0.38655546  Acc:  0.8682 Val_loss =  0.444592 Val_acc =  0.846\n",
            "Iteration  2002 : Loss =  0.38653034  Acc:  0.8681833 Val_loss =  0.44458115 Val_acc =  0.846\n",
            "Iteration  2003 : Loss =  0.38650525  Acc:  0.8681833 Val_loss =  0.4445703 Val_acc =  0.8459\n",
            "Iteration  2004 : Loss =  0.38648012  Acc:  0.8682 Val_loss =  0.44455948 Val_acc =  0.8459\n",
            "Iteration  2005 : Loss =  0.386455  Acc:  0.8682 Val_loss =  0.44454873 Val_acc =  0.8459\n",
            "Iteration  2006 : Loss =  0.38642994  Acc:  0.8682 Val_loss =  0.44453788 Val_acc =  0.8459\n",
            "Iteration  2007 : Loss =  0.38640487  Acc:  0.8682167 Val_loss =  0.44452715 Val_acc =  0.8459\n",
            "Iteration  2008 : Loss =  0.38637984  Acc:  0.8682 Val_loss =  0.44451642 Val_acc =  0.8459\n",
            "Iteration  2009 : Loss =  0.38635486  Acc:  0.8682167 Val_loss =  0.44450566 Val_acc =  0.8459\n",
            "Iteration  2010 : Loss =  0.38632983  Acc:  0.86825 Val_loss =  0.44449496 Val_acc =  0.8459\n",
            "Iteration  2011 : Loss =  0.38630483  Acc:  0.86825 Val_loss =  0.44448426 Val_acc =  0.8459\n",
            "Iteration  2012 : Loss =  0.38627988  Acc:  0.86825 Val_loss =  0.4444736 Val_acc =  0.8459\n",
            "Iteration  2013 : Loss =  0.3862549  Acc:  0.8683 Val_loss =  0.4444629 Val_acc =  0.8459\n",
            "Iteration  2014 : Loss =  0.38622996  Acc:  0.86831665 Val_loss =  0.44445226 Val_acc =  0.846\n",
            "Iteration  2015 : Loss =  0.38620505  Acc:  0.86833334 Val_loss =  0.4444416 Val_acc =  0.846\n",
            "Iteration  2016 : Loss =  0.38618013  Acc:  0.86835 Val_loss =  0.444431 Val_acc =  0.8459\n",
            "Iteration  2017 : Loss =  0.38615528  Acc:  0.86835 Val_loss =  0.4444204 Val_acc =  0.8459\n",
            "Iteration  2018 : Loss =  0.3861304  Acc:  0.86838335 Val_loss =  0.44440982 Val_acc =  0.8459\n",
            "Iteration  2019 : Loss =  0.38610554  Acc:  0.86841667 Val_loss =  0.44439927 Val_acc =  0.8459\n",
            "Iteration  2020 : Loss =  0.38608068  Acc:  0.8684 Val_loss =  0.44438872 Val_acc =  0.8459\n",
            "Iteration  2021 : Loss =  0.3860559  Acc:  0.86841667 Val_loss =  0.44437814 Val_acc =  0.8459\n",
            "Iteration  2022 : Loss =  0.3860311  Acc:  0.86841667 Val_loss =  0.44436768 Val_acc =  0.8459\n",
            "Iteration  2023 : Loss =  0.38600633  Acc:  0.86843336 Val_loss =  0.44435713 Val_acc =  0.8459\n",
            "Iteration  2024 : Loss =  0.3859815  Acc:  0.86843336 Val_loss =  0.44434664 Val_acc =  0.8459\n",
            "Iteration  2025 : Loss =  0.38595676  Acc:  0.86843336 Val_loss =  0.44433618 Val_acc =  0.8459\n",
            "Iteration  2026 : Loss =  0.38593203  Acc:  0.86845 Val_loss =  0.4443257 Val_acc =  0.8459\n",
            "Iteration  2027 : Loss =  0.3859073  Acc:  0.86845 Val_loss =  0.44431522 Val_acc =  0.8459\n",
            "Iteration  2028 : Loss =  0.38588262  Acc:  0.86845 Val_loss =  0.4443048 Val_acc =  0.8459\n",
            "Iteration  2029 : Loss =  0.3858579  Acc:  0.86845 Val_loss =  0.44429433 Val_acc =  0.8459\n",
            "Iteration  2030 : Loss =  0.38583323  Acc:  0.8685 Val_loss =  0.444284 Val_acc =  0.8459\n",
            "Iteration  2031 : Loss =  0.3858086  Acc:  0.8685 Val_loss =  0.4442736 Val_acc =  0.8459\n",
            "Iteration  2032 : Loss =  0.38578394  Acc:  0.8684833 Val_loss =  0.44426322 Val_acc =  0.8459\n",
            "Iteration  2033 : Loss =  0.38575935  Acc:  0.8684667 Val_loss =  0.44425282 Val_acc =  0.8459\n",
            "Iteration  2034 : Loss =  0.3857347  Acc:  0.8684833 Val_loss =  0.44424254 Val_acc =  0.846\n",
            "Iteration  2035 : Loss =  0.38571012  Acc:  0.8684833 Val_loss =  0.44423217 Val_acc =  0.8459\n",
            "Iteration  2036 : Loss =  0.38568553  Acc:  0.8684833 Val_loss =  0.44422188 Val_acc =  0.8459\n",
            "Iteration  2037 : Loss =  0.385661  Acc:  0.8684833 Val_loss =  0.44421163 Val_acc =  0.8459\n",
            "Iteration  2038 : Loss =  0.38563645  Acc:  0.8684667 Val_loss =  0.44420126 Val_acc =  0.8459\n",
            "Iteration  2039 : Loss =  0.38561192  Acc:  0.8684833 Val_loss =  0.444191 Val_acc =  0.8459\n",
            "Iteration  2040 : Loss =  0.38558742  Acc:  0.8684833 Val_loss =  0.44418082 Val_acc =  0.8459\n",
            "Iteration  2041 : Loss =  0.38556296  Acc:  0.8684667 Val_loss =  0.4441706 Val_acc =  0.8459\n",
            "Iteration  2042 : Loss =  0.3855385  Acc:  0.8684667 Val_loss =  0.44416034 Val_acc =  0.8459\n",
            "Iteration  2043 : Loss =  0.385514  Acc:  0.8685 Val_loss =  0.44415015 Val_acc =  0.8459\n",
            "Iteration  2044 : Loss =  0.38548958  Acc:  0.8685 Val_loss =  0.44413993 Val_acc =  0.8459\n",
            "Iteration  2045 : Loss =  0.38546515  Acc:  0.8685167 Val_loss =  0.4441298 Val_acc =  0.8459\n",
            "Iteration  2046 : Loss =  0.38544077  Acc:  0.8685 Val_loss =  0.44411963 Val_acc =  0.8459\n",
            "Iteration  2047 : Loss =  0.38541633  Acc:  0.8684833 Val_loss =  0.44410953 Val_acc =  0.8459\n",
            "Iteration  2048 : Loss =  0.38539195  Acc:  0.86845 Val_loss =  0.44409943 Val_acc =  0.8459\n",
            "Iteration  2049 : Loss =  0.3853676  Acc:  0.8684833 Val_loss =  0.44408926 Val_acc =  0.8459\n",
            "Iteration  2050 : Loss =  0.38534322  Acc:  0.8684833 Val_loss =  0.44407916 Val_acc =  0.846\n",
            "Iteration  2051 : Loss =  0.38531893  Acc:  0.8684833 Val_loss =  0.4440691 Val_acc =  0.8461\n",
            "Iteration  2052 : Loss =  0.3852946  Acc:  0.8685167 Val_loss =  0.44405904 Val_acc =  0.8461\n",
            "Iteration  2053 : Loss =  0.38527033  Acc:  0.8685333 Val_loss =  0.4440489 Val_acc =  0.8461\n",
            "Iteration  2054 : Loss =  0.38524604  Acc:  0.8685167 Val_loss =  0.44403893 Val_acc =  0.8461\n",
            "Iteration  2055 : Loss =  0.38522175  Acc:  0.8685167 Val_loss =  0.4440289 Val_acc =  0.8461\n",
            "Iteration  2056 : Loss =  0.38519752  Acc:  0.8685167 Val_loss =  0.4440189 Val_acc =  0.8461\n",
            "Iteration  2057 : Loss =  0.38517332  Acc:  0.8685 Val_loss =  0.4440089 Val_acc =  0.8461\n",
            "Iteration  2058 : Loss =  0.38514906  Acc:  0.8685 Val_loss =  0.44399893 Val_acc =  0.8461\n",
            "Iteration  2059 : Loss =  0.38512486  Acc:  0.8685167 Val_loss =  0.44398898 Val_acc =  0.8461\n",
            "Iteration  2060 : Loss =  0.38510066  Acc:  0.8685 Val_loss =  0.443979 Val_acc =  0.8462\n",
            "Iteration  2061 : Loss =  0.38507652  Acc:  0.8684833 Val_loss =  0.4439691 Val_acc =  0.8462\n",
            "Iteration  2062 : Loss =  0.38505235  Acc:  0.8685167 Val_loss =  0.44395918 Val_acc =  0.8462\n",
            "Iteration  2063 : Loss =  0.38502818  Acc:  0.8685167 Val_loss =  0.44394928 Val_acc =  0.8462\n",
            "Iteration  2064 : Loss =  0.3850041  Acc:  0.86855 Val_loss =  0.44393936 Val_acc =  0.8461\n",
            "Iteration  2065 : Loss =  0.38498  Acc:  0.86855 Val_loss =  0.4439295 Val_acc =  0.846\n",
            "Iteration  2066 : Loss =  0.38495588  Acc:  0.8685333 Val_loss =  0.44391963 Val_acc =  0.846\n",
            "Iteration  2067 : Loss =  0.38493183  Acc:  0.8685333 Val_loss =  0.44390982 Val_acc =  0.846\n",
            "Iteration  2068 : Loss =  0.38490775  Acc:  0.8685667 Val_loss =  0.4439 Val_acc =  0.846\n",
            "Iteration  2069 : Loss =  0.38488373  Acc:  0.86855 Val_loss =  0.44389012 Val_acc =  0.846\n",
            "Iteration  2070 : Loss =  0.38485968  Acc:  0.8685833 Val_loss =  0.44388038 Val_acc =  0.846\n",
            "Iteration  2071 : Loss =  0.3848357  Acc:  0.8685833 Val_loss =  0.4438706 Val_acc =  0.8459\n",
            "Iteration  2072 : Loss =  0.3848117  Acc:  0.8685833 Val_loss =  0.44386083 Val_acc =  0.8459\n",
            "Iteration  2073 : Loss =  0.3847877  Acc:  0.8685833 Val_loss =  0.44385108 Val_acc =  0.8459\n",
            "Iteration  2074 : Loss =  0.38476372  Acc:  0.8685833 Val_loss =  0.4438413 Val_acc =  0.8459\n",
            "Iteration  2075 : Loss =  0.3847398  Acc:  0.8686 Val_loss =  0.4438316 Val_acc =  0.8458\n",
            "Iteration  2076 : Loss =  0.38471583  Acc:  0.86863333 Val_loss =  0.44382188 Val_acc =  0.8457\n",
            "Iteration  2077 : Loss =  0.38469192  Acc:  0.86868334 Val_loss =  0.44381222 Val_acc =  0.8457\n",
            "Iteration  2078 : Loss =  0.38466802  Acc:  0.86868334 Val_loss =  0.44380248 Val_acc =  0.8458\n",
            "Iteration  2079 : Loss =  0.38464415  Acc:  0.86868334 Val_loss =  0.44379282 Val_acc =  0.8458\n",
            "Iteration  2080 : Loss =  0.38462025  Acc:  0.8687 Val_loss =  0.4437832 Val_acc =  0.8458\n",
            "Iteration  2081 : Loss =  0.38459638  Acc:  0.86871666 Val_loss =  0.44377354 Val_acc =  0.8457\n",
            "Iteration  2082 : Loss =  0.38457257  Acc:  0.86873335 Val_loss =  0.4437639 Val_acc =  0.8457\n",
            "Iteration  2083 : Loss =  0.38454872  Acc:  0.86873335 Val_loss =  0.4437543 Val_acc =  0.8457\n",
            "Iteration  2084 : Loss =  0.38452494  Acc:  0.8687 Val_loss =  0.44374472 Val_acc =  0.8457\n",
            "Iteration  2085 : Loss =  0.3845011  Acc:  0.8687 Val_loss =  0.44373515 Val_acc =  0.8457\n",
            "Iteration  2086 : Loss =  0.38447735  Acc:  0.86873335 Val_loss =  0.4437256 Val_acc =  0.8457\n",
            "Iteration  2087 : Loss =  0.3844536  Acc:  0.86876667 Val_loss =  0.44371602 Val_acc =  0.8457\n",
            "Iteration  2088 : Loss =  0.3844298  Acc:  0.86875 Val_loss =  0.44370645 Val_acc =  0.8457\n",
            "Iteration  2089 : Loss =  0.38440612  Acc:  0.86878335 Val_loss =  0.44369692 Val_acc =  0.8457\n",
            "Iteration  2090 : Loss =  0.3843824  Acc:  0.86878335 Val_loss =  0.44368744 Val_acc =  0.8457\n",
            "Iteration  2091 : Loss =  0.38435864  Acc:  0.8688 Val_loss =  0.44367793 Val_acc =  0.8457\n",
            "Iteration  2092 : Loss =  0.38433498  Acc:  0.8688 Val_loss =  0.44366845 Val_acc =  0.8457\n",
            "Iteration  2093 : Loss =  0.38431132  Acc:  0.8688 Val_loss =  0.44365898 Val_acc =  0.8457\n",
            "Iteration  2094 : Loss =  0.38428766  Acc:  0.8688 Val_loss =  0.44364956 Val_acc =  0.8457\n",
            "Iteration  2095 : Loss =  0.384264  Acc:  0.86878335 Val_loss =  0.44364014 Val_acc =  0.8457\n",
            "Iteration  2096 : Loss =  0.3842404  Acc:  0.86883336 Val_loss =  0.44363067 Val_acc =  0.8456\n",
            "Iteration  2097 : Loss =  0.38421676  Acc:  0.8688167 Val_loss =  0.44362128 Val_acc =  0.8455\n",
            "Iteration  2098 : Loss =  0.38419318  Acc:  0.8688167 Val_loss =  0.44361192 Val_acc =  0.8455\n",
            "Iteration  2099 : Loss =  0.3841696  Acc:  0.86885 Val_loss =  0.44360253 Val_acc =  0.8455\n",
            "Iteration  2100 : Loss =  0.38414603  Acc:  0.8688667 Val_loss =  0.44359317 Val_acc =  0.8456\n",
            "Iteration  2101 : Loss =  0.38412246  Acc:  0.8689 Val_loss =  0.44358385 Val_acc =  0.8456\n",
            "Iteration  2102 : Loss =  0.38409895  Acc:  0.8689333 Val_loss =  0.44357443 Val_acc =  0.8456\n",
            "Iteration  2103 : Loss =  0.38407543  Acc:  0.86895 Val_loss =  0.44356513 Val_acc =  0.8455\n",
            "Iteration  2104 : Loss =  0.38405192  Acc:  0.86895 Val_loss =  0.4435558 Val_acc =  0.8455\n",
            "Iteration  2105 : Loss =  0.38402846  Acc:  0.86895 Val_loss =  0.44354653 Val_acc =  0.8454\n",
            "Iteration  2106 : Loss =  0.38400495  Acc:  0.86895 Val_loss =  0.44353727 Val_acc =  0.8454\n",
            "Iteration  2107 : Loss =  0.3839815  Acc:  0.86895 Val_loss =  0.44352803 Val_acc =  0.8454\n",
            "Iteration  2108 : Loss =  0.38395807  Acc:  0.86895 Val_loss =  0.44351876 Val_acc =  0.8453\n",
            "Iteration  2109 : Loss =  0.38393462  Acc:  0.8689333 Val_loss =  0.44350952 Val_acc =  0.8453\n",
            "Iteration  2110 : Loss =  0.3839112  Acc:  0.86895 Val_loss =  0.44350028 Val_acc =  0.8453\n",
            "Iteration  2111 : Loss =  0.38388783  Acc:  0.86895 Val_loss =  0.44349107 Val_acc =  0.8453\n",
            "Iteration  2112 : Loss =  0.38386443  Acc:  0.86895 Val_loss =  0.44348183 Val_acc =  0.8454\n",
            "Iteration  2113 : Loss =  0.383841  Acc:  0.86895 Val_loss =  0.4434727 Val_acc =  0.8454\n",
            "Iteration  2114 : Loss =  0.38381767  Acc:  0.8689167 Val_loss =  0.44346353 Val_acc =  0.8454\n",
            "Iteration  2115 : Loss =  0.38379434  Acc:  0.8689333 Val_loss =  0.44345438 Val_acc =  0.8454\n",
            "Iteration  2116 : Loss =  0.38377103  Acc:  0.86895 Val_loss =  0.4434452 Val_acc =  0.8454\n",
            "Iteration  2117 : Loss =  0.38374773  Acc:  0.86896664 Val_loss =  0.44343615 Val_acc =  0.8454\n",
            "Iteration  2118 : Loss =  0.38372442  Acc:  0.8689833 Val_loss =  0.44342697 Val_acc =  0.8454\n",
            "Iteration  2119 : Loss =  0.38370112  Acc:  0.869 Val_loss =  0.44341788 Val_acc =  0.8454\n",
            "Iteration  2120 : Loss =  0.38367787  Acc:  0.869 Val_loss =  0.4434088 Val_acc =  0.8454\n",
            "Iteration  2121 : Loss =  0.38365462  Acc:  0.86896664 Val_loss =  0.4433997 Val_acc =  0.8454\n",
            "Iteration  2122 : Loss =  0.38363138  Acc:  0.869 Val_loss =  0.44339067 Val_acc =  0.8455\n",
            "Iteration  2123 : Loss =  0.38360813  Acc:  0.869 Val_loss =  0.44338164 Val_acc =  0.8454\n",
            "Iteration  2124 : Loss =  0.38358495  Acc:  0.869 Val_loss =  0.4433726 Val_acc =  0.8454\n",
            "Iteration  2125 : Loss =  0.38356176  Acc:  0.869 Val_loss =  0.44336358 Val_acc =  0.8455\n",
            "Iteration  2126 : Loss =  0.38353854  Acc:  0.869 Val_loss =  0.44335458 Val_acc =  0.8455\n",
            "Iteration  2127 : Loss =  0.38351542  Acc:  0.869 Val_loss =  0.4433456 Val_acc =  0.8455\n",
            "Iteration  2128 : Loss =  0.38349226  Acc:  0.869 Val_loss =  0.44333664 Val_acc =  0.8455\n",
            "Iteration  2129 : Loss =  0.38346913  Acc:  0.86901665 Val_loss =  0.44332764 Val_acc =  0.8455\n",
            "Iteration  2130 : Loss =  0.383446  Acc:  0.86903334 Val_loss =  0.44331875 Val_acc =  0.8454\n",
            "Iteration  2131 : Loss =  0.38342288  Acc:  0.86903334 Val_loss =  0.44330975 Val_acc =  0.8454\n",
            "Iteration  2132 : Loss =  0.3833998  Acc:  0.8689833 Val_loss =  0.44330087 Val_acc =  0.8454\n",
            "Iteration  2133 : Loss =  0.38337675  Acc:  0.8689833 Val_loss =  0.44329193 Val_acc =  0.8455\n",
            "Iteration  2134 : Loss =  0.38335368  Acc:  0.869 Val_loss =  0.44328305 Val_acc =  0.8455\n",
            "Iteration  2135 : Loss =  0.3833306  Acc:  0.869 Val_loss =  0.44327417 Val_acc =  0.8455\n",
            "Iteration  2136 : Loss =  0.38330755  Acc:  0.869 Val_loss =  0.44326532 Val_acc =  0.8455\n",
            "Iteration  2137 : Loss =  0.38328457  Acc:  0.86896664 Val_loss =  0.4432565 Val_acc =  0.8455\n",
            "Iteration  2138 : Loss =  0.38326156  Acc:  0.86896664 Val_loss =  0.44324765 Val_acc =  0.8455\n",
            "Iteration  2139 : Loss =  0.38323858  Acc:  0.86895 Val_loss =  0.44323877 Val_acc =  0.8454\n",
            "Iteration  2140 : Loss =  0.3832156  Acc:  0.86895 Val_loss =  0.44323003 Val_acc =  0.8454\n",
            "Iteration  2141 : Loss =  0.38319263  Acc:  0.86896664 Val_loss =  0.44322118 Val_acc =  0.8454\n",
            "Iteration  2142 : Loss =  0.38316965  Acc:  0.86896664 Val_loss =  0.4432124 Val_acc =  0.8455\n",
            "Iteration  2143 : Loss =  0.38314673  Acc:  0.86896664 Val_loss =  0.44320363 Val_acc =  0.8455\n",
            "Iteration  2144 : Loss =  0.38312387  Acc:  0.86896664 Val_loss =  0.44319493 Val_acc =  0.8455\n",
            "Iteration  2145 : Loss =  0.38310096  Acc:  0.86895 Val_loss =  0.44318613 Val_acc =  0.8455\n",
            "Iteration  2146 : Loss =  0.38307807  Acc:  0.8689167 Val_loss =  0.4431774 Val_acc =  0.8455\n",
            "Iteration  2147 : Loss =  0.3830552  Acc:  0.8689333 Val_loss =  0.4431687 Val_acc =  0.8456\n",
            "Iteration  2148 : Loss =  0.38303232  Acc:  0.8689333 Val_loss =  0.44316 Val_acc =  0.8456\n",
            "Iteration  2149 : Loss =  0.3830095  Acc:  0.8689333 Val_loss =  0.44315132 Val_acc =  0.8456\n",
            "Iteration  2150 : Loss =  0.38298666  Acc:  0.86895 Val_loss =  0.44314262 Val_acc =  0.8456\n",
            "Iteration  2151 : Loss =  0.38296384  Acc:  0.8689333 Val_loss =  0.44313398 Val_acc =  0.8456\n",
            "Iteration  2152 : Loss =  0.38294104  Acc:  0.8689333 Val_loss =  0.4431253 Val_acc =  0.8457\n",
            "Iteration  2153 : Loss =  0.38291824  Acc:  0.8689333 Val_loss =  0.4431167 Val_acc =  0.8457\n",
            "Iteration  2154 : Loss =  0.38289544  Acc:  0.8689333 Val_loss =  0.44310805 Val_acc =  0.8457\n",
            "Iteration  2155 : Loss =  0.3828727  Acc:  0.86896664 Val_loss =  0.44309947 Val_acc =  0.8457\n",
            "Iteration  2156 : Loss =  0.38284996  Acc:  0.86896664 Val_loss =  0.44309086 Val_acc =  0.8457\n",
            "Iteration  2157 : Loss =  0.38282722  Acc:  0.86895 Val_loss =  0.44308233 Val_acc =  0.8457\n",
            "Iteration  2158 : Loss =  0.3828045  Acc:  0.86895 Val_loss =  0.44307372 Val_acc =  0.8456\n",
            "Iteration  2159 : Loss =  0.38278183  Acc:  0.869 Val_loss =  0.44306514 Val_acc =  0.8456\n",
            "Iteration  2160 : Loss =  0.38275912  Acc:  0.8689833 Val_loss =  0.44305664 Val_acc =  0.8456\n",
            "Iteration  2161 : Loss =  0.38273644  Acc:  0.8689833 Val_loss =  0.44304806 Val_acc =  0.8456\n",
            "Iteration  2162 : Loss =  0.3827138  Acc:  0.8689833 Val_loss =  0.4430396 Val_acc =  0.8455\n",
            "Iteration  2163 : Loss =  0.38269114  Acc:  0.869 Val_loss =  0.44303104 Val_acc =  0.8455\n",
            "Iteration  2164 : Loss =  0.3826685  Acc:  0.86903334 Val_loss =  0.44302255 Val_acc =  0.8455\n",
            "Iteration  2165 : Loss =  0.3826459  Acc:  0.86901665 Val_loss =  0.44301406 Val_acc =  0.8455\n",
            "Iteration  2166 : Loss =  0.38262329  Acc:  0.86901665 Val_loss =  0.44300565 Val_acc =  0.8455\n",
            "Iteration  2167 : Loss =  0.38260072  Acc:  0.86905 Val_loss =  0.44299716 Val_acc =  0.8455\n",
            "Iteration  2168 : Loss =  0.38257813  Acc:  0.86905 Val_loss =  0.44298878 Val_acc =  0.8455\n",
            "Iteration  2169 : Loss =  0.38255554  Acc:  0.86908334 Val_loss =  0.44298038 Val_acc =  0.8455\n",
            "Iteration  2170 : Loss =  0.382533  Acc:  0.8691 Val_loss =  0.4429719 Val_acc =  0.8455\n",
            "Iteration  2171 : Loss =  0.38251048  Acc:  0.8691 Val_loss =  0.4429635 Val_acc =  0.8455\n",
            "Iteration  2172 : Loss =  0.38248795  Acc:  0.86911666 Val_loss =  0.44295514 Val_acc =  0.8454\n",
            "Iteration  2173 : Loss =  0.38246542  Acc:  0.86915 Val_loss =  0.4429468 Val_acc =  0.8454\n",
            "Iteration  2174 : Loss =  0.38244292  Acc:  0.86915 Val_loss =  0.4429384 Val_acc =  0.8454\n",
            "Iteration  2175 : Loss =  0.38242048  Acc:  0.86915 Val_loss =  0.44293007 Val_acc =  0.8454\n",
            "Iteration  2176 : Loss =  0.382398  Acc:  0.86915 Val_loss =  0.44292173 Val_acc =  0.8454\n",
            "Iteration  2177 : Loss =  0.3823756  Acc:  0.86918336 Val_loss =  0.44291338 Val_acc =  0.8454\n",
            "Iteration  2178 : Loss =  0.38235313  Acc:  0.8692 Val_loss =  0.44290507 Val_acc =  0.8454\n",
            "Iteration  2179 : Loss =  0.38233066  Acc:  0.8692 Val_loss =  0.4428968 Val_acc =  0.8454\n",
            "Iteration  2180 : Loss =  0.38230827  Acc:  0.86925 Val_loss =  0.44288853 Val_acc =  0.8454\n",
            "Iteration  2181 : Loss =  0.38228586  Acc:  0.86925 Val_loss =  0.44288027 Val_acc =  0.8454\n",
            "Iteration  2182 : Loss =  0.3822635  Acc:  0.86925 Val_loss =  0.44287202 Val_acc =  0.8454\n",
            "Iteration  2183 : Loss =  0.3822411  Acc:  0.8692667 Val_loss =  0.44286376 Val_acc =  0.8454\n",
            "Iteration  2184 : Loss =  0.38221875  Acc:  0.8692833 Val_loss =  0.4428555 Val_acc =  0.8454\n",
            "Iteration  2185 : Loss =  0.38219646  Acc:  0.86931664 Val_loss =  0.4428473 Val_acc =  0.8454\n",
            "Iteration  2186 : Loss =  0.38217407  Acc:  0.86931664 Val_loss =  0.44283912 Val_acc =  0.8454\n",
            "Iteration  2187 : Loss =  0.38215178  Acc:  0.86931664 Val_loss =  0.44283095 Val_acc =  0.8454\n",
            "Iteration  2188 : Loss =  0.3821295  Acc:  0.86931664 Val_loss =  0.44282275 Val_acc =  0.8454\n",
            "Iteration  2189 : Loss =  0.38210723  Acc:  0.86931664 Val_loss =  0.4428146 Val_acc =  0.8454\n",
            "Iteration  2190 : Loss =  0.38208497  Acc:  0.8693 Val_loss =  0.44280645 Val_acc =  0.8454\n",
            "Iteration  2191 : Loss =  0.3820627  Acc:  0.8693 Val_loss =  0.4427983 Val_acc =  0.8454\n",
            "Iteration  2192 : Loss =  0.38204044  Acc:  0.8692833 Val_loss =  0.44279018 Val_acc =  0.8454\n",
            "Iteration  2193 : Loss =  0.3820182  Acc:  0.8693 Val_loss =  0.44278204 Val_acc =  0.8454\n",
            "Iteration  2194 : Loss =  0.381996  Acc:  0.8692833 Val_loss =  0.44277397 Val_acc =  0.8454\n",
            "Iteration  2195 : Loss =  0.38197383  Acc:  0.8693 Val_loss =  0.44276586 Val_acc =  0.8453\n",
            "Iteration  2196 : Loss =  0.3819516  Acc:  0.86931664 Val_loss =  0.44275782 Val_acc =  0.8453\n",
            "Iteration  2197 : Loss =  0.38192943  Acc:  0.8693 Val_loss =  0.4427497 Val_acc =  0.8453\n",
            "Iteration  2198 : Loss =  0.38190725  Acc:  0.8692833 Val_loss =  0.4427417 Val_acc =  0.8453\n",
            "Iteration  2199 : Loss =  0.38188508  Acc:  0.8692667 Val_loss =  0.44273365 Val_acc =  0.8453\n",
            "Iteration  2200 : Loss =  0.38186297  Acc:  0.8692667 Val_loss =  0.4427257 Val_acc =  0.8453\n",
            "Iteration  2201 : Loss =  0.38184083  Acc:  0.8692833 Val_loss =  0.44271764 Val_acc =  0.8453\n",
            "Iteration  2202 : Loss =  0.38181874  Acc:  0.8692833 Val_loss =  0.44270962 Val_acc =  0.8453\n",
            "Iteration  2203 : Loss =  0.38179663  Acc:  0.8693 Val_loss =  0.44270167 Val_acc =  0.8453\n",
            "Iteration  2204 : Loss =  0.38177454  Acc:  0.86931664 Val_loss =  0.44269365 Val_acc =  0.8453\n",
            "Iteration  2205 : Loss =  0.38175246  Acc:  0.86931664 Val_loss =  0.4426857 Val_acc =  0.8453\n",
            "Iteration  2206 : Loss =  0.3817304  Acc:  0.86931664 Val_loss =  0.44267774 Val_acc =  0.8453\n",
            "Iteration  2207 : Loss =  0.38170838  Acc:  0.8693 Val_loss =  0.44266984 Val_acc =  0.8452\n",
            "Iteration  2208 : Loss =  0.38168636  Acc:  0.8693333 Val_loss =  0.4426619 Val_acc =  0.8452\n",
            "Iteration  2209 : Loss =  0.38166434  Acc:  0.86931664 Val_loss =  0.44265395 Val_acc =  0.8452\n",
            "Iteration  2210 : Loss =  0.3816423  Acc:  0.86935 Val_loss =  0.4426461 Val_acc =  0.8451\n",
            "Iteration  2211 : Loss =  0.38162035  Acc:  0.86935 Val_loss =  0.4426382 Val_acc =  0.8451\n",
            "Iteration  2212 : Loss =  0.38159838  Acc:  0.86936665 Val_loss =  0.44263032 Val_acc =  0.8451\n",
            "Iteration  2213 : Loss =  0.38157642  Acc:  0.86935 Val_loss =  0.44262245 Val_acc =  0.8451\n",
            "Iteration  2214 : Loss =  0.38155448  Acc:  0.86935 Val_loss =  0.4426146 Val_acc =  0.8452\n",
            "Iteration  2215 : Loss =  0.38153252  Acc:  0.86936665 Val_loss =  0.44260678 Val_acc =  0.8452\n",
            "Iteration  2216 : Loss =  0.38151062  Acc:  0.86936665 Val_loss =  0.44259894 Val_acc =  0.8452\n",
            "Iteration  2217 : Loss =  0.38148868  Acc:  0.86936665 Val_loss =  0.44259116 Val_acc =  0.8452\n",
            "Iteration  2218 : Loss =  0.3814668  Acc:  0.86935 Val_loss =  0.44258335 Val_acc =  0.8452\n",
            "Iteration  2219 : Loss =  0.38144493  Acc:  0.86935 Val_loss =  0.44257557 Val_acc =  0.8453\n",
            "Iteration  2220 : Loss =  0.38142306  Acc:  0.86936665 Val_loss =  0.44256777 Val_acc =  0.8453\n",
            "Iteration  2221 : Loss =  0.38140118  Acc:  0.86935 Val_loss =  0.44256005 Val_acc =  0.8453\n",
            "Iteration  2222 : Loss =  0.38137934  Acc:  0.8694 Val_loss =  0.4425523 Val_acc =  0.8453\n",
            "Iteration  2223 : Loss =  0.38135752  Acc:  0.8694 Val_loss =  0.44254452 Val_acc =  0.8452\n",
            "Iteration  2224 : Loss =  0.3813357  Acc:  0.8694 Val_loss =  0.44253683 Val_acc =  0.8452\n",
            "Iteration  2225 : Loss =  0.3813139  Acc:  0.8694 Val_loss =  0.4425291 Val_acc =  0.8452\n",
            "Iteration  2226 : Loss =  0.3812921  Acc:  0.86938334 Val_loss =  0.4425214 Val_acc =  0.8452\n",
            "Iteration  2227 : Loss =  0.38127032  Acc:  0.86938334 Val_loss =  0.44251373 Val_acc =  0.8452\n",
            "Iteration  2228 : Loss =  0.38124856  Acc:  0.86938334 Val_loss =  0.44250605 Val_acc =  0.8452\n",
            "Iteration  2229 : Loss =  0.38122684  Acc:  0.86938334 Val_loss =  0.4424984 Val_acc =  0.8452\n",
            "Iteration  2230 : Loss =  0.38120505  Acc:  0.86936665 Val_loss =  0.44249073 Val_acc =  0.8453\n",
            "Iteration  2231 : Loss =  0.38118333  Acc:  0.86935 Val_loss =  0.4424831 Val_acc =  0.8453\n",
            "Iteration  2232 : Loss =  0.38116163  Acc:  0.86935 Val_loss =  0.4424755 Val_acc =  0.8451\n",
            "Iteration  2233 : Loss =  0.38113993  Acc:  0.86936665 Val_loss =  0.44246787 Val_acc =  0.8451\n",
            "Iteration  2234 : Loss =  0.38111824  Acc:  0.86936665 Val_loss =  0.44246027 Val_acc =  0.8451\n",
            "Iteration  2235 : Loss =  0.38109657  Acc:  0.86941665 Val_loss =  0.44245264 Val_acc =  0.8451\n",
            "Iteration  2236 : Loss =  0.3810749  Acc:  0.86941665 Val_loss =  0.44244513 Val_acc =  0.8451\n",
            "Iteration  2237 : Loss =  0.38105327  Acc:  0.86941665 Val_loss =  0.44243756 Val_acc =  0.8451\n",
            "Iteration  2238 : Loss =  0.3810316  Acc:  0.86941665 Val_loss =  0.44243 Val_acc =  0.8451\n",
            "Iteration  2239 : Loss =  0.38101003  Acc:  0.86943334 Val_loss =  0.44242242 Val_acc =  0.8451\n",
            "Iteration  2240 : Loss =  0.38098842  Acc:  0.86943334 Val_loss =  0.44241488 Val_acc =  0.8451\n",
            "Iteration  2241 : Loss =  0.38096678  Acc:  0.86945 Val_loss =  0.44240737 Val_acc =  0.8451\n",
            "Iteration  2242 : Loss =  0.38094518  Acc:  0.86946666 Val_loss =  0.4423999 Val_acc =  0.8451\n",
            "Iteration  2243 : Loss =  0.38092363  Acc:  0.86946666 Val_loss =  0.44239238 Val_acc =  0.8451\n",
            "Iteration  2244 : Loss =  0.38090208  Acc:  0.86945 Val_loss =  0.4423849 Val_acc =  0.8451\n",
            "Iteration  2245 : Loss =  0.38088056  Acc:  0.86946666 Val_loss =  0.44237745 Val_acc =  0.8451\n",
            "Iteration  2246 : Loss =  0.38085902  Acc:  0.86946666 Val_loss =  0.44237003 Val_acc =  0.8451\n",
            "Iteration  2247 : Loss =  0.3808375  Acc:  0.8695167 Val_loss =  0.44236255 Val_acc =  0.8452\n",
            "Iteration  2248 : Loss =  0.38081595  Acc:  0.86955 Val_loss =  0.44235513 Val_acc =  0.8452\n",
            "Iteration  2249 : Loss =  0.3807945  Acc:  0.8695667 Val_loss =  0.4423477 Val_acc =  0.8452\n",
            "Iteration  2250 : Loss =  0.38077298  Acc:  0.86953336 Val_loss =  0.44234028 Val_acc =  0.8453\n",
            "Iteration  2251 : Loss =  0.38075152  Acc:  0.86953336 Val_loss =  0.44233292 Val_acc =  0.8453\n",
            "Iteration  2252 : Loss =  0.3807301  Acc:  0.86955 Val_loss =  0.4423255 Val_acc =  0.8453\n",
            "Iteration  2253 : Loss =  0.38070866  Acc:  0.8695667 Val_loss =  0.44231817 Val_acc =  0.8453\n",
            "Iteration  2254 : Loss =  0.38068718  Acc:  0.8695667 Val_loss =  0.44231078 Val_acc =  0.8453\n",
            "Iteration  2255 : Loss =  0.3806658  Acc:  0.8695667 Val_loss =  0.44230342 Val_acc =  0.8453\n",
            "Iteration  2256 : Loss =  0.3806444  Acc:  0.86955 Val_loss =  0.4422961 Val_acc =  0.8453\n",
            "Iteration  2257 : Loss =  0.38062298  Acc:  0.86955 Val_loss =  0.44228876 Val_acc =  0.8453\n",
            "Iteration  2258 : Loss =  0.3806016  Acc:  0.8695833 Val_loss =  0.44228145 Val_acc =  0.8453\n",
            "Iteration  2259 : Loss =  0.38058028  Acc:  0.8695667 Val_loss =  0.44227412 Val_acc =  0.8453\n",
            "Iteration  2260 : Loss =  0.38055888  Acc:  0.8695667 Val_loss =  0.44226688 Val_acc =  0.8453\n",
            "Iteration  2261 : Loss =  0.38053757  Acc:  0.8695667 Val_loss =  0.4422596 Val_acc =  0.8453\n",
            "Iteration  2262 : Loss =  0.38051623  Acc:  0.8695667 Val_loss =  0.44225234 Val_acc =  0.8453\n",
            "Iteration  2263 : Loss =  0.38049492  Acc:  0.8695667 Val_loss =  0.44224507 Val_acc =  0.8453\n",
            "Iteration  2264 : Loss =  0.3804736  Acc:  0.8695667 Val_loss =  0.44223785 Val_acc =  0.8453\n",
            "Iteration  2265 : Loss =  0.3804523  Acc:  0.86955 Val_loss =  0.44223055 Val_acc =  0.8453\n",
            "Iteration  2266 : Loss =  0.38043106  Acc:  0.86955 Val_loss =  0.4422234 Val_acc =  0.8453\n",
            "Iteration  2267 : Loss =  0.38040978  Acc:  0.8695167 Val_loss =  0.44221622 Val_acc =  0.8453\n",
            "Iteration  2268 : Loss =  0.3803885  Acc:  0.8695167 Val_loss =  0.44220898 Val_acc =  0.8453\n",
            "Iteration  2269 : Loss =  0.38036725  Acc:  0.8695167 Val_loss =  0.4422018 Val_acc =  0.8453\n",
            "Iteration  2270 : Loss =  0.38034603  Acc:  0.86953336 Val_loss =  0.44219464 Val_acc =  0.8453\n",
            "Iteration  2271 : Loss =  0.38032487  Acc:  0.8695667 Val_loss =  0.4421875 Val_acc =  0.8453\n",
            "Iteration  2272 : Loss =  0.38030365  Acc:  0.8695833 Val_loss =  0.44218034 Val_acc =  0.8453\n",
            "Iteration  2273 : Loss =  0.38028246  Acc:  0.8695833 Val_loss =  0.44217324 Val_acc =  0.8453\n",
            "Iteration  2274 : Loss =  0.38026127  Acc:  0.8695833 Val_loss =  0.44216606 Val_acc =  0.8453\n",
            "Iteration  2275 : Loss =  0.3802401  Acc:  0.8696167 Val_loss =  0.442159 Val_acc =  0.8453\n",
            "Iteration  2276 : Loss =  0.38021898  Acc:  0.8696167 Val_loss =  0.44215184 Val_acc =  0.8453\n",
            "Iteration  2277 : Loss =  0.3801978  Acc:  0.8696167 Val_loss =  0.44214472 Val_acc =  0.8454\n",
            "Iteration  2278 : Loss =  0.3801767  Acc:  0.8696167 Val_loss =  0.4421377 Val_acc =  0.8455\n",
            "Iteration  2279 : Loss =  0.3801556  Acc:  0.8696167 Val_loss =  0.44213063 Val_acc =  0.8455\n",
            "Iteration  2280 : Loss =  0.38013443  Acc:  0.8696167 Val_loss =  0.4421236 Val_acc =  0.8456\n",
            "Iteration  2281 : Loss =  0.38011333  Acc:  0.8696167 Val_loss =  0.44211656 Val_acc =  0.8456\n",
            "Iteration  2282 : Loss =  0.38009232  Acc:  0.8696167 Val_loss =  0.44210947 Val_acc =  0.8456\n",
            "Iteration  2283 : Loss =  0.38007122  Acc:  0.8696 Val_loss =  0.4421025 Val_acc =  0.8456\n",
            "Iteration  2284 : Loss =  0.38005015  Acc:  0.8696333 Val_loss =  0.44209546 Val_acc =  0.8456\n",
            "Iteration  2285 : Loss =  0.38002914  Acc:  0.8696333 Val_loss =  0.44208848 Val_acc =  0.8456\n",
            "Iteration  2286 : Loss =  0.38000807  Acc:  0.86965 Val_loss =  0.44208148 Val_acc =  0.8457\n",
            "Iteration  2287 : Loss =  0.3799871  Acc:  0.86965 Val_loss =  0.4420745 Val_acc =  0.8457\n",
            "Iteration  2288 : Loss =  0.37996608  Acc:  0.86965 Val_loss =  0.44206756 Val_acc =  0.8457\n",
            "Iteration  2289 : Loss =  0.37994504  Acc:  0.86965 Val_loss =  0.44206065 Val_acc =  0.8457\n",
            "Iteration  2290 : Loss =  0.3799241  Acc:  0.8696667 Val_loss =  0.44205368 Val_acc =  0.8457\n",
            "Iteration  2291 : Loss =  0.37990314  Acc:  0.8696833 Val_loss =  0.44204673 Val_acc =  0.8457\n",
            "Iteration  2292 : Loss =  0.37988216  Acc:  0.8696833 Val_loss =  0.44203985 Val_acc =  0.8457\n",
            "Iteration  2293 : Loss =  0.37986124  Acc:  0.86971664 Val_loss =  0.4420329 Val_acc =  0.8456\n",
            "Iteration  2294 : Loss =  0.37984028  Acc:  0.86973333 Val_loss =  0.44202608 Val_acc =  0.8456\n",
            "Iteration  2295 : Loss =  0.37981936  Acc:  0.86976665 Val_loss =  0.44201913 Val_acc =  0.8456\n",
            "Iteration  2296 : Loss =  0.37979844  Acc:  0.86976665 Val_loss =  0.4420123 Val_acc =  0.8456\n",
            "Iteration  2297 : Loss =  0.37977758  Acc:  0.86976665 Val_loss =  0.44200543 Val_acc =  0.8456\n",
            "Iteration  2298 : Loss =  0.37975672  Acc:  0.86978334 Val_loss =  0.44199857 Val_acc =  0.8456\n",
            "Iteration  2299 : Loss =  0.3797358  Acc:  0.86975 Val_loss =  0.4419917 Val_acc =  0.8457\n",
            "Iteration  2300 : Loss =  0.37971494  Acc:  0.86976665 Val_loss =  0.44198486 Val_acc =  0.8457\n",
            "Iteration  2301 : Loss =  0.3796941  Acc:  0.86975 Val_loss =  0.44197807 Val_acc =  0.8457\n",
            "Iteration  2302 : Loss =  0.37967327  Acc:  0.86976665 Val_loss =  0.4419713 Val_acc =  0.8457\n",
            "Iteration  2303 : Loss =  0.37965244  Acc:  0.86978334 Val_loss =  0.4419645 Val_acc =  0.8457\n",
            "Iteration  2304 : Loss =  0.37963164  Acc:  0.86981666 Val_loss =  0.4419577 Val_acc =  0.8457\n",
            "Iteration  2305 : Loss =  0.37961084  Acc:  0.86983335 Val_loss =  0.44195098 Val_acc =  0.8457\n",
            "Iteration  2306 : Loss =  0.37959003  Acc:  0.86983335 Val_loss =  0.44194418 Val_acc =  0.8456\n",
            "Iteration  2307 : Loss =  0.37956926  Acc:  0.86985 Val_loss =  0.44193745 Val_acc =  0.8457\n",
            "Iteration  2308 : Loss =  0.3795485  Acc:  0.86988336 Val_loss =  0.44193077 Val_acc =  0.8457\n",
            "Iteration  2309 : Loss =  0.3795278  Acc:  0.86988336 Val_loss =  0.44192398 Val_acc =  0.8457\n",
            "Iteration  2310 : Loss =  0.379507  Acc:  0.8699333 Val_loss =  0.44191727 Val_acc =  0.8457\n",
            "Iteration  2311 : Loss =  0.3794863  Acc:  0.8699333 Val_loss =  0.4419106 Val_acc =  0.8457\n",
            "Iteration  2312 : Loss =  0.37946555  Acc:  0.8699333 Val_loss =  0.44190392 Val_acc =  0.8457\n",
            "Iteration  2313 : Loss =  0.37944487  Acc:  0.8699333 Val_loss =  0.4418972 Val_acc =  0.8457\n",
            "Iteration  2314 : Loss =  0.37942418  Acc:  0.8699333 Val_loss =  0.44189057 Val_acc =  0.8457\n",
            "Iteration  2315 : Loss =  0.3794035  Acc:  0.8699333 Val_loss =  0.4418839 Val_acc =  0.8457\n",
            "Iteration  2316 : Loss =  0.37938282  Acc:  0.8699333 Val_loss =  0.44187725 Val_acc =  0.8457\n",
            "Iteration  2317 : Loss =  0.37936217  Acc:  0.86995 Val_loss =  0.4418706 Val_acc =  0.8457\n",
            "Iteration  2318 : Loss =  0.37934154  Acc:  0.86995 Val_loss =  0.441864 Val_acc =  0.8457\n",
            "Iteration  2319 : Loss =  0.3793209  Acc:  0.86995 Val_loss =  0.44185743 Val_acc =  0.8457\n",
            "Iteration  2320 : Loss =  0.3793003  Acc:  0.86995 Val_loss =  0.44185078 Val_acc =  0.8457\n",
            "Iteration  2321 : Loss =  0.37927964  Acc:  0.8699667 Val_loss =  0.4418442 Val_acc =  0.8457\n",
            "Iteration  2322 : Loss =  0.37925908  Acc:  0.8699833 Val_loss =  0.4418376 Val_acc =  0.8457\n",
            "Iteration  2323 : Loss =  0.3792385  Acc:  0.8699833 Val_loss =  0.44183105 Val_acc =  0.8458\n",
            "Iteration  2324 : Loss =  0.3792179  Acc:  0.8700167 Val_loss =  0.44182453 Val_acc =  0.8458\n",
            "Iteration  2325 : Loss =  0.37919736  Acc:  0.8700167 Val_loss =  0.44181797 Val_acc =  0.8458\n",
            "Iteration  2326 : Loss =  0.3791768  Acc:  0.87 Val_loss =  0.4418114 Val_acc =  0.8458\n",
            "Iteration  2327 : Loss =  0.37915626  Acc:  0.8700333 Val_loss =  0.44180495 Val_acc =  0.8458\n",
            "Iteration  2328 : Loss =  0.37913573  Acc:  0.8700333 Val_loss =  0.4417984 Val_acc =  0.8458\n",
            "Iteration  2329 : Loss =  0.37911522  Acc:  0.87005 Val_loss =  0.4417919 Val_acc =  0.8459\n",
            "Iteration  2330 : Loss =  0.37909472  Acc:  0.87005 Val_loss =  0.44178545 Val_acc =  0.846\n",
            "Iteration  2331 : Loss =  0.37907425  Acc:  0.87006664 Val_loss =  0.44177896 Val_acc =  0.846\n",
            "Iteration  2332 : Loss =  0.37905374  Acc:  0.8701 Val_loss =  0.44177246 Val_acc =  0.846\n",
            "Iteration  2333 : Loss =  0.37903327  Acc:  0.87011665 Val_loss =  0.44176602 Val_acc =  0.846\n",
            "Iteration  2334 : Loss =  0.37901282  Acc:  0.87011665 Val_loss =  0.44175956 Val_acc =  0.846\n",
            "Iteration  2335 : Loss =  0.37899238  Acc:  0.87013334 Val_loss =  0.44175312 Val_acc =  0.8461\n",
            "Iteration  2336 : Loss =  0.37897196  Acc:  0.87015 Val_loss =  0.44174674 Val_acc =  0.8461\n",
            "Iteration  2337 : Loss =  0.3789515  Acc:  0.87015 Val_loss =  0.44174027 Val_acc =  0.8461\n",
            "Iteration  2338 : Loss =  0.3789311  Acc:  0.87016666 Val_loss =  0.4417339 Val_acc =  0.8461\n",
            "Iteration  2339 : Loss =  0.37891072  Acc:  0.87016666 Val_loss =  0.44172755 Val_acc =  0.8461\n",
            "Iteration  2340 : Loss =  0.37889034  Acc:  0.87015 Val_loss =  0.44172114 Val_acc =  0.8461\n",
            "Iteration  2341 : Loss =  0.37886998  Acc:  0.87015 Val_loss =  0.44171473 Val_acc =  0.8461\n",
            "Iteration  2342 : Loss =  0.3788496  Acc:  0.87015 Val_loss =  0.4417084 Val_acc =  0.8461\n",
            "Iteration  2343 : Loss =  0.37882924  Acc:  0.87015 Val_loss =  0.44170204 Val_acc =  0.8461\n",
            "Iteration  2344 : Loss =  0.37880892  Acc:  0.87015 Val_loss =  0.4416957 Val_acc =  0.8461\n",
            "Iteration  2345 : Loss =  0.37878853  Acc:  0.87013334 Val_loss =  0.44168934 Val_acc =  0.8461\n",
            "Iteration  2346 : Loss =  0.3787683  Acc:  0.87013334 Val_loss =  0.4416831 Val_acc =  0.846\n",
            "Iteration  2347 : Loss =  0.37874797  Acc:  0.87011665 Val_loss =  0.44167677 Val_acc =  0.846\n",
            "Iteration  2348 : Loss =  0.37872767  Acc:  0.87013334 Val_loss =  0.44167045 Val_acc =  0.846\n",
            "Iteration  2349 : Loss =  0.3787074  Acc:  0.87016666 Val_loss =  0.44166422 Val_acc =  0.846\n",
            "Iteration  2350 : Loss =  0.3786871  Acc:  0.87013334 Val_loss =  0.4416579 Val_acc =  0.846\n",
            "Iteration  2351 : Loss =  0.37866685  Acc:  0.87013334 Val_loss =  0.44165167 Val_acc =  0.846\n",
            "Iteration  2352 : Loss =  0.3786466  Acc:  0.87015 Val_loss =  0.4416454 Val_acc =  0.846\n",
            "Iteration  2353 : Loss =  0.37862638  Acc:  0.87016666 Val_loss =  0.44163916 Val_acc =  0.846\n",
            "Iteration  2354 : Loss =  0.3786061  Acc:  0.87016666 Val_loss =  0.44163296 Val_acc =  0.846\n",
            "Iteration  2355 : Loss =  0.37858593  Acc:  0.87016666 Val_loss =  0.44162676 Val_acc =  0.8461\n",
            "Iteration  2356 : Loss =  0.37856576  Acc:  0.87018335 Val_loss =  0.4416205 Val_acc =  0.8461\n",
            "Iteration  2357 : Loss =  0.37854555  Acc:  0.8702 Val_loss =  0.44161436 Val_acc =  0.8461\n",
            "Iteration  2358 : Loss =  0.37852535  Acc:  0.8702 Val_loss =  0.44160816 Val_acc =  0.8461\n",
            "Iteration  2359 : Loss =  0.3785052  Acc:  0.8702 Val_loss =  0.44160196 Val_acc =  0.8461\n",
            "Iteration  2360 : Loss =  0.37848502  Acc:  0.8702 Val_loss =  0.4415958 Val_acc =  0.8461\n",
            "Iteration  2361 : Loss =  0.3784649  Acc:  0.87021667 Val_loss =  0.44158965 Val_acc =  0.8461\n",
            "Iteration  2362 : Loss =  0.37844476  Acc:  0.87023336 Val_loss =  0.44158348 Val_acc =  0.8461\n",
            "Iteration  2363 : Loss =  0.3784246  Acc:  0.87021667 Val_loss =  0.44157735 Val_acc =  0.8461\n",
            "Iteration  2364 : Loss =  0.37840453  Acc:  0.87023336 Val_loss =  0.44157124 Val_acc =  0.8461\n",
            "Iteration  2365 : Loss =  0.3783844  Acc:  0.87025 Val_loss =  0.44156513 Val_acc =  0.8462\n",
            "Iteration  2366 : Loss =  0.37836432  Acc:  0.87025 Val_loss =  0.44155908 Val_acc =  0.8462\n",
            "Iteration  2367 : Loss =  0.37834427  Acc:  0.87025 Val_loss =  0.44155294 Val_acc =  0.8462\n",
            "Iteration  2368 : Loss =  0.3783242  Acc:  0.87025 Val_loss =  0.4415469 Val_acc =  0.8462\n",
            "Iteration  2369 : Loss =  0.3783041  Acc:  0.87023336 Val_loss =  0.4415408 Val_acc =  0.8463\n",
            "Iteration  2370 : Loss =  0.3782841  Acc:  0.87023336 Val_loss =  0.44153476 Val_acc =  0.8463\n",
            "Iteration  2371 : Loss =  0.37826407  Acc:  0.8702667 Val_loss =  0.4415287 Val_acc =  0.8462\n",
            "Iteration  2372 : Loss =  0.37824404  Acc:  0.8702667 Val_loss =  0.44152266 Val_acc =  0.8462\n",
            "Iteration  2373 : Loss =  0.37822402  Acc:  0.8702667 Val_loss =  0.4415166 Val_acc =  0.8463\n",
            "Iteration  2374 : Loss =  0.37820405  Acc:  0.8702667 Val_loss =  0.44151065 Val_acc =  0.8463\n",
            "Iteration  2375 : Loss =  0.37818405  Acc:  0.8703 Val_loss =  0.44150463 Val_acc =  0.8463\n",
            "Iteration  2376 : Loss =  0.37816405  Acc:  0.8703167 Val_loss =  0.44149864 Val_acc =  0.8463\n",
            "Iteration  2377 : Loss =  0.37814412  Acc:  0.87035 Val_loss =  0.44149262 Val_acc =  0.8463\n",
            "Iteration  2378 : Loss =  0.37812415  Acc:  0.8703333 Val_loss =  0.44148666 Val_acc =  0.8463\n",
            "Iteration  2379 : Loss =  0.37810418  Acc:  0.8703667 Val_loss =  0.44148067 Val_acc =  0.8463\n",
            "Iteration  2380 : Loss =  0.37808424  Acc:  0.8704 Val_loss =  0.4414747 Val_acc =  0.8464\n",
            "Iteration  2381 : Loss =  0.37806436  Acc:  0.8704 Val_loss =  0.4414688 Val_acc =  0.8463\n",
            "Iteration  2382 : Loss =  0.37804443  Acc:  0.8703833 Val_loss =  0.4414629 Val_acc =  0.8463\n",
            "Iteration  2383 : Loss =  0.37802455  Acc:  0.8703833 Val_loss =  0.44145694 Val_acc =  0.8463\n",
            "Iteration  2384 : Loss =  0.3780046  Acc:  0.8703667 Val_loss =  0.441451 Val_acc =  0.8462\n",
            "Iteration  2385 : Loss =  0.37798476  Acc:  0.8703667 Val_loss =  0.4414451 Val_acc =  0.8462\n",
            "Iteration  2386 : Loss =  0.37796488  Acc:  0.8703833 Val_loss =  0.44143927 Val_acc =  0.8462\n",
            "Iteration  2387 : Loss =  0.377945  Acc:  0.87041664 Val_loss =  0.44143334 Val_acc =  0.8462\n",
            "Iteration  2388 : Loss =  0.3779252  Acc:  0.87043333 Val_loss =  0.4414275 Val_acc =  0.8462\n",
            "Iteration  2389 : Loss =  0.37790534  Acc:  0.87043333 Val_loss =  0.44142163 Val_acc =  0.8462\n",
            "Iteration  2390 : Loss =  0.37788552  Acc:  0.87043333 Val_loss =  0.44141582 Val_acc =  0.8463\n",
            "Iteration  2391 : Loss =  0.37786573  Acc:  0.87045 Val_loss =  0.44140998 Val_acc =  0.8463\n",
            "Iteration  2392 : Loss =  0.3778459  Acc:  0.87046665 Val_loss =  0.4414041 Val_acc =  0.8463\n",
            "Iteration  2393 : Loss =  0.37782612  Acc:  0.8705 Val_loss =  0.44139835 Val_acc =  0.8463\n",
            "Iteration  2394 : Loss =  0.37780637  Acc:  0.87051666 Val_loss =  0.44139248 Val_acc =  0.8463\n",
            "Iteration  2395 : Loss =  0.37778658  Acc:  0.8705 Val_loss =  0.44138667 Val_acc =  0.8463\n",
            "Iteration  2396 : Loss =  0.37776682  Acc:  0.8705 Val_loss =  0.44138092 Val_acc =  0.8463\n",
            "Iteration  2397 : Loss =  0.37774706  Acc:  0.87051666 Val_loss =  0.44137514 Val_acc =  0.8463\n",
            "Iteration  2398 : Loss =  0.37772733  Acc:  0.87051666 Val_loss =  0.44136932 Val_acc =  0.8466\n",
            "Iteration  2399 : Loss =  0.37770763  Acc:  0.87053335 Val_loss =  0.44136357 Val_acc =  0.8465\n",
            "Iteration  2400 : Loss =  0.37768793  Acc:  0.87055 Val_loss =  0.44135785 Val_acc =  0.8465\n",
            "Iteration  2401 : Loss =  0.37766823  Acc:  0.87055 Val_loss =  0.44135216 Val_acc =  0.8464\n",
            "Iteration  2402 : Loss =  0.3776485  Acc:  0.87055 Val_loss =  0.44134638 Val_acc =  0.8464\n",
            "Iteration  2403 : Loss =  0.37762883  Acc:  0.8706 Val_loss =  0.44134068 Val_acc =  0.8464\n",
            "Iteration  2404 : Loss =  0.3776092  Acc:  0.8706 Val_loss =  0.44133496 Val_acc =  0.8464\n",
            "Iteration  2405 : Loss =  0.37758952  Acc:  0.87065 Val_loss =  0.4413293 Val_acc =  0.8464\n",
            "Iteration  2406 : Loss =  0.37756988  Acc:  0.87065 Val_loss =  0.44132358 Val_acc =  0.8464\n",
            "Iteration  2407 : Loss =  0.3775502  Acc:  0.87065 Val_loss =  0.44131792 Val_acc =  0.8464\n",
            "Iteration  2408 : Loss =  0.3775306  Acc:  0.87065 Val_loss =  0.4413123 Val_acc =  0.8464\n",
            "Iteration  2409 : Loss =  0.377511  Acc:  0.8706667 Val_loss =  0.4413066 Val_acc =  0.8464\n",
            "Iteration  2410 : Loss =  0.3774914  Acc:  0.8706833 Val_loss =  0.441301 Val_acc =  0.8464\n",
            "Iteration  2411 : Loss =  0.37747177  Acc:  0.8706833 Val_loss =  0.44129536 Val_acc =  0.8466\n",
            "Iteration  2412 : Loss =  0.37745222  Acc:  0.8706833 Val_loss =  0.44128975 Val_acc =  0.8466\n",
            "Iteration  2413 : Loss =  0.37743264  Acc:  0.8706833 Val_loss =  0.4412841 Val_acc =  0.8466\n",
            "Iteration  2414 : Loss =  0.3774131  Acc:  0.8706667 Val_loss =  0.44127852 Val_acc =  0.8466\n",
            "Iteration  2415 : Loss =  0.3773935  Acc:  0.8706833 Val_loss =  0.4412729 Val_acc =  0.8466\n",
            "Iteration  2416 : Loss =  0.377374  Acc:  0.8707167 Val_loss =  0.44126728 Val_acc =  0.8466\n",
            "Iteration  2417 : Loss =  0.37735447  Acc:  0.87075 Val_loss =  0.4412617 Val_acc =  0.8467\n",
            "Iteration  2418 : Loss =  0.37733492  Acc:  0.8707333 Val_loss =  0.44125617 Val_acc =  0.8466\n",
            "Iteration  2419 : Loss =  0.37731543  Acc:  0.87075 Val_loss =  0.4412506 Val_acc =  0.8466\n",
            "Iteration  2420 : Loss =  0.3772959  Acc:  0.87076664 Val_loss =  0.44124508 Val_acc =  0.8466\n",
            "Iteration  2421 : Loss =  0.37727645  Acc:  0.87075 Val_loss =  0.44123957 Val_acc =  0.8466\n",
            "Iteration  2422 : Loss =  0.37725696  Acc:  0.87075 Val_loss =  0.441234 Val_acc =  0.8467\n",
            "Iteration  2423 : Loss =  0.3772375  Acc:  0.8707333 Val_loss =  0.4412285 Val_acc =  0.8467\n",
            "Iteration  2424 : Loss =  0.37721804  Acc:  0.87075 Val_loss =  0.441223 Val_acc =  0.8467\n",
            "Iteration  2425 : Loss =  0.3771986  Acc:  0.87075 Val_loss =  0.44121748 Val_acc =  0.8467\n",
            "Iteration  2426 : Loss =  0.37717918  Acc:  0.8707333 Val_loss =  0.441212 Val_acc =  0.8467\n",
            "Iteration  2427 : Loss =  0.37715974  Acc:  0.8707333 Val_loss =  0.44120654 Val_acc =  0.8467\n",
            "Iteration  2428 : Loss =  0.37714037  Acc:  0.8707333 Val_loss =  0.44120106 Val_acc =  0.8467\n",
            "Iteration  2429 : Loss =  0.37712097  Acc:  0.8707333 Val_loss =  0.4411956 Val_acc =  0.8467\n",
            "Iteration  2430 : Loss =  0.37710157  Acc:  0.8707333 Val_loss =  0.44119012 Val_acc =  0.8467\n",
            "Iteration  2431 : Loss =  0.37708217  Acc:  0.8707333 Val_loss =  0.44118476 Val_acc =  0.8467\n",
            "Iteration  2432 : Loss =  0.3770628  Acc:  0.8707333 Val_loss =  0.44117934 Val_acc =  0.8467\n",
            "Iteration  2433 : Loss =  0.37704343  Acc:  0.8707167 Val_loss =  0.44117388 Val_acc =  0.8467\n",
            "Iteration  2434 : Loss =  0.37702408  Acc:  0.8707167 Val_loss =  0.44116852 Val_acc =  0.8467\n",
            "Iteration  2435 : Loss =  0.3770047  Acc:  0.87075 Val_loss =  0.4411631 Val_acc =  0.8468\n",
            "Iteration  2436 : Loss =  0.37698543  Acc:  0.87075 Val_loss =  0.44115773 Val_acc =  0.8468\n",
            "Iteration  2437 : Loss =  0.3769661  Acc:  0.8707833 Val_loss =  0.44115233 Val_acc =  0.8468\n",
            "Iteration  2438 : Loss =  0.3769468  Acc:  0.8707833 Val_loss =  0.44114697 Val_acc =  0.8466\n",
            "Iteration  2439 : Loss =  0.37692747  Acc:  0.8707833 Val_loss =  0.4411416 Val_acc =  0.8466\n",
            "Iteration  2440 : Loss =  0.3769082  Acc:  0.8708 Val_loss =  0.44113627 Val_acc =  0.8466\n",
            "Iteration  2441 : Loss =  0.37688893  Acc:  0.87081665 Val_loss =  0.44113097 Val_acc =  0.8466\n",
            "Iteration  2442 : Loss =  0.37686965  Acc:  0.87083334 Val_loss =  0.44112563 Val_acc =  0.8466\n",
            "Iteration  2443 : Loss =  0.37685043  Acc:  0.87085 Val_loss =  0.44112033 Val_acc =  0.8466\n",
            "Iteration  2444 : Loss =  0.37683117  Acc:  0.87083334 Val_loss =  0.441115 Val_acc =  0.8466\n",
            "Iteration  2445 : Loss =  0.37681192  Acc:  0.87083334 Val_loss =  0.44110972 Val_acc =  0.8466\n",
            "Iteration  2446 : Loss =  0.3767927  Acc:  0.87085 Val_loss =  0.44110438 Val_acc =  0.8466\n",
            "Iteration  2447 : Loss =  0.37677348  Acc:  0.87088335 Val_loss =  0.44109917 Val_acc =  0.8466\n",
            "Iteration  2448 : Loss =  0.37675428  Acc:  0.87088335 Val_loss =  0.44109386 Val_acc =  0.8466\n",
            "Iteration  2449 : Loss =  0.3767351  Acc:  0.87088335 Val_loss =  0.44108862 Val_acc =  0.8466\n",
            "Iteration  2450 : Loss =  0.3767159  Acc:  0.87091666 Val_loss =  0.44108334 Val_acc =  0.8466\n",
            "Iteration  2451 : Loss =  0.37669674  Acc:  0.87091666 Val_loss =  0.44107813 Val_acc =  0.8466\n",
            "Iteration  2452 : Loss =  0.3766776  Acc:  0.87091666 Val_loss =  0.4410729 Val_acc =  0.8466\n",
            "Iteration  2453 : Loss =  0.37665844  Acc:  0.87091666 Val_loss =  0.44106773 Val_acc =  0.8466\n",
            "Iteration  2454 : Loss =  0.37663928  Acc:  0.87091666 Val_loss =  0.4410625 Val_acc =  0.8466\n",
            "Iteration  2455 : Loss =  0.37662017  Acc:  0.87091666 Val_loss =  0.44105732 Val_acc =  0.8467\n",
            "Iteration  2456 : Loss =  0.37660104  Acc:  0.87093335 Val_loss =  0.4410521 Val_acc =  0.8467\n",
            "Iteration  2457 : Loss =  0.3765819  Acc:  0.8709667 Val_loss =  0.44104692 Val_acc =  0.8467\n",
            "Iteration  2458 : Loss =  0.37656283  Acc:  0.87098336 Val_loss =  0.4410417 Val_acc =  0.8467\n",
            "Iteration  2459 : Loss =  0.37654376  Acc:  0.87098336 Val_loss =  0.44103658 Val_acc =  0.8467\n",
            "Iteration  2460 : Loss =  0.3765247  Acc:  0.87098336 Val_loss =  0.44103146 Val_acc =  0.8467\n",
            "Iteration  2461 : Loss =  0.3765056  Acc:  0.8710333 Val_loss =  0.44102627 Val_acc =  0.8466\n",
            "Iteration  2462 : Loss =  0.3764865  Acc:  0.8710333 Val_loss =  0.44102114 Val_acc =  0.8466\n",
            "Iteration  2463 : Loss =  0.37646747  Acc:  0.8710167 Val_loss =  0.44101602 Val_acc =  0.8466\n",
            "Iteration  2464 : Loss =  0.37644842  Acc:  0.8710333 Val_loss =  0.44101095 Val_acc =  0.8466\n",
            "Iteration  2465 : Loss =  0.3764294  Acc:  0.8710333 Val_loss =  0.4410058 Val_acc =  0.8466\n",
            "Iteration  2466 : Loss =  0.37641042  Acc:  0.8710333 Val_loss =  0.44100073 Val_acc =  0.8466\n",
            "Iteration  2467 : Loss =  0.3763914  Acc:  0.8710167 Val_loss =  0.4409956 Val_acc =  0.8466\n",
            "Iteration  2468 : Loss =  0.3763724  Acc:  0.871 Val_loss =  0.44099057 Val_acc =  0.8466\n",
            "Iteration  2469 : Loss =  0.37635338  Acc:  0.871 Val_loss =  0.4409855 Val_acc =  0.8466\n",
            "Iteration  2470 : Loss =  0.37633443  Acc:  0.87098336 Val_loss =  0.44098046 Val_acc =  0.8466\n",
            "Iteration  2471 : Loss =  0.37631547  Acc:  0.871 Val_loss =  0.4409754 Val_acc =  0.8466\n",
            "Iteration  2472 : Loss =  0.3762965  Acc:  0.87098336 Val_loss =  0.44097042 Val_acc =  0.8465\n",
            "Iteration  2473 : Loss =  0.37627754  Acc:  0.8710167 Val_loss =  0.44096532 Val_acc =  0.8465\n",
            "Iteration  2474 : Loss =  0.37625858  Acc:  0.871 Val_loss =  0.4409603 Val_acc =  0.8465\n",
            "Iteration  2475 : Loss =  0.37623972  Acc:  0.87098336 Val_loss =  0.4409553 Val_acc =  0.8465\n",
            "Iteration  2476 : Loss =  0.37622076  Acc:  0.87098336 Val_loss =  0.4409503 Val_acc =  0.8465\n",
            "Iteration  2477 : Loss =  0.3762019  Acc:  0.87098336 Val_loss =  0.44094536 Val_acc =  0.8465\n",
            "Iteration  2478 : Loss =  0.37618294  Acc:  0.87098336 Val_loss =  0.44094032 Val_acc =  0.8465\n",
            "Iteration  2479 : Loss =  0.37616405  Acc:  0.87095 Val_loss =  0.4409354 Val_acc =  0.8465\n",
            "Iteration  2480 : Loss =  0.37614518  Acc:  0.87095 Val_loss =  0.44093043 Val_acc =  0.8465\n",
            "Iteration  2481 : Loss =  0.37612635  Acc:  0.87095 Val_loss =  0.44092548 Val_acc =  0.8465\n",
            "Iteration  2482 : Loss =  0.37610748  Acc:  0.87095 Val_loss =  0.4409205 Val_acc =  0.8465\n",
            "Iteration  2483 : Loss =  0.37608865  Acc:  0.87095 Val_loss =  0.44091558 Val_acc =  0.8465\n",
            "Iteration  2484 : Loss =  0.37606978  Acc:  0.8709667 Val_loss =  0.4409107 Val_acc =  0.8465\n",
            "Iteration  2485 : Loss =  0.37605098  Acc:  0.87095 Val_loss =  0.44090575 Val_acc =  0.8464\n",
            "Iteration  2486 : Loss =  0.3760321  Acc:  0.87091666 Val_loss =  0.4409009 Val_acc =  0.8464\n",
            "Iteration  2487 : Loss =  0.37601334  Acc:  0.8709 Val_loss =  0.440896 Val_acc =  0.8464\n",
            "Iteration  2488 : Loss =  0.37599456  Acc:  0.8709 Val_loss =  0.44089106 Val_acc =  0.8464\n",
            "Iteration  2489 : Loss =  0.37597576  Acc:  0.87091666 Val_loss =  0.44088617 Val_acc =  0.8464\n",
            "Iteration  2490 : Loss =  0.37595695  Acc:  0.87091666 Val_loss =  0.44088134 Val_acc =  0.8464\n",
            "Iteration  2491 : Loss =  0.3759382  Acc:  0.87091666 Val_loss =  0.44087645 Val_acc =  0.8464\n",
            "Iteration  2492 : Loss =  0.37591946  Acc:  0.87093335 Val_loss =  0.44087163 Val_acc =  0.8464\n",
            "Iteration  2493 : Loss =  0.37590072  Acc:  0.87093335 Val_loss =  0.4408668 Val_acc =  0.8463\n",
            "Iteration  2494 : Loss =  0.375882  Acc:  0.87091666 Val_loss =  0.44086197 Val_acc =  0.8463\n",
            "Iteration  2495 : Loss =  0.37586325  Acc:  0.87091666 Val_loss =  0.44085714 Val_acc =  0.8463\n",
            "Iteration  2496 : Loss =  0.37584454  Acc:  0.87091666 Val_loss =  0.44085234 Val_acc =  0.8462\n",
            "Iteration  2497 : Loss =  0.37582585  Acc:  0.87095 Val_loss =  0.44084755 Val_acc =  0.8462\n",
            "Iteration  2498 : Loss =  0.37580714  Acc:  0.8709667 Val_loss =  0.44084278 Val_acc =  0.8462\n",
            "Iteration  2499 : Loss =  0.37578842  Acc:  0.87098336 Val_loss =  0.44083798 Val_acc =  0.8462\n",
            "Iteration  2500 : Loss =  0.37576976  Acc:  0.871 Val_loss =  0.4408332 Val_acc =  0.8462\n",
            "Iteration  2501 : Loss =  0.37575108  Acc:  0.871 Val_loss =  0.4408284 Val_acc =  0.8462\n",
            "Iteration  2502 : Loss =  0.37573242  Acc:  0.8710333 Val_loss =  0.44082367 Val_acc =  0.8462\n",
            "Iteration  2503 : Loss =  0.3757138  Acc:  0.87105 Val_loss =  0.44081894 Val_acc =  0.8462\n",
            "Iteration  2504 : Loss =  0.3756951  Acc:  0.87105 Val_loss =  0.44081417 Val_acc =  0.8462\n",
            "Iteration  2505 : Loss =  0.37567648  Acc:  0.8710833 Val_loss =  0.44080946 Val_acc =  0.8462\n",
            "Iteration  2506 : Loss =  0.3756579  Acc:  0.87111664 Val_loss =  0.44080475 Val_acc =  0.8462\n",
            "Iteration  2507 : Loss =  0.37563926  Acc:  0.87111664 Val_loss =  0.44080004 Val_acc =  0.8462\n",
            "Iteration  2508 : Loss =  0.3756207  Acc:  0.87111664 Val_loss =  0.44079536 Val_acc =  0.8462\n",
            "Iteration  2509 : Loss =  0.3756021  Acc:  0.87111664 Val_loss =  0.44079062 Val_acc =  0.8461\n",
            "Iteration  2510 : Loss =  0.37558353  Acc:  0.8711333 Val_loss =  0.44078594 Val_acc =  0.8461\n",
            "Iteration  2511 : Loss =  0.37556493  Acc:  0.8711333 Val_loss =  0.4407813 Val_acc =  0.8461\n",
            "Iteration  2512 : Loss =  0.3755464  Acc:  0.8711333 Val_loss =  0.44077662 Val_acc =  0.8461\n",
            "Iteration  2513 : Loss =  0.37552783  Acc:  0.87116665 Val_loss =  0.44077197 Val_acc =  0.8461\n",
            "Iteration  2514 : Loss =  0.37550932  Acc:  0.87116665 Val_loss =  0.44076735 Val_acc =  0.8461\n",
            "Iteration  2515 : Loss =  0.37549075  Acc:  0.87116665 Val_loss =  0.4407627 Val_acc =  0.8462\n",
            "Iteration  2516 : Loss =  0.37547225  Acc:  0.87116665 Val_loss =  0.44075805 Val_acc =  0.8462\n",
            "Iteration  2517 : Loss =  0.3754537  Acc:  0.87116665 Val_loss =  0.44075343 Val_acc =  0.8462\n",
            "Iteration  2518 : Loss =  0.37543523  Acc:  0.87118334 Val_loss =  0.44074884 Val_acc =  0.8462\n",
            "Iteration  2519 : Loss =  0.37541673  Acc:  0.87118334 Val_loss =  0.44074425 Val_acc =  0.8462\n",
            "Iteration  2520 : Loss =  0.37539825  Acc:  0.87118334 Val_loss =  0.44073966 Val_acc =  0.8462\n",
            "Iteration  2521 : Loss =  0.37537974  Acc:  0.87115 Val_loss =  0.44073507 Val_acc =  0.8462\n",
            "Iteration  2522 : Loss =  0.3753613  Acc:  0.87115 Val_loss =  0.44073048 Val_acc =  0.8462\n",
            "Iteration  2523 : Loss =  0.37534285  Acc:  0.87118334 Val_loss =  0.44072592 Val_acc =  0.8462\n",
            "Iteration  2524 : Loss =  0.37532443  Acc:  0.87116665 Val_loss =  0.4407214 Val_acc =  0.8462\n",
            "Iteration  2525 : Loss =  0.37530598  Acc:  0.87116665 Val_loss =  0.44071683 Val_acc =  0.8462\n",
            "Iteration  2526 : Loss =  0.37528756  Acc:  0.87118334 Val_loss =  0.4407123 Val_acc =  0.8462\n",
            "Iteration  2527 : Loss =  0.37526914  Acc:  0.87118334 Val_loss =  0.44070777 Val_acc =  0.8462\n",
            "Iteration  2528 : Loss =  0.37525073  Acc:  0.87121665 Val_loss =  0.4407032 Val_acc =  0.8462\n",
            "Iteration  2529 : Loss =  0.37523237  Acc:  0.8712 Val_loss =  0.44069874 Val_acc =  0.8462\n",
            "Iteration  2530 : Loss =  0.37521392  Acc:  0.8712 Val_loss =  0.44069424 Val_acc =  0.8462\n",
            "Iteration  2531 : Loss =  0.37519556  Acc:  0.8712 Val_loss =  0.44068974 Val_acc =  0.8463\n",
            "Iteration  2532 : Loss =  0.37517717  Acc:  0.8712 Val_loss =  0.4406853 Val_acc =  0.8463\n",
            "Iteration  2533 : Loss =  0.37515885  Acc:  0.8712 Val_loss =  0.4406808 Val_acc =  0.8463\n",
            "Iteration  2534 : Loss =  0.3751405  Acc:  0.8712 Val_loss =  0.44067636 Val_acc =  0.8462\n",
            "Iteration  2535 : Loss =  0.37512213  Acc:  0.8712 Val_loss =  0.44067186 Val_acc =  0.8462\n",
            "Iteration  2536 : Loss =  0.37510383  Acc:  0.87121665 Val_loss =  0.44066742 Val_acc =  0.8462\n",
            "Iteration  2537 : Loss =  0.37508547  Acc:  0.87121665 Val_loss =  0.44066298 Val_acc =  0.8462\n",
            "Iteration  2538 : Loss =  0.37506717  Acc:  0.87123334 Val_loss =  0.44065854 Val_acc =  0.8461\n",
            "Iteration  2539 : Loss =  0.3750489  Acc:  0.87123334 Val_loss =  0.44065416 Val_acc =  0.8461\n",
            "Iteration  2540 : Loss =  0.37503058  Acc:  0.87125 Val_loss =  0.44064975 Val_acc =  0.8461\n",
            "Iteration  2541 : Loss =  0.3750123  Acc:  0.87125 Val_loss =  0.44064537 Val_acc =  0.8461\n",
            "Iteration  2542 : Loss =  0.374994  Acc:  0.87125 Val_loss =  0.44064093 Val_acc =  0.8461\n",
            "Iteration  2543 : Loss =  0.37497577  Acc:  0.87125 Val_loss =  0.44063658 Val_acc =  0.8462\n",
            "Iteration  2544 : Loss =  0.37495753  Acc:  0.8713 Val_loss =  0.44063222 Val_acc =  0.8462\n",
            "Iteration  2545 : Loss =  0.37493926  Acc:  0.8713 Val_loss =  0.44062784 Val_acc =  0.8462\n",
            "Iteration  2546 : Loss =  0.37492102  Acc:  0.8713 Val_loss =  0.44062343 Val_acc =  0.8462\n",
            "Iteration  2547 : Loss =  0.37490278  Acc:  0.87128335 Val_loss =  0.44061914 Val_acc =  0.8462\n",
            "Iteration  2548 : Loss =  0.37488458  Acc:  0.8713167 Val_loss =  0.44061476 Val_acc =  0.8462\n",
            "Iteration  2549 : Loss =  0.3748664  Acc:  0.8713 Val_loss =  0.44061044 Val_acc =  0.8462\n",
            "Iteration  2550 : Loss =  0.3748482  Acc:  0.87126666 Val_loss =  0.44060615 Val_acc =  0.8462\n",
            "Iteration  2551 : Loss =  0.37483  Acc:  0.87126666 Val_loss =  0.4406018 Val_acc =  0.8462\n",
            "Iteration  2552 : Loss =  0.37481183  Acc:  0.87128335 Val_loss =  0.4405975 Val_acc =  0.8462\n",
            "Iteration  2553 : Loss =  0.37479365  Acc:  0.87128335 Val_loss =  0.4405932 Val_acc =  0.8462\n",
            "Iteration  2554 : Loss =  0.37477547  Acc:  0.87128335 Val_loss =  0.44058892 Val_acc =  0.8463\n",
            "Iteration  2555 : Loss =  0.37475732  Acc:  0.87128335 Val_loss =  0.44058466 Val_acc =  0.8464\n",
            "Iteration  2556 : Loss =  0.3747392  Acc:  0.87128335 Val_loss =  0.44058037 Val_acc =  0.8464\n",
            "Iteration  2557 : Loss =  0.37472105  Acc:  0.8713 Val_loss =  0.44057614 Val_acc =  0.8464\n",
            "Iteration  2558 : Loss =  0.37470293  Acc:  0.8713 Val_loss =  0.44057187 Val_acc =  0.8464\n",
            "Iteration  2559 : Loss =  0.37468484  Acc:  0.87133336 Val_loss =  0.4405676 Val_acc =  0.8464\n",
            "Iteration  2560 : Loss =  0.37466672  Acc:  0.87133336 Val_loss =  0.44056338 Val_acc =  0.8464\n",
            "Iteration  2561 : Loss =  0.3746486  Acc:  0.87135 Val_loss =  0.44055918 Val_acc =  0.8464\n",
            "Iteration  2562 : Loss =  0.37463054  Acc:  0.8713167 Val_loss =  0.44055498 Val_acc =  0.8465\n",
            "Iteration  2563 : Loss =  0.37461248  Acc:  0.8713 Val_loss =  0.44055074 Val_acc =  0.8465\n",
            "Iteration  2564 : Loss =  0.3745944  Acc:  0.8713167 Val_loss =  0.44054654 Val_acc =  0.8465\n",
            "Iteration  2565 : Loss =  0.3745763  Acc:  0.8713167 Val_loss =  0.44054234 Val_acc =  0.8465\n",
            "Iteration  2566 : Loss =  0.37455827  Acc:  0.8713167 Val_loss =  0.4405382 Val_acc =  0.8465\n",
            "Iteration  2567 : Loss =  0.37454024  Acc:  0.8713167 Val_loss =  0.440534 Val_acc =  0.8464\n",
            "Iteration  2568 : Loss =  0.3745222  Acc:  0.87128335 Val_loss =  0.44052982 Val_acc =  0.8464\n",
            "Iteration  2569 : Loss =  0.37450418  Acc:  0.8713167 Val_loss =  0.44052568 Val_acc =  0.8464\n",
            "Iteration  2570 : Loss =  0.37448618  Acc:  0.8713167 Val_loss =  0.44052148 Val_acc =  0.8464\n",
            "Iteration  2571 : Loss =  0.37446818  Acc:  0.8713167 Val_loss =  0.4405174 Val_acc =  0.8464\n",
            "Iteration  2572 : Loss =  0.37445018  Acc:  0.8713167 Val_loss =  0.44051328 Val_acc =  0.8464\n",
            "Iteration  2573 : Loss =  0.37443218  Acc:  0.8713667 Val_loss =  0.44050914 Val_acc =  0.8465\n",
            "Iteration  2574 : Loss =  0.3744142  Acc:  0.8713667 Val_loss =  0.44050503 Val_acc =  0.8466\n",
            "Iteration  2575 : Loss =  0.37439623  Acc:  0.87133336 Val_loss =  0.4405009 Val_acc =  0.8466\n",
            "Iteration  2576 : Loss =  0.3743783  Acc:  0.87133336 Val_loss =  0.44049683 Val_acc =  0.8466\n",
            "Iteration  2577 : Loss =  0.37436035  Acc:  0.87133336 Val_loss =  0.44049278 Val_acc =  0.8466\n",
            "Iteration  2578 : Loss =  0.37434238  Acc:  0.87135 Val_loss =  0.44048867 Val_acc =  0.8467\n",
            "Iteration  2579 : Loss =  0.37432447  Acc:  0.87133336 Val_loss =  0.44048458 Val_acc =  0.8467\n",
            "Iteration  2580 : Loss =  0.37430653  Acc:  0.8713167 Val_loss =  0.44048056 Val_acc =  0.8467\n",
            "Iteration  2581 : Loss =  0.37428862  Acc:  0.8713167 Val_loss =  0.44047648 Val_acc =  0.8467\n",
            "Iteration  2582 : Loss =  0.3742707  Acc:  0.8713167 Val_loss =  0.44047245 Val_acc =  0.8467\n",
            "Iteration  2583 : Loss =  0.37425283  Acc:  0.8713 Val_loss =  0.44046837 Val_acc =  0.8467\n",
            "Iteration  2584 : Loss =  0.37423497  Acc:  0.8713167 Val_loss =  0.44046435 Val_acc =  0.8467\n",
            "Iteration  2585 : Loss =  0.37421706  Acc:  0.87133336 Val_loss =  0.44046035 Val_acc =  0.8467\n",
            "Iteration  2586 : Loss =  0.3741992  Acc:  0.87133336 Val_loss =  0.44045636 Val_acc =  0.8467\n",
            "Iteration  2587 : Loss =  0.37418136  Acc:  0.87133336 Val_loss =  0.44045234 Val_acc =  0.8467\n",
            "Iteration  2588 : Loss =  0.37416348  Acc:  0.87135 Val_loss =  0.44044834 Val_acc =  0.8467\n",
            "Iteration  2589 : Loss =  0.37414563  Acc:  0.87135 Val_loss =  0.44044438 Val_acc =  0.8468\n",
            "Iteration  2590 : Loss =  0.37412786  Acc:  0.87135 Val_loss =  0.4404404 Val_acc =  0.8468\n",
            "Iteration  2591 : Loss =  0.37411  Acc:  0.87135 Val_loss =  0.44043642 Val_acc =  0.8469\n",
            "Iteration  2592 : Loss =  0.3740922  Acc:  0.87135 Val_loss =  0.44043246 Val_acc =  0.8469\n",
            "Iteration  2593 : Loss =  0.37407437  Acc:  0.8713833 Val_loss =  0.44042853 Val_acc =  0.8469\n",
            "Iteration  2594 : Loss =  0.37405658  Acc:  0.8713833 Val_loss =  0.44042462 Val_acc =  0.8468\n",
            "Iteration  2595 : Loss =  0.37403882  Acc:  0.8713833 Val_loss =  0.44042066 Val_acc =  0.8468\n",
            "Iteration  2596 : Loss =  0.37402102  Acc:  0.8714167 Val_loss =  0.4404167 Val_acc =  0.8468\n",
            "Iteration  2597 : Loss =  0.37400326  Acc:  0.8714167 Val_loss =  0.4404128 Val_acc =  0.8468\n",
            "Iteration  2598 : Loss =  0.37398553  Acc:  0.8714 Val_loss =  0.4404089 Val_acc =  0.8468\n",
            "Iteration  2599 : Loss =  0.37396774  Acc:  0.8714 Val_loss =  0.44040498 Val_acc =  0.8468\n",
            "Iteration  2600 : Loss =  0.37395  Acc:  0.8714 Val_loss =  0.44040108 Val_acc =  0.8468\n",
            "Iteration  2601 : Loss =  0.3739323  Acc:  0.8713833 Val_loss =  0.4403972 Val_acc =  0.8468\n",
            "Iteration  2602 : Loss =  0.37391454  Acc:  0.8713833 Val_loss =  0.44039336 Val_acc =  0.8469\n",
            "Iteration  2603 : Loss =  0.37389684  Acc:  0.8714 Val_loss =  0.44038945 Val_acc =  0.8469\n",
            "Iteration  2604 : Loss =  0.37387913  Acc:  0.8714167 Val_loss =  0.44038564 Val_acc =  0.847\n",
            "Iteration  2605 : Loss =  0.37386143  Acc:  0.8714333 Val_loss =  0.44038174 Val_acc =  0.847\n",
            "Iteration  2606 : Loss =  0.3738438  Acc:  0.8714667 Val_loss =  0.44037792 Val_acc =  0.847\n",
            "Iteration  2607 : Loss =  0.3738261  Acc:  0.87145 Val_loss =  0.44037414 Val_acc =  0.847\n",
            "Iteration  2608 : Loss =  0.37380838  Acc:  0.87145 Val_loss =  0.44037026 Val_acc =  0.847\n",
            "Iteration  2609 : Loss =  0.37379074  Acc:  0.8714667 Val_loss =  0.44036645 Val_acc =  0.847\n",
            "Iteration  2610 : Loss =  0.37377307  Acc:  0.8714667 Val_loss =  0.44036263 Val_acc =  0.8469\n",
            "Iteration  2611 : Loss =  0.37375543  Acc:  0.87145 Val_loss =  0.44035885 Val_acc =  0.8469\n",
            "Iteration  2612 : Loss =  0.3737378  Acc:  0.8714667 Val_loss =  0.44035503 Val_acc =  0.8469\n",
            "Iteration  2613 : Loss =  0.37372017  Acc:  0.8714667 Val_loss =  0.44035128 Val_acc =  0.8469\n",
            "Iteration  2614 : Loss =  0.37370262  Acc:  0.8715 Val_loss =  0.44034746 Val_acc =  0.8469\n",
            "Iteration  2615 : Loss =  0.37368497  Acc:  0.8715 Val_loss =  0.44034374 Val_acc =  0.8469\n",
            "Iteration  2616 : Loss =  0.37366736  Acc:  0.87151664 Val_loss =  0.44033998 Val_acc =  0.8469\n",
            "Iteration  2617 : Loss =  0.3736498  Acc:  0.87151664 Val_loss =  0.44033623 Val_acc =  0.8469\n",
            "Iteration  2618 : Loss =  0.3736322  Acc:  0.87153333 Val_loss =  0.44033247 Val_acc =  0.8469\n",
            "Iteration  2619 : Loss =  0.37361464  Acc:  0.87153333 Val_loss =  0.44032875 Val_acc =  0.8469\n",
            "Iteration  2620 : Loss =  0.37359706  Acc:  0.87153333 Val_loss =  0.440325 Val_acc =  0.8469\n",
            "Iteration  2621 : Loss =  0.3735795  Acc:  0.87153333 Val_loss =  0.4403213 Val_acc =  0.8469\n",
            "Iteration  2622 : Loss =  0.37356198  Acc:  0.87153333 Val_loss =  0.44031757 Val_acc =  0.8469\n",
            "Iteration  2623 : Loss =  0.3735444  Acc:  0.87153333 Val_loss =  0.44031388 Val_acc =  0.8469\n",
            "Iteration  2624 : Loss =  0.3735269  Acc:  0.87153333 Val_loss =  0.4403102 Val_acc =  0.8469\n",
            "Iteration  2625 : Loss =  0.37350938  Acc:  0.87155 Val_loss =  0.44030648 Val_acc =  0.8469\n",
            "Iteration  2626 : Loss =  0.37349182  Acc:  0.87155 Val_loss =  0.44030282 Val_acc =  0.8469\n",
            "Iteration  2627 : Loss =  0.37347436  Acc:  0.87155 Val_loss =  0.44029912 Val_acc =  0.8469\n",
            "Iteration  2628 : Loss =  0.37345684  Acc:  0.87155 Val_loss =  0.44029552 Val_acc =  0.847\n",
            "Iteration  2629 : Loss =  0.3734394  Acc:  0.87158334 Val_loss =  0.44029188 Val_acc =  0.847\n",
            "Iteration  2630 : Loss =  0.37342188  Acc:  0.87156665 Val_loss =  0.44028825 Val_acc =  0.847\n",
            "Iteration  2631 : Loss =  0.3734044  Acc:  0.8716 Val_loss =  0.44028458 Val_acc =  0.847\n",
            "Iteration  2632 : Loss =  0.37338698  Acc:  0.87161666 Val_loss =  0.44028094 Val_acc =  0.8471\n",
            "Iteration  2633 : Loss =  0.37336954  Acc:  0.87163335 Val_loss =  0.44027734 Val_acc =  0.8471\n",
            "Iteration  2634 : Loss =  0.37335205  Acc:  0.87163335 Val_loss =  0.44027373 Val_acc =  0.8471\n",
            "Iteration  2635 : Loss =  0.37333465  Acc:  0.8716 Val_loss =  0.44027013 Val_acc =  0.8471\n",
            "Iteration  2636 : Loss =  0.3733172  Acc:  0.8716 Val_loss =  0.4402665 Val_acc =  0.8473\n",
            "Iteration  2637 : Loss =  0.3732998  Acc:  0.8716 Val_loss =  0.440263 Val_acc =  0.8473\n",
            "Iteration  2638 : Loss =  0.3732824  Acc:  0.87161666 Val_loss =  0.44025937 Val_acc =  0.8473\n",
            "Iteration  2639 : Loss =  0.373265  Acc:  0.87165 Val_loss =  0.44025582 Val_acc =  0.8472\n",
            "Iteration  2640 : Loss =  0.37324762  Acc:  0.87165 Val_loss =  0.44025224 Val_acc =  0.8471\n",
            "Iteration  2641 : Loss =  0.37323022  Acc:  0.87165 Val_loss =  0.44024873 Val_acc =  0.8471\n",
            "Iteration  2642 : Loss =  0.3732128  Acc:  0.87165 Val_loss =  0.44024515 Val_acc =  0.8471\n",
            "Iteration  2643 : Loss =  0.37319547  Acc:  0.87165 Val_loss =  0.4402416 Val_acc =  0.8471\n",
            "Iteration  2644 : Loss =  0.37317812  Acc:  0.87168336 Val_loss =  0.4402381 Val_acc =  0.8471\n",
            "Iteration  2645 : Loss =  0.37316078  Acc:  0.87168336 Val_loss =  0.44023457 Val_acc =  0.8471\n",
            "Iteration  2646 : Loss =  0.37314346  Acc:  0.87166667 Val_loss =  0.44023106 Val_acc =  0.8471\n",
            "Iteration  2647 : Loss =  0.37312606  Acc:  0.87166667 Val_loss =  0.44022754 Val_acc =  0.8471\n",
            "Iteration  2648 : Loss =  0.37310877  Acc:  0.87168336 Val_loss =  0.44022402 Val_acc =  0.8471\n",
            "Iteration  2649 : Loss =  0.37309146  Acc:  0.87168336 Val_loss =  0.4402206 Val_acc =  0.8471\n",
            "Iteration  2650 : Loss =  0.37307414  Acc:  0.87168336 Val_loss =  0.44021708 Val_acc =  0.8471\n",
            "Iteration  2651 : Loss =  0.37305686  Acc:  0.87168336 Val_loss =  0.44021362 Val_acc =  0.847\n",
            "Iteration  2652 : Loss =  0.37303957  Acc:  0.87168336 Val_loss =  0.44021016 Val_acc =  0.847\n",
            "Iteration  2653 : Loss =  0.3730223  Acc:  0.8717 Val_loss =  0.44020668 Val_acc =  0.847\n",
            "Iteration  2654 : Loss =  0.373005  Acc:  0.8717167 Val_loss =  0.44020322 Val_acc =  0.8471\n",
            "Iteration  2655 : Loss =  0.37298775  Acc:  0.8717167 Val_loss =  0.4401998 Val_acc =  0.8471\n",
            "Iteration  2656 : Loss =  0.37297052  Acc:  0.87175 Val_loss =  0.4401964 Val_acc =  0.8471\n",
            "Iteration  2657 : Loss =  0.37295327  Acc:  0.8717667 Val_loss =  0.4401929 Val_acc =  0.847\n",
            "Iteration  2658 : Loss =  0.372936  Acc:  0.8717667 Val_loss =  0.44018954 Val_acc =  0.847\n",
            "Iteration  2659 : Loss =  0.3729188  Acc:  0.8717667 Val_loss =  0.44018614 Val_acc =  0.8469\n",
            "Iteration  2660 : Loss =  0.37290156  Acc:  0.87175 Val_loss =  0.44018272 Val_acc =  0.8469\n",
            "Iteration  2661 : Loss =  0.37288436  Acc:  0.87175 Val_loss =  0.4401793 Val_acc =  0.8469\n",
            "Iteration  2662 : Loss =  0.3728672  Acc:  0.8717667 Val_loss =  0.44017598 Val_acc =  0.8468\n",
            "Iteration  2663 : Loss =  0.37284997  Acc:  0.8717667 Val_loss =  0.44017255 Val_acc =  0.8468\n",
            "Iteration  2664 : Loss =  0.37283278  Acc:  0.8717667 Val_loss =  0.4401692 Val_acc =  0.8468\n",
            "Iteration  2665 : Loss =  0.37281564  Acc:  0.87175 Val_loss =  0.44016582 Val_acc =  0.8468\n",
            "Iteration  2666 : Loss =  0.37279844  Acc:  0.8718 Val_loss =  0.4401625 Val_acc =  0.8469\n",
            "Iteration  2667 : Loss =  0.37278125  Acc:  0.8718167 Val_loss =  0.44015914 Val_acc =  0.8469\n",
            "Iteration  2668 : Loss =  0.37276414  Acc:  0.8718167 Val_loss =  0.44015577 Val_acc =  0.8468\n",
            "Iteration  2669 : Loss =  0.37274697  Acc:  0.8718333 Val_loss =  0.44015244 Val_acc =  0.8468\n",
            "Iteration  2670 : Loss =  0.3727298  Acc:  0.8718333 Val_loss =  0.44014913 Val_acc =  0.8468\n",
            "Iteration  2671 : Loss =  0.3727127  Acc:  0.8718167 Val_loss =  0.4401458 Val_acc =  0.8468\n",
            "Iteration  2672 : Loss =  0.37269557  Acc:  0.87185 Val_loss =  0.44014257 Val_acc =  0.8468\n",
            "Iteration  2673 : Loss =  0.3726785  Acc:  0.87185 Val_loss =  0.44013926 Val_acc =  0.8469\n",
            "Iteration  2674 : Loss =  0.37266135  Acc:  0.8718333 Val_loss =  0.44013593 Val_acc =  0.8469\n",
            "Iteration  2675 : Loss =  0.37264428  Acc:  0.8718333 Val_loss =  0.44013268 Val_acc =  0.8469\n",
            "Iteration  2676 : Loss =  0.3726272  Acc:  0.8718333 Val_loss =  0.4401294 Val_acc =  0.8469\n",
            "Iteration  2677 : Loss =  0.3726101  Acc:  0.8718333 Val_loss =  0.44012612 Val_acc =  0.8469\n",
            "Iteration  2678 : Loss =  0.37259305  Acc:  0.8718333 Val_loss =  0.44012284 Val_acc =  0.8469\n",
            "Iteration  2679 : Loss =  0.37257597  Acc:  0.87185 Val_loss =  0.44011962 Val_acc =  0.8469\n",
            "Iteration  2680 : Loss =  0.37255895  Acc:  0.87185 Val_loss =  0.44011635 Val_acc =  0.8469\n",
            "Iteration  2681 : Loss =  0.3725419  Acc:  0.87186664 Val_loss =  0.44011313 Val_acc =  0.8469\n",
            "Iteration  2682 : Loss =  0.37252483  Acc:  0.87188333 Val_loss =  0.4401099 Val_acc =  0.8469\n",
            "Iteration  2683 : Loss =  0.3725078  Acc:  0.87188333 Val_loss =  0.4401067 Val_acc =  0.8469\n",
            "Iteration  2684 : Loss =  0.37249082  Acc:  0.8719 Val_loss =  0.44010347 Val_acc =  0.8469\n",
            "Iteration  2685 : Loss =  0.37247384  Acc:  0.8719 Val_loss =  0.44010028 Val_acc =  0.8469\n",
            "Iteration  2686 : Loss =  0.3724568  Acc:  0.8719 Val_loss =  0.44009706 Val_acc =  0.8469\n",
            "Iteration  2687 : Loss =  0.37243977  Acc:  0.8719 Val_loss =  0.4400939 Val_acc =  0.8469\n",
            "Iteration  2688 : Loss =  0.37242278  Acc:  0.87188333 Val_loss =  0.4400907 Val_acc =  0.8469\n",
            "Iteration  2689 : Loss =  0.3724058  Acc:  0.87188333 Val_loss =  0.4400875 Val_acc =  0.8469\n",
            "Iteration  2690 : Loss =  0.37238887  Acc:  0.8719 Val_loss =  0.44008437 Val_acc =  0.8469\n",
            "Iteration  2691 : Loss =  0.3723719  Acc:  0.87188333 Val_loss =  0.4400812 Val_acc =  0.8469\n",
            "Iteration  2692 : Loss =  0.37235495  Acc:  0.87191665 Val_loss =  0.44007802 Val_acc =  0.8469\n",
            "Iteration  2693 : Loss =  0.372338  Acc:  0.8719 Val_loss =  0.4400749 Val_acc =  0.8469\n",
            "Iteration  2694 : Loss =  0.37232107  Acc:  0.8719 Val_loss =  0.4400718 Val_acc =  0.8469\n",
            "Iteration  2695 : Loss =  0.37230414  Acc:  0.8719 Val_loss =  0.44006866 Val_acc =  0.8469\n",
            "Iteration  2696 : Loss =  0.37228724  Acc:  0.87193334 Val_loss =  0.44006553 Val_acc =  0.8469\n",
            "Iteration  2697 : Loss =  0.37227032  Acc:  0.87195 Val_loss =  0.4400624 Val_acc =  0.8469\n",
            "Iteration  2698 : Loss =  0.3722534  Acc:  0.87195 Val_loss =  0.44005927 Val_acc =  0.8469\n",
            "Iteration  2699 : Loss =  0.37223646  Acc:  0.87195 Val_loss =  0.4400562 Val_acc =  0.8469\n",
            "Iteration  2700 : Loss =  0.3722196  Acc:  0.87196666 Val_loss =  0.44005314 Val_acc =  0.8469\n",
            "Iteration  2701 : Loss =  0.3722027  Acc:  0.87196666 Val_loss =  0.44005004 Val_acc =  0.8469\n",
            "Iteration  2702 : Loss =  0.3721859  Acc:  0.87198335 Val_loss =  0.44004697 Val_acc =  0.8469\n",
            "Iteration  2703 : Loss =  0.372169  Acc:  0.872 Val_loss =  0.4400439 Val_acc =  0.8469\n",
            "Iteration  2704 : Loss =  0.37215215  Acc:  0.872 Val_loss =  0.44004086 Val_acc =  0.8469\n",
            "Iteration  2705 : Loss =  0.37213528  Acc:  0.872 Val_loss =  0.4400378 Val_acc =  0.8469\n",
            "Iteration  2706 : Loss =  0.3721184  Acc:  0.87201667 Val_loss =  0.44003472 Val_acc =  0.8469\n",
            "Iteration  2707 : Loss =  0.3721016  Acc:  0.8720667 Val_loss =  0.44003174 Val_acc =  0.8469\n",
            "Iteration  2708 : Loss =  0.3720848  Acc:  0.8721 Val_loss =  0.4400287 Val_acc =  0.8469\n",
            "Iteration  2709 : Loss =  0.37206796  Acc:  0.8721 Val_loss =  0.4400257 Val_acc =  0.8469\n",
            "Iteration  2710 : Loss =  0.37205118  Acc:  0.8721167 Val_loss =  0.44002265 Val_acc =  0.8469\n",
            "Iteration  2711 : Loss =  0.37203434  Acc:  0.8721167 Val_loss =  0.44001964 Val_acc =  0.8469\n",
            "Iteration  2712 : Loss =  0.3720176  Acc:  0.8721667 Val_loss =  0.4400166 Val_acc =  0.8469\n",
            "Iteration  2713 : Loss =  0.37200078  Acc:  0.87215 Val_loss =  0.44001368 Val_acc =  0.8468\n",
            "Iteration  2714 : Loss =  0.371984  Acc:  0.87215 Val_loss =  0.44001076 Val_acc =  0.8468\n",
            "Iteration  2715 : Loss =  0.37196726  Acc:  0.87215 Val_loss =  0.44000772 Val_acc =  0.8468\n",
            "Iteration  2716 : Loss =  0.37195048  Acc:  0.87215 Val_loss =  0.44000474 Val_acc =  0.8468\n",
            "Iteration  2717 : Loss =  0.37193373  Acc:  0.8721833 Val_loss =  0.44000182 Val_acc =  0.8468\n",
            "Iteration  2718 : Loss =  0.37191698  Acc:  0.8721833 Val_loss =  0.43999884 Val_acc =  0.8468\n",
            "Iteration  2719 : Loss =  0.37190026  Acc:  0.8722 Val_loss =  0.43999588 Val_acc =  0.8469\n",
            "Iteration  2720 : Loss =  0.37188354  Acc:  0.87221664 Val_loss =  0.43999296 Val_acc =  0.8469\n",
            "Iteration  2721 : Loss =  0.3718668  Acc:  0.87223333 Val_loss =  0.43999004 Val_acc =  0.8469\n",
            "Iteration  2722 : Loss =  0.37185007  Acc:  0.87223333 Val_loss =  0.43998712 Val_acc =  0.8469\n",
            "Iteration  2723 : Loss =  0.37183338  Acc:  0.87223333 Val_loss =  0.43998417 Val_acc =  0.8469\n",
            "Iteration  2724 : Loss =  0.37181666  Acc:  0.87225 Val_loss =  0.4399813 Val_acc =  0.8469\n",
            "Iteration  2725 : Loss =  0.3718  Acc:  0.87225 Val_loss =  0.43997842 Val_acc =  0.8469\n",
            "Iteration  2726 : Loss =  0.37178335  Acc:  0.87223333 Val_loss =  0.4399755 Val_acc =  0.8469\n",
            "Iteration  2727 : Loss =  0.37176666  Acc:  0.87223333 Val_loss =  0.4399726 Val_acc =  0.8469\n",
            "Iteration  2728 : Loss =  0.37175  Acc:  0.87223333 Val_loss =  0.43996972 Val_acc =  0.8469\n",
            "Iteration  2729 : Loss =  0.37173334  Acc:  0.87223333 Val_loss =  0.43996686 Val_acc =  0.8469\n",
            "Iteration  2730 : Loss =  0.37171668  Acc:  0.87223333 Val_loss =  0.43996397 Val_acc =  0.847\n",
            "Iteration  2731 : Loss =  0.37170008  Acc:  0.87223333 Val_loss =  0.4399612 Val_acc =  0.847\n",
            "Iteration  2732 : Loss =  0.37168342  Acc:  0.87223333 Val_loss =  0.4399583 Val_acc =  0.847\n",
            "Iteration  2733 : Loss =  0.3716668  Acc:  0.87223333 Val_loss =  0.43995547 Val_acc =  0.847\n",
            "Iteration  2734 : Loss =  0.3716502  Acc:  0.87223333 Val_loss =  0.43995264 Val_acc =  0.847\n",
            "Iteration  2735 : Loss =  0.37163356  Acc:  0.87223333 Val_loss =  0.4399498 Val_acc =  0.847\n",
            "Iteration  2736 : Loss =  0.371617  Acc:  0.87223333 Val_loss =  0.43994698 Val_acc =  0.847\n",
            "Iteration  2737 : Loss =  0.3716004  Acc:  0.87225 Val_loss =  0.43994418 Val_acc =  0.847\n",
            "Iteration  2738 : Loss =  0.3715838  Acc:  0.87225 Val_loss =  0.4399414 Val_acc =  0.8471\n",
            "Iteration  2739 : Loss =  0.37156722  Acc:  0.87225 Val_loss =  0.43993858 Val_acc =  0.847\n",
            "Iteration  2740 : Loss =  0.37155065  Acc:  0.87223333 Val_loss =  0.4399358 Val_acc =  0.847\n",
            "Iteration  2741 : Loss =  0.37153408  Acc:  0.87223333 Val_loss =  0.439933 Val_acc =  0.847\n",
            "Iteration  2742 : Loss =  0.3715175  Acc:  0.87223333 Val_loss =  0.43993026 Val_acc =  0.847\n",
            "Iteration  2743 : Loss =  0.37150097  Acc:  0.87223333 Val_loss =  0.4399275 Val_acc =  0.847\n",
            "Iteration  2744 : Loss =  0.37148446  Acc:  0.87225 Val_loss =  0.43992472 Val_acc =  0.847\n",
            "Iteration  2745 : Loss =  0.37146792  Acc:  0.87226665 Val_loss =  0.43992198 Val_acc =  0.847\n",
            "Iteration  2746 : Loss =  0.37145138  Acc:  0.87226665 Val_loss =  0.43991923 Val_acc =  0.847\n",
            "Iteration  2747 : Loss =  0.3714349  Acc:  0.87225 Val_loss =  0.4399165 Val_acc =  0.847\n",
            "Iteration  2748 : Loss =  0.37141836  Acc:  0.87226665 Val_loss =  0.43991378 Val_acc =  0.847\n",
            "Iteration  2749 : Loss =  0.37140188  Acc:  0.87228334 Val_loss =  0.43991104 Val_acc =  0.847\n",
            "Iteration  2750 : Loss =  0.37138543  Acc:  0.87228334 Val_loss =  0.43990836 Val_acc =  0.847\n",
            "Iteration  2751 : Loss =  0.37136889  Acc:  0.87228334 Val_loss =  0.4399056 Val_acc =  0.847\n",
            "Iteration  2752 : Loss =  0.37135243  Acc:  0.87228334 Val_loss =  0.43990293 Val_acc =  0.847\n",
            "Iteration  2753 : Loss =  0.37133592  Acc:  0.87228334 Val_loss =  0.43990028 Val_acc =  0.8469\n",
            "Iteration  2754 : Loss =  0.3713195  Acc:  0.87228334 Val_loss =  0.43989757 Val_acc =  0.8469\n",
            "Iteration  2755 : Loss =  0.37130305  Acc:  0.87228334 Val_loss =  0.43989488 Val_acc =  0.8469\n",
            "Iteration  2756 : Loss =  0.3712866  Acc:  0.87228334 Val_loss =  0.43989217 Val_acc =  0.8469\n",
            "Iteration  2757 : Loss =  0.37127018  Acc:  0.87228334 Val_loss =  0.43988955 Val_acc =  0.8469\n",
            "Iteration  2758 : Loss =  0.37125373  Acc:  0.87228334 Val_loss =  0.43988693 Val_acc =  0.8469\n",
            "Iteration  2759 : Loss =  0.3712373  Acc:  0.87228334 Val_loss =  0.43988428 Val_acc =  0.8469\n",
            "Iteration  2760 : Loss =  0.3712209  Acc:  0.87228334 Val_loss =  0.43988165 Val_acc =  0.8469\n",
            "Iteration  2761 : Loss =  0.3712045  Acc:  0.8723 Val_loss =  0.439879 Val_acc =  0.8469\n",
            "Iteration  2762 : Loss =  0.37118807  Acc:  0.8723 Val_loss =  0.43987638 Val_acc =  0.8469\n",
            "Iteration  2763 : Loss =  0.37117168  Acc:  0.87231666 Val_loss =  0.43987373 Val_acc =  0.8469\n",
            "Iteration  2764 : Loss =  0.37115535  Acc:  0.87231666 Val_loss =  0.4398711 Val_acc =  0.8469\n",
            "Iteration  2765 : Loss =  0.37113893  Acc:  0.87231666 Val_loss =  0.4398685 Val_acc =  0.8469\n",
            "Iteration  2766 : Loss =  0.3711226  Acc:  0.87231666 Val_loss =  0.43986592 Val_acc =  0.8469\n",
            "Iteration  2767 : Loss =  0.3711062  Acc:  0.87236667 Val_loss =  0.43986332 Val_acc =  0.8469\n",
            "Iteration  2768 : Loss =  0.3710899  Acc:  0.87235 Val_loss =  0.43986073 Val_acc =  0.8469\n",
            "Iteration  2769 : Loss =  0.3710735  Acc:  0.87236667 Val_loss =  0.43985817 Val_acc =  0.8469\n",
            "Iteration  2770 : Loss =  0.37105715  Acc:  0.87236667 Val_loss =  0.43985558 Val_acc =  0.8468\n",
            "Iteration  2771 : Loss =  0.37104085  Acc:  0.87235 Val_loss =  0.439853 Val_acc =  0.8468\n",
            "Iteration  2772 : Loss =  0.37102455  Acc:  0.87236667 Val_loss =  0.43985048 Val_acc =  0.8468\n",
            "Iteration  2773 : Loss =  0.37100822  Acc:  0.87236667 Val_loss =  0.43984795 Val_acc =  0.8468\n",
            "Iteration  2774 : Loss =  0.37099192  Acc:  0.87236667 Val_loss =  0.4398454 Val_acc =  0.8468\n",
            "Iteration  2775 : Loss =  0.3709756  Acc:  0.87238336 Val_loss =  0.43984288 Val_acc =  0.8468\n",
            "Iteration  2776 : Loss =  0.3709593  Acc:  0.8724 Val_loss =  0.43984035 Val_acc =  0.8466\n",
            "Iteration  2777 : Loss =  0.37094304  Acc:  0.87238336 Val_loss =  0.43983778 Val_acc =  0.8467\n",
            "Iteration  2778 : Loss =  0.37092677  Acc:  0.8724167 Val_loss =  0.4398353 Val_acc =  0.8467\n",
            "Iteration  2779 : Loss =  0.37091053  Acc:  0.8724 Val_loss =  0.4398328 Val_acc =  0.8467\n",
            "Iteration  2780 : Loss =  0.37089422  Acc:  0.87238336 Val_loss =  0.43983027 Val_acc =  0.8467\n",
            "Iteration  2781 : Loss =  0.37087798  Acc:  0.87238336 Val_loss =  0.43982783 Val_acc =  0.8467\n",
            "Iteration  2782 : Loss =  0.37086174  Acc:  0.87235 Val_loss =  0.43982536 Val_acc =  0.8467\n",
            "Iteration  2783 : Loss =  0.3708455  Acc:  0.87235 Val_loss =  0.43982285 Val_acc =  0.8467\n",
            "Iteration  2784 : Loss =  0.37082925  Acc:  0.87235 Val_loss =  0.4398204 Val_acc =  0.8467\n",
            "Iteration  2785 : Loss =  0.37081304  Acc:  0.87235 Val_loss =  0.43981797 Val_acc =  0.8467\n",
            "Iteration  2786 : Loss =  0.3707968  Acc:  0.87236667 Val_loss =  0.43981552 Val_acc =  0.8467\n",
            "Iteration  2787 : Loss =  0.3707806  Acc:  0.87236667 Val_loss =  0.43981308 Val_acc =  0.8467\n",
            "Iteration  2788 : Loss =  0.37076446  Acc:  0.87236667 Val_loss =  0.43981063 Val_acc =  0.8467\n",
            "Iteration  2789 : Loss =  0.37074822  Acc:  0.87236667 Val_loss =  0.43980816 Val_acc =  0.8468\n",
            "Iteration  2790 : Loss =  0.37073207  Acc:  0.87238336 Val_loss =  0.43980578 Val_acc =  0.8468\n",
            "Iteration  2791 : Loss =  0.37071586  Acc:  0.87238336 Val_loss =  0.43980333 Val_acc =  0.8468\n",
            "Iteration  2792 : Loss =  0.3706997  Acc:  0.8724 Val_loss =  0.4398009 Val_acc =  0.8468\n",
            "Iteration  2793 : Loss =  0.37068352  Acc:  0.8724 Val_loss =  0.43979853 Val_acc =  0.8468\n",
            "Iteration  2794 : Loss =  0.37066737  Acc:  0.8724 Val_loss =  0.4397961 Val_acc =  0.8468\n",
            "Iteration  2795 : Loss =  0.37065125  Acc:  0.8724 Val_loss =  0.43979374 Val_acc =  0.8467\n",
            "Iteration  2796 : Loss =  0.3706351  Acc:  0.8724167 Val_loss =  0.43979135 Val_acc =  0.8467\n",
            "Iteration  2797 : Loss =  0.37061897  Acc:  0.8724333 Val_loss =  0.43978897 Val_acc =  0.8467\n",
            "Iteration  2798 : Loss =  0.37060285  Acc:  0.87245 Val_loss =  0.4397866 Val_acc =  0.8467\n",
            "Iteration  2799 : Loss =  0.37058672  Acc:  0.87245 Val_loss =  0.43978423 Val_acc =  0.8467\n",
            "Iteration  2800 : Loss =  0.37057057  Acc:  0.8724833 Val_loss =  0.43978187 Val_acc =  0.8467\n",
            "Iteration  2801 : Loss =  0.3705545  Acc:  0.8725 Val_loss =  0.43977955 Val_acc =  0.8467\n",
            "Iteration  2802 : Loss =  0.3705384  Acc:  0.8725 Val_loss =  0.4397772 Val_acc =  0.8467\n",
            "Iteration  2803 : Loss =  0.37052232  Acc:  0.8725 Val_loss =  0.4397749 Val_acc =  0.8467\n",
            "Iteration  2804 : Loss =  0.37050626  Acc:  0.8725 Val_loss =  0.43977252 Val_acc =  0.8467\n",
            "Iteration  2805 : Loss =  0.37049016  Acc:  0.8725 Val_loss =  0.43977022 Val_acc =  0.8466\n",
            "Iteration  2806 : Loss =  0.3704741  Acc:  0.8724833 Val_loss =  0.43976793 Val_acc =  0.8466\n",
            "Iteration  2807 : Loss =  0.37045804  Acc:  0.8725 Val_loss =  0.43976563 Val_acc =  0.8466\n",
            "Iteration  2808 : Loss =  0.370442  Acc:  0.8725 Val_loss =  0.43976328 Val_acc =  0.8466\n",
            "Iteration  2809 : Loss =  0.37042594  Acc:  0.8725 Val_loss =  0.43976104 Val_acc =  0.8466\n",
            "Iteration  2810 : Loss =  0.37040994  Acc:  0.8725167 Val_loss =  0.43975878 Val_acc =  0.8466\n",
            "Iteration  2811 : Loss =  0.37039387  Acc:  0.8725 Val_loss =  0.43975645 Val_acc =  0.8466\n",
            "Iteration  2812 : Loss =  0.37037787  Acc:  0.8725 Val_loss =  0.4397542 Val_acc =  0.8466\n",
            "Iteration  2813 : Loss =  0.37036183  Acc:  0.8725167 Val_loss =  0.43975195 Val_acc =  0.8466\n",
            "Iteration  2814 : Loss =  0.37034583  Acc:  0.8725167 Val_loss =  0.43974966 Val_acc =  0.8466\n",
            "Iteration  2815 : Loss =  0.37032983  Acc:  0.8725167 Val_loss =  0.43974742 Val_acc =  0.8466\n",
            "Iteration  2816 : Loss =  0.37031382  Acc:  0.8725167 Val_loss =  0.43974516 Val_acc =  0.8466\n",
            "Iteration  2817 : Loss =  0.37029785  Acc:  0.8725167 Val_loss =  0.43974298 Val_acc =  0.8466\n",
            "Iteration  2818 : Loss =  0.3702819  Acc:  0.8725 Val_loss =  0.4397407 Val_acc =  0.8466\n",
            "Iteration  2819 : Loss =  0.37026587  Acc:  0.8725 Val_loss =  0.43973848 Val_acc =  0.8466\n",
            "Iteration  2820 : Loss =  0.37024993  Acc:  0.8724833 Val_loss =  0.43973622 Val_acc =  0.8466\n",
            "Iteration  2821 : Loss =  0.37023398  Acc:  0.8724833 Val_loss =  0.43973407 Val_acc =  0.8466\n",
            "Iteration  2822 : Loss =  0.37021804  Acc:  0.8724667 Val_loss =  0.43973184 Val_acc =  0.8466\n",
            "Iteration  2823 : Loss =  0.3702021  Acc:  0.8724667 Val_loss =  0.4397297 Val_acc =  0.8467\n",
            "Iteration  2824 : Loss =  0.3701862  Acc:  0.8725 Val_loss =  0.4397275 Val_acc =  0.8467\n",
            "Iteration  2825 : Loss =  0.37017024  Acc:  0.8725 Val_loss =  0.43972528 Val_acc =  0.8467\n",
            "Iteration  2826 : Loss =  0.37015432  Acc:  0.8725 Val_loss =  0.43972313 Val_acc =  0.8466\n",
            "Iteration  2827 : Loss =  0.3701384  Acc:  0.8725 Val_loss =  0.43972096 Val_acc =  0.8466\n",
            "Iteration  2828 : Loss =  0.37012252  Acc:  0.87256664 Val_loss =  0.43971875 Val_acc =  0.8466\n",
            "Iteration  2829 : Loss =  0.3701066  Acc:  0.87256664 Val_loss =  0.43971664 Val_acc =  0.8466\n",
            "Iteration  2830 : Loss =  0.37009072  Acc:  0.87256664 Val_loss =  0.4397145 Val_acc =  0.8466\n",
            "Iteration  2831 : Loss =  0.37007487  Acc:  0.87256664 Val_loss =  0.43971235 Val_acc =  0.8466\n",
            "Iteration  2832 : Loss =  0.37005898  Acc:  0.8725833 Val_loss =  0.43971026 Val_acc =  0.8466\n",
            "Iteration  2833 : Loss =  0.3700431  Acc:  0.8725833 Val_loss =  0.4397081 Val_acc =  0.8465\n",
            "Iteration  2834 : Loss =  0.3700272  Acc:  0.8725833 Val_loss =  0.43970597 Val_acc =  0.8465\n",
            "Iteration  2835 : Loss =  0.3700114  Acc:  0.8725833 Val_loss =  0.43970385 Val_acc =  0.8465\n",
            "Iteration  2836 : Loss =  0.36999553  Acc:  0.8726 Val_loss =  0.43970177 Val_acc =  0.8465\n",
            "Iteration  2837 : Loss =  0.36997968  Acc:  0.8725833 Val_loss =  0.4396997 Val_acc =  0.8465\n",
            "Iteration  2838 : Loss =  0.36996385  Acc:  0.87256664 Val_loss =  0.43969756 Val_acc =  0.8465\n",
            "Iteration  2839 : Loss =  0.36994806  Acc:  0.87256664 Val_loss =  0.4396955 Val_acc =  0.8465\n",
            "Iteration  2840 : Loss =  0.36993223  Acc:  0.87256664 Val_loss =  0.43969342 Val_acc =  0.8465\n",
            "Iteration  2841 : Loss =  0.3699164  Acc:  0.87256664 Val_loss =  0.4396913 Val_acc =  0.8464\n",
            "Iteration  2842 : Loss =  0.3699006  Acc:  0.8725833 Val_loss =  0.43968925 Val_acc =  0.8464\n",
            "Iteration  2843 : Loss =  0.3698848  Acc:  0.8725833 Val_loss =  0.4396872 Val_acc =  0.8464\n",
            "Iteration  2844 : Loss =  0.36986902  Acc:  0.87256664 Val_loss =  0.43968517 Val_acc =  0.8464\n",
            "Iteration  2845 : Loss =  0.36985326  Acc:  0.87256664 Val_loss =  0.4396831 Val_acc =  0.8464\n",
            "Iteration  2846 : Loss =  0.36983746  Acc:  0.87256664 Val_loss =  0.4396811 Val_acc =  0.8464\n",
            "Iteration  2847 : Loss =  0.36982167  Acc:  0.87256664 Val_loss =  0.43967906 Val_acc =  0.8465\n",
            "Iteration  2848 : Loss =  0.36980593  Acc:  0.87256664 Val_loss =  0.43967706 Val_acc =  0.8465\n",
            "Iteration  2849 : Loss =  0.36979017  Acc:  0.87256664 Val_loss =  0.439675 Val_acc =  0.8465\n",
            "Iteration  2850 : Loss =  0.36977446  Acc:  0.87256664 Val_loss =  0.439673 Val_acc =  0.8465\n",
            "Iteration  2851 : Loss =  0.3697587  Acc:  0.87256664 Val_loss =  0.439671 Val_acc =  0.8463\n",
            "Iteration  2852 : Loss =  0.36974296  Acc:  0.87256664 Val_loss =  0.43966898 Val_acc =  0.8463\n",
            "Iteration  2853 : Loss =  0.36972725  Acc:  0.87256664 Val_loss =  0.439667 Val_acc =  0.8463\n",
            "Iteration  2854 : Loss =  0.36971152  Acc:  0.87256664 Val_loss =  0.43966505 Val_acc =  0.8463\n",
            "Iteration  2855 : Loss =  0.36969584  Acc:  0.8726 Val_loss =  0.43966302 Val_acc =  0.8463\n",
            "Iteration  2856 : Loss =  0.3696801  Acc:  0.87261665 Val_loss =  0.4396611 Val_acc =  0.8463\n",
            "Iteration  2857 : Loss =  0.3696644  Acc:  0.87261665 Val_loss =  0.4396591 Val_acc =  0.8464\n",
            "Iteration  2858 : Loss =  0.3696487  Acc:  0.87265 Val_loss =  0.43965712 Val_acc =  0.8464\n",
            "Iteration  2859 : Loss =  0.36963302  Acc:  0.87263334 Val_loss =  0.4396552 Val_acc =  0.8464\n",
            "Iteration  2860 : Loss =  0.36961734  Acc:  0.87265 Val_loss =  0.43965328 Val_acc =  0.8464\n",
            "Iteration  2861 : Loss =  0.3696017  Acc:  0.87265 Val_loss =  0.4396513 Val_acc =  0.8464\n",
            "Iteration  2862 : Loss =  0.36958602  Acc:  0.87266666 Val_loss =  0.4396494 Val_acc =  0.8464\n",
            "Iteration  2863 : Loss =  0.36957037  Acc:  0.87265 Val_loss =  0.43964747 Val_acc =  0.8464\n",
            "Iteration  2864 : Loss =  0.36955476  Acc:  0.87266666 Val_loss =  0.43964556 Val_acc =  0.8464\n",
            "Iteration  2865 : Loss =  0.36953905  Acc:  0.87266666 Val_loss =  0.43964365 Val_acc =  0.8464\n",
            "Iteration  2866 : Loss =  0.36952344  Acc:  0.87268335 Val_loss =  0.43964174 Val_acc =  0.8464\n",
            "Iteration  2867 : Loss =  0.36950782  Acc:  0.87268335 Val_loss =  0.43963984 Val_acc =  0.8464\n",
            "Iteration  2868 : Loss =  0.36949223  Acc:  0.87268335 Val_loss =  0.439638 Val_acc =  0.8464\n",
            "Iteration  2869 : Loss =  0.3694766  Acc:  0.87268335 Val_loss =  0.43963608 Val_acc =  0.8464\n",
            "Iteration  2870 : Loss =  0.369461  Acc:  0.8727 Val_loss =  0.43963417 Val_acc =  0.8463\n",
            "Iteration  2871 : Loss =  0.3694454  Acc:  0.8727 Val_loss =  0.43963233 Val_acc =  0.8463\n",
            "Iteration  2872 : Loss =  0.36942983  Acc:  0.87271667 Val_loss =  0.43963048 Val_acc =  0.8463\n",
            "Iteration  2873 : Loss =  0.36941424  Acc:  0.87271667 Val_loss =  0.4396286 Val_acc =  0.8463\n",
            "Iteration  2874 : Loss =  0.36939862  Acc:  0.87273335 Val_loss =  0.43962675 Val_acc =  0.8463\n",
            "Iteration  2875 : Loss =  0.36938307  Acc:  0.87273335 Val_loss =  0.4396249 Val_acc =  0.8464\n",
            "Iteration  2876 : Loss =  0.3693675  Acc:  0.87273335 Val_loss =  0.4396231 Val_acc =  0.8464\n",
            "Iteration  2877 : Loss =  0.36935195  Acc:  0.87275 Val_loss =  0.43962124 Val_acc =  0.8464\n",
            "Iteration  2878 : Loss =  0.3693364  Acc:  0.87275 Val_loss =  0.43961942 Val_acc =  0.8464\n",
            "Iteration  2879 : Loss =  0.36932087  Acc:  0.87275 Val_loss =  0.43961757 Val_acc =  0.8464\n",
            "Iteration  2880 : Loss =  0.36930534  Acc:  0.87275 Val_loss =  0.43961582 Val_acc =  0.8464\n",
            "Iteration  2881 : Loss =  0.3692898  Acc:  0.8727667 Val_loss =  0.43961397 Val_acc =  0.8464\n",
            "Iteration  2882 : Loss =  0.36927426  Acc:  0.8727667 Val_loss =  0.4396122 Val_acc =  0.8464\n",
            "Iteration  2883 : Loss =  0.36925876  Acc:  0.8728 Val_loss =  0.4396104 Val_acc =  0.8464\n",
            "Iteration  2884 : Loss =  0.36924323  Acc:  0.8728 Val_loss =  0.4396086 Val_acc =  0.8464\n",
            "Iteration  2885 : Loss =  0.36922777  Acc:  0.8728 Val_loss =  0.43960685 Val_acc =  0.8464\n",
            "Iteration  2886 : Loss =  0.36921227  Acc:  0.8728 Val_loss =  0.4396051 Val_acc =  0.8464\n",
            "Iteration  2887 : Loss =  0.36919677  Acc:  0.8728167 Val_loss =  0.43960333 Val_acc =  0.8464\n",
            "Iteration  2888 : Loss =  0.36918128  Acc:  0.8728167 Val_loss =  0.43960157 Val_acc =  0.8465\n",
            "Iteration  2889 : Loss =  0.3691658  Acc:  0.8728167 Val_loss =  0.4395998 Val_acc =  0.8465\n",
            "Iteration  2890 : Loss =  0.36915037  Acc:  0.8728167 Val_loss =  0.43959805 Val_acc =  0.8465\n",
            "Iteration  2891 : Loss =  0.3691349  Acc:  0.8728167 Val_loss =  0.4395963 Val_acc =  0.8465\n",
            "Iteration  2892 : Loss =  0.36911947  Acc:  0.8728333 Val_loss =  0.43959457 Val_acc =  0.8465\n",
            "Iteration  2893 : Loss =  0.369104  Acc:  0.8728333 Val_loss =  0.43959287 Val_acc =  0.8465\n",
            "Iteration  2894 : Loss =  0.36908853  Acc:  0.8728333 Val_loss =  0.4395911 Val_acc =  0.8465\n",
            "Iteration  2895 : Loss =  0.36907315  Acc:  0.87285 Val_loss =  0.4395894 Val_acc =  0.8465\n",
            "Iteration  2896 : Loss =  0.36905771  Acc:  0.87285 Val_loss =  0.43958768 Val_acc =  0.8465\n",
            "Iteration  2897 : Loss =  0.3690423  Acc:  0.8728833 Val_loss =  0.43958604 Val_acc =  0.8465\n",
            "Iteration  2898 : Loss =  0.3690269  Acc:  0.8728833 Val_loss =  0.43958429 Val_acc =  0.8465\n",
            "Iteration  2899 : Loss =  0.36901146  Acc:  0.8728833 Val_loss =  0.43958262 Val_acc =  0.8465\n",
            "Iteration  2900 : Loss =  0.36899608  Acc:  0.8728833 Val_loss =  0.43958095 Val_acc =  0.8465\n",
            "Iteration  2901 : Loss =  0.3689807  Acc:  0.8728833 Val_loss =  0.4395793 Val_acc =  0.8465\n",
            "Iteration  2902 : Loss =  0.3689653  Acc:  0.8728833 Val_loss =  0.43957764 Val_acc =  0.8465\n",
            "Iteration  2903 : Loss =  0.36894995  Acc:  0.8728833 Val_loss =  0.43957597 Val_acc =  0.8465\n",
            "Iteration  2904 : Loss =  0.36893457  Acc:  0.8728667 Val_loss =  0.43957427 Val_acc =  0.8466\n",
            "Iteration  2905 : Loss =  0.3689192  Acc:  0.8728667 Val_loss =  0.43957266 Val_acc =  0.8466\n",
            "Iteration  2906 : Loss =  0.36890385  Acc:  0.8728833 Val_loss =  0.439571 Val_acc =  0.8466\n",
            "Iteration  2907 : Loss =  0.36888847  Acc:  0.8728833 Val_loss =  0.43956938 Val_acc =  0.8466\n",
            "Iteration  2908 : Loss =  0.36887315  Acc:  0.8728667 Val_loss =  0.43956771 Val_acc =  0.8466\n",
            "Iteration  2909 : Loss =  0.3688578  Acc:  0.8728667 Val_loss =  0.4395661 Val_acc =  0.8466\n",
            "Iteration  2910 : Loss =  0.36884248  Acc:  0.87285 Val_loss =  0.4395645 Val_acc =  0.8466\n",
            "Iteration  2911 : Loss =  0.36882713  Acc:  0.8728667 Val_loss =  0.4395629 Val_acc =  0.8466\n",
            "Iteration  2912 : Loss =  0.36881185  Acc:  0.8728667 Val_loss =  0.43956128 Val_acc =  0.8466\n",
            "Iteration  2913 : Loss =  0.36879656  Acc:  0.8728667 Val_loss =  0.43955967 Val_acc =  0.8466\n",
            "Iteration  2914 : Loss =  0.3687812  Acc:  0.8728833 Val_loss =  0.43955812 Val_acc =  0.8466\n",
            "Iteration  2915 : Loss =  0.36876595  Acc:  0.8728833 Val_loss =  0.43955654 Val_acc =  0.8465\n",
            "Iteration  2916 : Loss =  0.36875066  Acc:  0.8728833 Val_loss =  0.439555 Val_acc =  0.8465\n",
            "Iteration  2917 : Loss =  0.36873534  Acc:  0.8729 Val_loss =  0.43955338 Val_acc =  0.8465\n",
            "Iteration  2918 : Loss =  0.36872008  Acc:  0.8729 Val_loss =  0.4395518 Val_acc =  0.8466\n",
            "Iteration  2919 : Loss =  0.36870483  Acc:  0.8729 Val_loss =  0.43955025 Val_acc =  0.8466\n",
            "Iteration  2920 : Loss =  0.3686895  Acc:  0.87291664 Val_loss =  0.43954867 Val_acc =  0.8466\n",
            "Iteration  2921 : Loss =  0.36867428  Acc:  0.87291664 Val_loss =  0.43954718 Val_acc =  0.8466\n",
            "Iteration  2922 : Loss =  0.36865905  Acc:  0.8729333 Val_loss =  0.4395456 Val_acc =  0.8466\n",
            "Iteration  2923 : Loss =  0.36864382  Acc:  0.8729333 Val_loss =  0.43954408 Val_acc =  0.8466\n",
            "Iteration  2924 : Loss =  0.3686286  Acc:  0.87296665 Val_loss =  0.4395426 Val_acc =  0.8465\n",
            "Iteration  2925 : Loss =  0.36861333  Acc:  0.87298334 Val_loss =  0.439541 Val_acc =  0.8465\n",
            "Iteration  2926 : Loss =  0.3685981  Acc:  0.873 Val_loss =  0.4395395 Val_acc =  0.8465\n",
            "Iteration  2927 : Loss =  0.3685829  Acc:  0.87301666 Val_loss =  0.439538 Val_acc =  0.8465\n",
            "Iteration  2928 : Loss =  0.3685677  Acc:  0.87301666 Val_loss =  0.43953648 Val_acc =  0.8465\n",
            "Iteration  2929 : Loss =  0.36855248  Acc:  0.87301666 Val_loss =  0.43953502 Val_acc =  0.8465\n",
            "Iteration  2930 : Loss =  0.3685373  Acc:  0.87305 Val_loss =  0.4395335 Val_acc =  0.8465\n",
            "Iteration  2931 : Loss =  0.3685221  Acc:  0.87305 Val_loss =  0.43953204 Val_acc =  0.8466\n",
            "Iteration  2932 : Loss =  0.36850697  Acc:  0.87305 Val_loss =  0.43953058 Val_acc =  0.8466\n",
            "Iteration  2933 : Loss =  0.36849177  Acc:  0.87305 Val_loss =  0.4395291 Val_acc =  0.8467\n",
            "Iteration  2934 : Loss =  0.3684766  Acc:  0.87305 Val_loss =  0.43952763 Val_acc =  0.8467\n",
            "Iteration  2935 : Loss =  0.3684614  Acc:  0.87305 Val_loss =  0.43952617 Val_acc =  0.8467\n",
            "Iteration  2936 : Loss =  0.36844626  Acc:  0.87306666 Val_loss =  0.4395247 Val_acc =  0.8467\n",
            "Iteration  2937 : Loss =  0.36843112  Acc:  0.87308335 Val_loss =  0.43952325 Val_acc =  0.8467\n",
            "Iteration  2938 : Loss =  0.36841598  Acc:  0.87306666 Val_loss =  0.43952188 Val_acc =  0.8467\n",
            "Iteration  2939 : Loss =  0.36840084  Acc:  0.8731 Val_loss =  0.43952042 Val_acc =  0.8467\n",
            "Iteration  2940 : Loss =  0.36838573  Acc:  0.87308335 Val_loss =  0.43951896 Val_acc =  0.8468\n",
            "Iteration  2941 : Loss =  0.3683706  Acc:  0.87308335 Val_loss =  0.4395176 Val_acc =  0.8468\n",
            "Iteration  2942 : Loss =  0.36835548  Acc:  0.87308335 Val_loss =  0.43951613 Val_acc =  0.8468\n",
            "Iteration  2943 : Loss =  0.36834037  Acc:  0.87308335 Val_loss =  0.43951476 Val_acc =  0.8467\n",
            "Iteration  2944 : Loss =  0.36832526  Acc:  0.87308335 Val_loss =  0.43951333 Val_acc =  0.8467\n",
            "Iteration  2945 : Loss =  0.36831015  Acc:  0.8731 Val_loss =  0.43951195 Val_acc =  0.8467\n",
            "Iteration  2946 : Loss =  0.36829507  Acc:  0.8731 Val_loss =  0.43951055 Val_acc =  0.8467\n",
            "Iteration  2947 : Loss =  0.36828002  Acc:  0.8731 Val_loss =  0.43950918 Val_acc =  0.8467\n",
            "Iteration  2948 : Loss =  0.3682649  Acc:  0.87308335 Val_loss =  0.4395078 Val_acc =  0.8467\n",
            "Iteration  2949 : Loss =  0.36824986  Acc:  0.87308335 Val_loss =  0.43950644 Val_acc =  0.8467\n",
            "Iteration  2950 : Loss =  0.36823475  Acc:  0.8731 Val_loss =  0.43950507 Val_acc =  0.8467\n",
            "Iteration  2951 : Loss =  0.36821973  Acc:  0.8731 Val_loss =  0.4395037 Val_acc =  0.8467\n",
            "Iteration  2952 : Loss =  0.36820468  Acc:  0.8731 Val_loss =  0.43950236 Val_acc =  0.8467\n",
            "Iteration  2953 : Loss =  0.36818966  Acc:  0.8731 Val_loss =  0.439501 Val_acc =  0.8467\n",
            "Iteration  2954 : Loss =  0.3681746  Acc:  0.8731 Val_loss =  0.43949965 Val_acc =  0.8467\n",
            "Iteration  2955 : Loss =  0.36815956  Acc:  0.8731 Val_loss =  0.43949834 Val_acc =  0.8468\n",
            "Iteration  2956 : Loss =  0.36814454  Acc:  0.87308335 Val_loss =  0.43949702 Val_acc =  0.8468\n",
            "Iteration  2957 : Loss =  0.3681295  Acc:  0.87308335 Val_loss =  0.4394957 Val_acc =  0.8469\n",
            "Iteration  2958 : Loss =  0.36811453  Acc:  0.8731167 Val_loss =  0.43949437 Val_acc =  0.8469\n",
            "Iteration  2959 : Loss =  0.3680995  Acc:  0.87313336 Val_loss =  0.43949306 Val_acc =  0.8469\n",
            "Iteration  2960 : Loss =  0.36808452  Acc:  0.8731167 Val_loss =  0.4394918 Val_acc =  0.8469\n",
            "Iteration  2961 : Loss =  0.36806953  Acc:  0.87308335 Val_loss =  0.43949047 Val_acc =  0.847\n",
            "Iteration  2962 : Loss =  0.36805457  Acc:  0.87308335 Val_loss =  0.43948916 Val_acc =  0.847\n",
            "Iteration  2963 : Loss =  0.36803958  Acc:  0.8731167 Val_loss =  0.4394879 Val_acc =  0.847\n",
            "Iteration  2964 : Loss =  0.36802462  Acc:  0.8731167 Val_loss =  0.43948662 Val_acc =  0.847\n",
            "Iteration  2965 : Loss =  0.36800963  Acc:  0.87315 Val_loss =  0.43948534 Val_acc =  0.847\n",
            "Iteration  2966 : Loss =  0.36799467  Acc:  0.87315 Val_loss =  0.4394841 Val_acc =  0.847\n",
            "Iteration  2967 : Loss =  0.3679797  Acc:  0.8731833 Val_loss =  0.4394828 Val_acc =  0.847\n",
            "Iteration  2968 : Loss =  0.36796477  Acc:  0.8731833 Val_loss =  0.4394816 Val_acc =  0.847\n",
            "Iteration  2969 : Loss =  0.3679498  Acc:  0.8731833 Val_loss =  0.43948033 Val_acc =  0.847\n",
            "Iteration  2970 : Loss =  0.36793494  Acc:  0.8732 Val_loss =  0.4394791 Val_acc =  0.847\n",
            "Iteration  2971 : Loss =  0.36791998  Acc:  0.8732167 Val_loss =  0.43947783 Val_acc =  0.847\n",
            "Iteration  2972 : Loss =  0.36790508  Acc:  0.8732167 Val_loss =  0.43947667 Val_acc =  0.847\n",
            "Iteration  2973 : Loss =  0.36789018  Acc:  0.8732333 Val_loss =  0.43947545 Val_acc =  0.847\n",
            "Iteration  2974 : Loss =  0.36787522  Acc:  0.8732333 Val_loss =  0.43947423 Val_acc =  0.847\n",
            "Iteration  2975 : Loss =  0.36786035  Acc:  0.87325 Val_loss =  0.43947294 Val_acc =  0.847\n",
            "Iteration  2976 : Loss =  0.36784545  Acc:  0.87325 Val_loss =  0.43947178 Val_acc =  0.847\n",
            "Iteration  2977 : Loss =  0.36783057  Acc:  0.87325 Val_loss =  0.43947062 Val_acc =  0.847\n",
            "Iteration  2978 : Loss =  0.3678157  Acc:  0.87325 Val_loss =  0.4394694 Val_acc =  0.8469\n",
            "Iteration  2979 : Loss =  0.3678008  Acc:  0.87325 Val_loss =  0.43946818 Val_acc =  0.8469\n",
            "Iteration  2980 : Loss =  0.36778593  Acc:  0.87325 Val_loss =  0.43946704 Val_acc =  0.8469\n",
            "Iteration  2981 : Loss =  0.3677711  Acc:  0.87325 Val_loss =  0.43946582 Val_acc =  0.8469\n",
            "Iteration  2982 : Loss =  0.36775622  Acc:  0.87325 Val_loss =  0.43946466 Val_acc =  0.8469\n",
            "Iteration  2983 : Loss =  0.36774135  Acc:  0.87326664 Val_loss =  0.43946353 Val_acc =  0.8469\n",
            "Iteration  2984 : Loss =  0.36772653  Acc:  0.8732833 Val_loss =  0.4394624 Val_acc =  0.8469\n",
            "Iteration  2985 : Loss =  0.3677117  Acc:  0.87331665 Val_loss =  0.43946123 Val_acc =  0.8469\n",
            "Iteration  2986 : Loss =  0.36769688  Acc:  0.87333333 Val_loss =  0.43946007 Val_acc =  0.8469\n",
            "Iteration  2987 : Loss =  0.36768204  Acc:  0.87333333 Val_loss =  0.43945894 Val_acc =  0.847\n",
            "Iteration  2988 : Loss =  0.36766723  Acc:  0.87333333 Val_loss =  0.4394578 Val_acc =  0.847\n",
            "Iteration  2989 : Loss =  0.36765242  Acc:  0.87335 Val_loss =  0.4394567 Val_acc =  0.847\n",
            "Iteration  2990 : Loss =  0.36763763  Acc:  0.87336665 Val_loss =  0.43945557 Val_acc =  0.847\n",
            "Iteration  2991 : Loss =  0.36762282  Acc:  0.87338334 Val_loss =  0.4394545 Val_acc =  0.847\n",
            "Iteration  2992 : Loss =  0.367608  Acc:  0.87338334 Val_loss =  0.43945333 Val_acc =  0.847\n",
            "Iteration  2993 : Loss =  0.36759323  Acc:  0.87338334 Val_loss =  0.43945226 Val_acc =  0.847\n",
            "Iteration  2994 : Loss =  0.36757845  Acc:  0.87338334 Val_loss =  0.43945113 Val_acc =  0.847\n",
            "Iteration  2995 : Loss =  0.36756366  Acc:  0.87336665 Val_loss =  0.43945006 Val_acc =  0.847\n",
            "Iteration  2996 : Loss =  0.36754888  Acc:  0.87336665 Val_loss =  0.43944898 Val_acc =  0.847\n",
            "Iteration  2997 : Loss =  0.36753416  Acc:  0.87336665 Val_loss =  0.4394479 Val_acc =  0.847\n",
            "Iteration  2998 : Loss =  0.3675194  Acc:  0.87338334 Val_loss =  0.43944684 Val_acc =  0.8471\n",
            "Iteration  2999 : Loss =  0.36750463  Acc:  0.87338334 Val_loss =  0.43944576 Val_acc =  0.8471\n",
            "Iteration  3000 : Loss =  0.3674899  Acc:  0.8734 Val_loss =  0.4394447 Val_acc =  0.8471\n",
            "Iteration  3001 : Loss =  0.36747515  Acc:  0.8734 Val_loss =  0.43944365 Val_acc =  0.8471\n",
            "Iteration  3002 : Loss =  0.36746046  Acc:  0.8734 Val_loss =  0.43944263 Val_acc =  0.8471\n",
            "Iteration  3003 : Loss =  0.3674457  Acc:  0.87341666 Val_loss =  0.43944156 Val_acc =  0.8471\n",
            "Iteration  3004 : Loss =  0.36743098  Acc:  0.87341666 Val_loss =  0.43944052 Val_acc =  0.8471\n",
            "Iteration  3005 : Loss =  0.36741626  Acc:  0.87341666 Val_loss =  0.4394395 Val_acc =  0.8471\n",
            "Iteration  3006 : Loss =  0.36740157  Acc:  0.87341666 Val_loss =  0.43943846 Val_acc =  0.8471\n",
            "Iteration  3007 : Loss =  0.3673869  Acc:  0.87341666 Val_loss =  0.4394375 Val_acc =  0.8471\n",
            "Iteration  3008 : Loss =  0.3673722  Acc:  0.87341666 Val_loss =  0.43943644 Val_acc =  0.8471\n",
            "Iteration  3009 : Loss =  0.3673575  Acc:  0.87341666 Val_loss =  0.43943545 Val_acc =  0.8471\n",
            "Iteration  3010 : Loss =  0.36734283  Acc:  0.87341666 Val_loss =  0.43943447 Val_acc =  0.8471\n",
            "Iteration  3011 : Loss =  0.3673282  Acc:  0.87338334 Val_loss =  0.43943346 Val_acc =  0.8471\n",
            "Iteration  3012 : Loss =  0.36731347  Acc:  0.87338334 Val_loss =  0.43943247 Val_acc =  0.847\n",
            "Iteration  3013 : Loss =  0.36729884  Acc:  0.87338334 Val_loss =  0.4394315 Val_acc =  0.847\n",
            "Iteration  3014 : Loss =  0.36728418  Acc:  0.8734 Val_loss =  0.4394305 Val_acc =  0.847\n",
            "Iteration  3015 : Loss =  0.36726955  Acc:  0.87345 Val_loss =  0.4394295 Val_acc =  0.847\n",
            "Iteration  3016 : Loss =  0.36725488  Acc:  0.8734667 Val_loss =  0.43942857 Val_acc =  0.8471\n",
            "Iteration  3017 : Loss =  0.36724022  Acc:  0.87345 Val_loss =  0.43942758 Val_acc =  0.8471\n",
            "Iteration  3018 : Loss =  0.36722565  Acc:  0.8734667 Val_loss =  0.43942666 Val_acc =  0.8471\n",
            "Iteration  3019 : Loss =  0.367211  Acc:  0.87345 Val_loss =  0.43942574 Val_acc =  0.8471\n",
            "Iteration  3020 : Loss =  0.36719635  Acc:  0.87345 Val_loss =  0.43942475 Val_acc =  0.8471\n",
            "Iteration  3021 : Loss =  0.36718178  Acc:  0.87343335 Val_loss =  0.43942383 Val_acc =  0.8472\n",
            "Iteration  3022 : Loss =  0.36716717  Acc:  0.87341666 Val_loss =  0.4394229 Val_acc =  0.8472\n",
            "Iteration  3023 : Loss =  0.36715254  Acc:  0.87341666 Val_loss =  0.43942198 Val_acc =  0.8473\n",
            "Iteration  3024 : Loss =  0.36713797  Acc:  0.87341666 Val_loss =  0.4394211 Val_acc =  0.8473\n",
            "Iteration  3025 : Loss =  0.36712337  Acc:  0.8734 Val_loss =  0.4394201 Val_acc =  0.8473\n",
            "Iteration  3026 : Loss =  0.3671088  Acc:  0.87341666 Val_loss =  0.43941924 Val_acc =  0.8473\n",
            "Iteration  3027 : Loss =  0.36709422  Acc:  0.87341666 Val_loss =  0.43941835 Val_acc =  0.8474\n",
            "Iteration  3028 : Loss =  0.36707968  Acc:  0.87341666 Val_loss =  0.43941748 Val_acc =  0.8474\n",
            "Iteration  3029 : Loss =  0.3670651  Acc:  0.87341666 Val_loss =  0.43941656 Val_acc =  0.8474\n",
            "Iteration  3030 : Loss =  0.3670506  Acc:  0.87341666 Val_loss =  0.43941566 Val_acc =  0.8474\n",
            "Iteration  3031 : Loss =  0.367036  Acc:  0.87341666 Val_loss =  0.43941483 Val_acc =  0.8474\n",
            "Iteration  3032 : Loss =  0.36702147  Acc:  0.87338334 Val_loss =  0.4394139 Val_acc =  0.8474\n",
            "Iteration  3033 : Loss =  0.3670069  Acc:  0.87336665 Val_loss =  0.4394131 Val_acc =  0.8474\n",
            "Iteration  3034 : Loss =  0.36699238  Acc:  0.87336665 Val_loss =  0.4394122 Val_acc =  0.8474\n",
            "Iteration  3035 : Loss =  0.36697787  Acc:  0.87336665 Val_loss =  0.43941134 Val_acc =  0.8474\n",
            "Iteration  3036 : Loss =  0.36696336  Acc:  0.87336665 Val_loss =  0.4394105 Val_acc =  0.8474\n",
            "Iteration  3037 : Loss =  0.36694887  Acc:  0.87336665 Val_loss =  0.43940967 Val_acc =  0.8474\n",
            "Iteration  3038 : Loss =  0.3669343  Acc:  0.87336665 Val_loss =  0.43940884 Val_acc =  0.8474\n",
            "Iteration  3039 : Loss =  0.36691985  Acc:  0.87335 Val_loss =  0.439408 Val_acc =  0.8474\n",
            "Iteration  3040 : Loss =  0.36690533  Acc:  0.87335 Val_loss =  0.43940717 Val_acc =  0.8474\n",
            "Iteration  3041 : Loss =  0.36689085  Acc:  0.87335 Val_loss =  0.43940634 Val_acc =  0.8474\n",
            "Iteration  3042 : Loss =  0.36687636  Acc:  0.87335 Val_loss =  0.43940556 Val_acc =  0.8474\n",
            "Iteration  3043 : Loss =  0.3668619  Acc:  0.87335 Val_loss =  0.43940473 Val_acc =  0.8474\n",
            "Iteration  3044 : Loss =  0.36684746  Acc:  0.87335 Val_loss =  0.43940395 Val_acc =  0.8474\n",
            "Iteration  3045 : Loss =  0.36683294  Acc:  0.87336665 Val_loss =  0.43940312 Val_acc =  0.8474\n",
            "Iteration  3046 : Loss =  0.36681852  Acc:  0.87338334 Val_loss =  0.4394024 Val_acc =  0.8474\n",
            "Iteration  3047 : Loss =  0.36680406  Acc:  0.87338334 Val_loss =  0.43940157 Val_acc =  0.8474\n",
            "Iteration  3048 : Loss =  0.36678964  Acc:  0.8734 Val_loss =  0.4394008 Val_acc =  0.8474\n",
            "Iteration  3049 : Loss =  0.36677513  Acc:  0.87341666 Val_loss =  0.4394 Val_acc =  0.8474\n",
            "Iteration  3050 : Loss =  0.36676073  Acc:  0.87341666 Val_loss =  0.43939927 Val_acc =  0.8474\n",
            "Iteration  3051 : Loss =  0.36674634  Acc:  0.87341666 Val_loss =  0.4393985 Val_acc =  0.8475\n",
            "Iteration  3052 : Loss =  0.3667319  Acc:  0.87343335 Val_loss =  0.43939775 Val_acc =  0.8475\n",
            "Iteration  3053 : Loss =  0.3667175  Acc:  0.87343335 Val_loss =  0.439397 Val_acc =  0.8475\n",
            "Iteration  3054 : Loss =  0.36670306  Acc:  0.87343335 Val_loss =  0.4393963 Val_acc =  0.8475\n",
            "Iteration  3055 : Loss =  0.36668867  Acc:  0.87343335 Val_loss =  0.43939552 Val_acc =  0.8475\n",
            "Iteration  3056 : Loss =  0.36667427  Acc:  0.87345 Val_loss =  0.43939483 Val_acc =  0.8475\n",
            "Iteration  3057 : Loss =  0.3666599  Acc:  0.87345 Val_loss =  0.43939406 Val_acc =  0.8475\n",
            "Iteration  3058 : Loss =  0.36664551  Acc:  0.87345 Val_loss =  0.43939337 Val_acc =  0.8475\n",
            "Iteration  3059 : Loss =  0.3666311  Acc:  0.87345 Val_loss =  0.43939263 Val_acc =  0.8474\n",
            "Iteration  3060 : Loss =  0.36661673  Acc:  0.87345 Val_loss =  0.43939188 Val_acc =  0.8474\n",
            "Iteration  3061 : Loss =  0.3666024  Acc:  0.87348336 Val_loss =  0.43939123 Val_acc =  0.8474\n",
            "Iteration  3062 : Loss =  0.36658803  Acc:  0.8735 Val_loss =  0.43939054 Val_acc =  0.8474\n",
            "Iteration  3063 : Loss =  0.36657366  Acc:  0.8735 Val_loss =  0.43938985 Val_acc =  0.8474\n",
            "Iteration  3064 : Loss =  0.3665593  Acc:  0.8735 Val_loss =  0.43938917 Val_acc =  0.8474\n",
            "Iteration  3065 : Loss =  0.36654496  Acc:  0.87348336 Val_loss =  0.43938848 Val_acc =  0.8474\n",
            "Iteration  3066 : Loss =  0.36653063  Acc:  0.87348336 Val_loss =  0.4393878 Val_acc =  0.8474\n",
            "Iteration  3067 : Loss =  0.36651626  Acc:  0.8735 Val_loss =  0.4393871 Val_acc =  0.8474\n",
            "Iteration  3068 : Loss =  0.366502  Acc:  0.8735 Val_loss =  0.4393865 Val_acc =  0.8474\n",
            "Iteration  3069 : Loss =  0.36648762  Acc:  0.8735 Val_loss =  0.4393858 Val_acc =  0.8473\n",
            "Iteration  3070 : Loss =  0.36647335  Acc:  0.8735167 Val_loss =  0.43938515 Val_acc =  0.8473\n",
            "Iteration  3071 : Loss =  0.36645904  Acc:  0.8735167 Val_loss =  0.43938446 Val_acc =  0.8473\n",
            "Iteration  3072 : Loss =  0.36644474  Acc:  0.8735333 Val_loss =  0.43938383 Val_acc =  0.8473\n",
            "Iteration  3073 : Loss =  0.36643046  Acc:  0.8735333 Val_loss =  0.4393832 Val_acc =  0.8473\n",
            "Iteration  3074 : Loss =  0.36641616  Acc:  0.8735667 Val_loss =  0.4393826 Val_acc =  0.8474\n",
            "Iteration  3075 : Loss =  0.36640188  Acc:  0.8735667 Val_loss =  0.43938193 Val_acc =  0.8474\n",
            "Iteration  3076 : Loss =  0.36638764  Acc:  0.8735833 Val_loss =  0.43938136 Val_acc =  0.8474\n",
            "Iteration  3077 : Loss =  0.3663733  Acc:  0.8735833 Val_loss =  0.43938076 Val_acc =  0.8473\n",
            "Iteration  3078 : Loss =  0.36635906  Acc:  0.8735833 Val_loss =  0.43938014 Val_acc =  0.8473\n",
            "Iteration  3079 : Loss =  0.36634478  Acc:  0.8735833 Val_loss =  0.43937954 Val_acc =  0.8473\n",
            "Iteration  3080 : Loss =  0.36633053  Acc:  0.8735833 Val_loss =  0.43937895 Val_acc =  0.8473\n",
            "Iteration  3081 : Loss =  0.3663163  Acc:  0.8735833 Val_loss =  0.43937832 Val_acc =  0.8473\n",
            "Iteration  3082 : Loss =  0.366302  Acc:  0.8735833 Val_loss =  0.43937778 Val_acc =  0.8473\n",
            "Iteration  3083 : Loss =  0.36628783  Acc:  0.8736 Val_loss =  0.4393772 Val_acc =  0.8473\n",
            "Iteration  3084 : Loss =  0.3662736  Acc:  0.8736 Val_loss =  0.43937662 Val_acc =  0.8473\n",
            "Iteration  3085 : Loss =  0.36625937  Acc:  0.8736 Val_loss =  0.4393761 Val_acc =  0.8473\n",
            "Iteration  3086 : Loss =  0.36624512  Acc:  0.8736167 Val_loss =  0.4393755 Val_acc =  0.8473\n",
            "Iteration  3087 : Loss =  0.36623093  Acc:  0.8736333 Val_loss =  0.4393749 Val_acc =  0.8473\n",
            "Iteration  3088 : Loss =  0.36621672  Acc:  0.87365 Val_loss =  0.43937436 Val_acc =  0.8473\n",
            "Iteration  3089 : Loss =  0.36620253  Acc:  0.87366664 Val_loss =  0.43937382 Val_acc =  0.8473\n",
            "Iteration  3090 : Loss =  0.36618832  Acc:  0.87365 Val_loss =  0.43937328 Val_acc =  0.8473\n",
            "Iteration  3091 : Loss =  0.36617416  Acc:  0.87368333 Val_loss =  0.43937275 Val_acc =  0.8474\n",
            "Iteration  3092 : Loss =  0.36615998  Acc:  0.8737 Val_loss =  0.4393722 Val_acc =  0.8474\n",
            "Iteration  3093 : Loss =  0.36614576  Acc:  0.87371665 Val_loss =  0.43937168 Val_acc =  0.8474\n",
            "Iteration  3094 : Loss =  0.3661316  Acc:  0.87373334 Val_loss =  0.4393712 Val_acc =  0.8474\n",
            "Iteration  3095 : Loss =  0.36611745  Acc:  0.87373334 Val_loss =  0.43937066 Val_acc =  0.8474\n",
            "Iteration  3096 : Loss =  0.3661033  Acc:  0.87373334 Val_loss =  0.43937021 Val_acc =  0.8474\n",
            "Iteration  3097 : Loss =  0.36608914  Acc:  0.87373334 Val_loss =  0.43936968 Val_acc =  0.8474\n",
            "Iteration  3098 : Loss =  0.366075  Acc:  0.87371665 Val_loss =  0.43936914 Val_acc =  0.8474\n",
            "Iteration  3099 : Loss =  0.3660608  Acc:  0.87371665 Val_loss =  0.4393687 Val_acc =  0.8474\n",
            "Iteration  3100 : Loss =  0.36604673  Acc:  0.87373334 Val_loss =  0.43936822 Val_acc =  0.8474\n",
            "Iteration  3101 : Loss =  0.36603254  Acc:  0.87371665 Val_loss =  0.4393677 Val_acc =  0.8474\n",
            "Iteration  3102 : Loss =  0.3660184  Acc:  0.8737 Val_loss =  0.43936723 Val_acc =  0.8474\n",
            "Iteration  3103 : Loss =  0.3660043  Acc:  0.8737 Val_loss =  0.4393668 Val_acc =  0.8474\n",
            "Iteration  3104 : Loss =  0.36599022  Acc:  0.87371665 Val_loss =  0.4393663 Val_acc =  0.8474\n",
            "Iteration  3105 : Loss =  0.3659761  Acc:  0.8737 Val_loss =  0.43936586 Val_acc =  0.8474\n",
            "Iteration  3106 : Loss =  0.36596197  Acc:  0.8737 Val_loss =  0.43936542 Val_acc =  0.8474\n",
            "Iteration  3107 : Loss =  0.36594787  Acc:  0.8737 Val_loss =  0.439365 Val_acc =  0.8474\n",
            "Iteration  3108 : Loss =  0.36593378  Acc:  0.8737 Val_loss =  0.43936455 Val_acc =  0.8474\n",
            "Iteration  3109 : Loss =  0.36591974  Acc:  0.87371665 Val_loss =  0.4393641 Val_acc =  0.8474\n",
            "Iteration  3110 : Loss =  0.36590567  Acc:  0.87371665 Val_loss =  0.43936366 Val_acc =  0.8474\n",
            "Iteration  3111 : Loss =  0.3658916  Acc:  0.87373334 Val_loss =  0.43936327 Val_acc =  0.8474\n",
            "Iteration  3112 : Loss =  0.3658775  Acc:  0.87376666 Val_loss =  0.43936285 Val_acc =  0.8474\n",
            "Iteration  3113 : Loss =  0.36586344  Acc:  0.8738 Val_loss =  0.4393624 Val_acc =  0.8474\n",
            "Iteration  3114 : Loss =  0.3658494  Acc:  0.8738 Val_loss =  0.43936202 Val_acc =  0.8474\n",
            "Iteration  3115 : Loss =  0.36583534  Acc:  0.87383336 Val_loss =  0.43936163 Val_acc =  0.8474\n",
            "Iteration  3116 : Loss =  0.3658213  Acc:  0.8738667 Val_loss =  0.43936124 Val_acc =  0.8474\n",
            "Iteration  3117 : Loss =  0.36580727  Acc:  0.8738833 Val_loss =  0.43936083 Val_acc =  0.8474\n",
            "Iteration  3118 : Loss =  0.36579323  Acc:  0.8738833 Val_loss =  0.43936044 Val_acc =  0.8474\n",
            "Iteration  3119 : Loss =  0.36577922  Acc:  0.8738833 Val_loss =  0.43936005 Val_acc =  0.8473\n",
            "Iteration  3120 : Loss =  0.36576518  Acc:  0.87385 Val_loss =  0.43935966 Val_acc =  0.8473\n",
            "Iteration  3121 : Loss =  0.36575118  Acc:  0.87385 Val_loss =  0.43935934 Val_acc =  0.8473\n",
            "Iteration  3122 : Loss =  0.36573717  Acc:  0.87385 Val_loss =  0.43935898 Val_acc =  0.8474\n",
            "Iteration  3123 : Loss =  0.36572316  Acc:  0.87385 Val_loss =  0.4393586 Val_acc =  0.8474\n",
            "Iteration  3124 : Loss =  0.3657092  Acc:  0.87381667 Val_loss =  0.43935826 Val_acc =  0.8474\n",
            "Iteration  3125 : Loss =  0.36569518  Acc:  0.87381667 Val_loss =  0.4393579 Val_acc =  0.8474\n",
            "Iteration  3126 : Loss =  0.36568117  Acc:  0.87381667 Val_loss =  0.43935758 Val_acc =  0.8474\n",
            "Iteration  3127 : Loss =  0.36566722  Acc:  0.87381667 Val_loss =  0.43935722 Val_acc =  0.8474\n",
            "Iteration  3128 : Loss =  0.36565322  Acc:  0.8738 Val_loss =  0.43935692 Val_acc =  0.8474\n",
            "Iteration  3129 : Loss =  0.36563927  Acc:  0.8738 Val_loss =  0.4393566 Val_acc =  0.8475\n",
            "Iteration  3130 : Loss =  0.3656253  Acc:  0.87378335 Val_loss =  0.43935624 Val_acc =  0.8475\n",
            "Iteration  3131 : Loss =  0.3656113  Acc:  0.87378335 Val_loss =  0.43935597 Val_acc =  0.8475\n",
            "Iteration  3132 : Loss =  0.3655974  Acc:  0.8738 Val_loss =  0.43935567 Val_acc =  0.8475\n",
            "Iteration  3133 : Loss =  0.36558342  Acc:  0.8738 Val_loss =  0.43935537 Val_acc =  0.8475\n",
            "Iteration  3134 : Loss =  0.36556953  Acc:  0.8738 Val_loss =  0.43935502 Val_acc =  0.8474\n",
            "Iteration  3135 : Loss =  0.36555555  Acc:  0.8738 Val_loss =  0.43935475 Val_acc =  0.8474\n",
            "Iteration  3136 : Loss =  0.36554164  Acc:  0.87381667 Val_loss =  0.43935445 Val_acc =  0.8474\n",
            "Iteration  3137 : Loss =  0.3655277  Acc:  0.87383336 Val_loss =  0.4393542 Val_acc =  0.8474\n",
            "Iteration  3138 : Loss =  0.3655138  Acc:  0.87381667 Val_loss =  0.4393539 Val_acc =  0.8475\n",
            "Iteration  3139 : Loss =  0.36549988  Acc:  0.87381667 Val_loss =  0.43935362 Val_acc =  0.8475\n",
            "Iteration  3140 : Loss =  0.36548594  Acc:  0.87381667 Val_loss =  0.43935338 Val_acc =  0.8475\n",
            "Iteration  3141 : Loss =  0.36547208  Acc:  0.87381667 Val_loss =  0.43935314 Val_acc =  0.8475\n",
            "Iteration  3142 : Loss =  0.3654582  Acc:  0.87381667 Val_loss =  0.43935284 Val_acc =  0.8475\n",
            "Iteration  3143 : Loss =  0.36544427  Acc:  0.87381667 Val_loss =  0.43935263 Val_acc =  0.8475\n",
            "Iteration  3144 : Loss =  0.3654304  Acc:  0.87381667 Val_loss =  0.43935233 Val_acc =  0.8475\n",
            "Iteration  3145 : Loss =  0.36541653  Acc:  0.87383336 Val_loss =  0.43935215 Val_acc =  0.8475\n",
            "Iteration  3146 : Loss =  0.36540264  Acc:  0.87381667 Val_loss =  0.43935186 Val_acc =  0.8475\n",
            "Iteration  3147 : Loss =  0.36538875  Acc:  0.87383336 Val_loss =  0.43935165 Val_acc =  0.8475\n",
            "Iteration  3148 : Loss =  0.3653749  Acc:  0.87383336 Val_loss =  0.43935147 Val_acc =  0.8475\n",
            "Iteration  3149 : Loss =  0.36536106  Acc:  0.87383336 Val_loss =  0.43935123 Val_acc =  0.8475\n",
            "Iteration  3150 : Loss =  0.3653472  Acc:  0.87381667 Val_loss =  0.43935096 Val_acc =  0.8475\n",
            "Iteration  3151 : Loss =  0.36533338  Acc:  0.87383336 Val_loss =  0.43935078 Val_acc =  0.8475\n",
            "Iteration  3152 : Loss =  0.36531952  Acc:  0.87383336 Val_loss =  0.43935058 Val_acc =  0.8475\n",
            "Iteration  3153 : Loss =  0.36530566  Acc:  0.87385 Val_loss =  0.4393504 Val_acc =  0.8475\n",
            "Iteration  3154 : Loss =  0.36529186  Acc:  0.87385 Val_loss =  0.4393502 Val_acc =  0.8475\n",
            "Iteration  3155 : Loss =  0.36527807  Acc:  0.87385 Val_loss =  0.43935 Val_acc =  0.8475\n",
            "Iteration  3156 : Loss =  0.3652642  Acc:  0.8738667 Val_loss =  0.43934986 Val_acc =  0.8475\n",
            "Iteration  3157 : Loss =  0.36525038  Acc:  0.87385 Val_loss =  0.4393497 Val_acc =  0.8476\n",
            "Iteration  3158 : Loss =  0.36523658  Acc:  0.8738667 Val_loss =  0.4393495 Val_acc =  0.8477\n",
            "Iteration  3159 : Loss =  0.36522278  Acc:  0.8738667 Val_loss =  0.43934935 Val_acc =  0.8478\n",
            "Iteration  3160 : Loss =  0.36520898  Acc:  0.8738667 Val_loss =  0.4393492 Val_acc =  0.8478\n",
            "Iteration  3161 : Loss =  0.3651952  Acc:  0.8738667 Val_loss =  0.43934903 Val_acc =  0.8478\n",
            "Iteration  3162 : Loss =  0.36518145  Acc:  0.87385 Val_loss =  0.43934888 Val_acc =  0.8478\n",
            "Iteration  3163 : Loss =  0.36516765  Acc:  0.87385 Val_loss =  0.43934873 Val_acc =  0.8478\n",
            "Iteration  3164 : Loss =  0.36515388  Acc:  0.87385 Val_loss =  0.43934864 Val_acc =  0.8478\n",
            "Iteration  3165 : Loss =  0.3651401  Acc:  0.87383336 Val_loss =  0.4393485 Val_acc =  0.8479\n",
            "Iteration  3166 : Loss =  0.36512637  Acc:  0.87383336 Val_loss =  0.43934834 Val_acc =  0.8479\n",
            "Iteration  3167 : Loss =  0.3651126  Acc:  0.87383336 Val_loss =  0.43934825 Val_acc =  0.8479\n",
            "Iteration  3168 : Loss =  0.36509883  Acc:  0.87381667 Val_loss =  0.4393481 Val_acc =  0.8479\n",
            "Iteration  3169 : Loss =  0.3650851  Acc:  0.87381667 Val_loss =  0.43934804 Val_acc =  0.8479\n",
            "Iteration  3170 : Loss =  0.36507136  Acc:  0.87383336 Val_loss =  0.4393479 Val_acc =  0.8479\n",
            "Iteration  3171 : Loss =  0.36505762  Acc:  0.87383336 Val_loss =  0.4393478 Val_acc =  0.8479\n",
            "Iteration  3172 : Loss =  0.36504388  Acc:  0.87383336 Val_loss =  0.43934765 Val_acc =  0.8478\n",
            "Iteration  3173 : Loss =  0.36503017  Acc:  0.87383336 Val_loss =  0.4393476 Val_acc =  0.8477\n",
            "Iteration  3174 : Loss =  0.36501646  Acc:  0.87385 Val_loss =  0.43934757 Val_acc =  0.8477\n",
            "Iteration  3175 : Loss =  0.36500272  Acc:  0.87383336 Val_loss =  0.43934748 Val_acc =  0.8477\n",
            "Iteration  3176 : Loss =  0.36498904  Acc:  0.87383336 Val_loss =  0.43934736 Val_acc =  0.8477\n",
            "Iteration  3177 : Loss =  0.36497533  Acc:  0.87383336 Val_loss =  0.43934733 Val_acc =  0.8477\n",
            "Iteration  3178 : Loss =  0.36496165  Acc:  0.87385 Val_loss =  0.43934727 Val_acc =  0.8478\n",
            "Iteration  3179 : Loss =  0.36494794  Acc:  0.87385 Val_loss =  0.43934718 Val_acc =  0.8478\n",
            "Iteration  3180 : Loss =  0.36493427  Acc:  0.8738667 Val_loss =  0.43934712 Val_acc =  0.8478\n",
            "Iteration  3181 : Loss =  0.3649206  Acc:  0.8738833 Val_loss =  0.43934706 Val_acc =  0.8478\n",
            "Iteration  3182 : Loss =  0.3649069  Acc:  0.8738833 Val_loss =  0.43934706 Val_acc =  0.8478\n",
            "Iteration  3183 : Loss =  0.36489323  Acc:  0.8739 Val_loss =  0.43934703 Val_acc =  0.8478\n",
            "Iteration  3184 : Loss =  0.36487958  Acc:  0.8739167 Val_loss =  0.43934697 Val_acc =  0.8478\n",
            "Iteration  3185 : Loss =  0.36486596  Acc:  0.8739167 Val_loss =  0.43934697 Val_acc =  0.8478\n",
            "Iteration  3186 : Loss =  0.36485228  Acc:  0.8739167 Val_loss =  0.4393469 Val_acc =  0.8478\n",
            "Iteration  3187 : Loss =  0.36483863  Acc:  0.8739167 Val_loss =  0.4393469 Val_acc =  0.8478\n",
            "Iteration  3188 : Loss =  0.364825  Acc:  0.8739333 Val_loss =  0.43934688 Val_acc =  0.8478\n",
            "Iteration  3189 : Loss =  0.36481133  Acc:  0.87395 Val_loss =  0.43934688 Val_acc =  0.8478\n",
            "Iteration  3190 : Loss =  0.3647977  Acc:  0.87395 Val_loss =  0.43934688 Val_acc =  0.8478\n",
            "Iteration  3191 : Loss =  0.3647841  Acc:  0.87395 Val_loss =  0.43934688 Val_acc =  0.8478\n",
            "Iteration  3192 : Loss =  0.36477047  Acc:  0.8739667 Val_loss =  0.4393469 Val_acc =  0.8478\n",
            "Iteration  3193 : Loss =  0.36475682  Acc:  0.87395 Val_loss =  0.43934697 Val_acc =  0.8478\n",
            "Iteration  3194 : Loss =  0.36474323  Acc:  0.87395 Val_loss =  0.43934697 Val_acc =  0.8478\n",
            "Iteration  3195 : Loss =  0.36472964  Acc:  0.8739833 Val_loss =  0.43934697 Val_acc =  0.8478\n",
            "Iteration  3196 : Loss =  0.36471605  Acc:  0.874 Val_loss =  0.43934706 Val_acc =  0.8478\n",
            "Iteration  3197 : Loss =  0.36470243  Acc:  0.87405 Val_loss =  0.43934706 Val_acc =  0.8478\n",
            "Iteration  3198 : Loss =  0.36468887  Acc:  0.87405 Val_loss =  0.43934706 Val_acc =  0.8478\n",
            "Iteration  3199 : Loss =  0.36467525  Acc:  0.87406665 Val_loss =  0.43934712 Val_acc =  0.8478\n",
            "Iteration  3200 : Loss =  0.36466172  Acc:  0.87405 Val_loss =  0.43934718 Val_acc =  0.8478\n",
            "Iteration  3201 : Loss =  0.3646481  Acc:  0.87406665 Val_loss =  0.43934727 Val_acc =  0.8478\n",
            "Iteration  3202 : Loss =  0.36463457  Acc:  0.87406665 Val_loss =  0.43934733 Val_acc =  0.8478\n",
            "Iteration  3203 : Loss =  0.36462104  Acc:  0.87406665 Val_loss =  0.43934736 Val_acc =  0.8478\n",
            "Iteration  3204 : Loss =  0.36460745  Acc:  0.87406665 Val_loss =  0.43934748 Val_acc =  0.8478\n",
            "Iteration  3205 : Loss =  0.36459392  Acc:  0.87406665 Val_loss =  0.4393475 Val_acc =  0.8478\n",
            "Iteration  3206 : Loss =  0.36458036  Acc:  0.87408334 Val_loss =  0.4393476 Val_acc =  0.8478\n",
            "Iteration  3207 : Loss =  0.36456683  Acc:  0.87408334 Val_loss =  0.43934765 Val_acc =  0.8478\n",
            "Iteration  3208 : Loss =  0.36455333  Acc:  0.87406665 Val_loss =  0.43934774 Val_acc =  0.8478\n",
            "Iteration  3209 : Loss =  0.36453977  Acc:  0.87408334 Val_loss =  0.4393479 Val_acc =  0.8478\n",
            "Iteration  3210 : Loss =  0.36452624  Acc:  0.87408334 Val_loss =  0.43934795 Val_acc =  0.8478\n",
            "Iteration  3211 : Loss =  0.36451274  Acc:  0.87408334 Val_loss =  0.4393481 Val_acc =  0.8478\n",
            "Iteration  3212 : Loss =  0.3644992  Acc:  0.87408334 Val_loss =  0.4393482 Val_acc =  0.8478\n",
            "Iteration  3213 : Loss =  0.3644857  Acc:  0.87406665 Val_loss =  0.43934834 Val_acc =  0.8478\n",
            "Iteration  3214 : Loss =  0.3644722  Acc:  0.87406665 Val_loss =  0.43934843 Val_acc =  0.8478\n",
            "Iteration  3215 : Loss =  0.3644587  Acc:  0.87408334 Val_loss =  0.43934858 Val_acc =  0.8478\n",
            "Iteration  3216 : Loss =  0.36444524  Acc:  0.87408334 Val_loss =  0.43934873 Val_acc =  0.8478\n",
            "Iteration  3217 : Loss =  0.36443177  Acc:  0.87408334 Val_loss =  0.43934882 Val_acc =  0.8478\n",
            "Iteration  3218 : Loss =  0.36441824  Acc:  0.87408334 Val_loss =  0.43934903 Val_acc =  0.8478\n",
            "Iteration  3219 : Loss =  0.36440483  Acc:  0.87408334 Val_loss =  0.4393491 Val_acc =  0.8478\n",
            "Iteration  3220 : Loss =  0.36439133  Acc:  0.87408334 Val_loss =  0.43934932 Val_acc =  0.8478\n",
            "Iteration  3221 : Loss =  0.36437786  Acc:  0.87408334 Val_loss =  0.43934947 Val_acc =  0.8478\n",
            "Iteration  3222 : Loss =  0.3643644  Acc:  0.8741 Val_loss =  0.43934962 Val_acc =  0.8478\n",
            "Iteration  3223 : Loss =  0.36435094  Acc:  0.8741 Val_loss =  0.4393498 Val_acc =  0.8478\n",
            "Iteration  3224 : Loss =  0.3643375  Acc:  0.87408334 Val_loss =  0.43935 Val_acc =  0.8478\n",
            "Iteration  3225 : Loss =  0.36432406  Acc:  0.87408334 Val_loss =  0.4393501 Val_acc =  0.8478\n",
            "Iteration  3226 : Loss =  0.36431062  Acc:  0.87408334 Val_loss =  0.43935034 Val_acc =  0.8478\n",
            "Iteration  3227 : Loss =  0.3642972  Acc:  0.8741 Val_loss =  0.4393505 Val_acc =  0.8478\n",
            "Iteration  3228 : Loss =  0.3642837  Acc:  0.8741 Val_loss =  0.43935072 Val_acc =  0.8478\n",
            "Iteration  3229 : Loss =  0.36427036  Acc:  0.8741 Val_loss =  0.43935093 Val_acc =  0.8478\n",
            "Iteration  3230 : Loss =  0.36425695  Acc:  0.8741 Val_loss =  0.4393511 Val_acc =  0.8477\n",
            "Iteration  3231 : Loss =  0.3642435  Acc:  0.8741 Val_loss =  0.43935132 Val_acc =  0.8477\n",
            "Iteration  3232 : Loss =  0.3642301  Acc:  0.8741 Val_loss =  0.43935156 Val_acc =  0.8476\n",
            "Iteration  3233 : Loss =  0.3642167  Acc:  0.87411666 Val_loss =  0.43935177 Val_acc =  0.8476\n",
            "Iteration  3234 : Loss =  0.36420333  Acc:  0.87411666 Val_loss =  0.43935195 Val_acc =  0.8476\n",
            "Iteration  3235 : Loss =  0.36418992  Acc:  0.87411666 Val_loss =  0.43935224 Val_acc =  0.8476\n",
            "Iteration  3236 : Loss =  0.36417654  Acc:  0.87411666 Val_loss =  0.43935245 Val_acc =  0.8476\n",
            "Iteration  3237 : Loss =  0.36416316  Acc:  0.87411666 Val_loss =  0.4393527 Val_acc =  0.8475\n",
            "Iteration  3238 : Loss =  0.36414978  Acc:  0.87411666 Val_loss =  0.43935293 Val_acc =  0.8474\n",
            "Iteration  3239 : Loss =  0.3641364  Acc:  0.8741 Val_loss =  0.43935317 Val_acc =  0.8474\n",
            "Iteration  3240 : Loss =  0.36412305  Acc:  0.8741 Val_loss =  0.43935347 Val_acc =  0.8474\n",
            "Iteration  3241 : Loss =  0.3641097  Acc:  0.8741 Val_loss =  0.4393537 Val_acc =  0.8474\n",
            "Iteration  3242 : Loss =  0.36409634  Acc:  0.87411666 Val_loss =  0.43935394 Val_acc =  0.8474\n",
            "Iteration  3243 : Loss =  0.36408302  Acc:  0.8741 Val_loss =  0.4393542 Val_acc =  0.8474\n",
            "Iteration  3244 : Loss =  0.36406967  Acc:  0.8741 Val_loss =  0.43935448 Val_acc =  0.8474\n",
            "Iteration  3245 : Loss =  0.36405632  Acc:  0.8741 Val_loss =  0.43935478 Val_acc =  0.8474\n",
            "Iteration  3246 : Loss =  0.36404297  Acc:  0.8741 Val_loss =  0.43935508 Val_acc =  0.8474\n",
            "Iteration  3247 : Loss =  0.36402965  Acc:  0.87408334 Val_loss =  0.43935537 Val_acc =  0.8474\n",
            "Iteration  3248 : Loss =  0.36401635  Acc:  0.87408334 Val_loss =  0.43935567 Val_acc =  0.8474\n",
            "Iteration  3249 : Loss =  0.364003  Acc:  0.87406665 Val_loss =  0.43935597 Val_acc =  0.8474\n",
            "Iteration  3250 : Loss =  0.3639897  Acc:  0.87406665 Val_loss =  0.43935624 Val_acc =  0.8474\n",
            "Iteration  3251 : Loss =  0.3639764  Acc:  0.87406665 Val_loss =  0.4393566 Val_acc =  0.8474\n",
            "Iteration  3252 : Loss =  0.3639631  Acc:  0.87403333 Val_loss =  0.4393569 Val_acc =  0.8474\n",
            "Iteration  3253 : Loss =  0.3639498  Acc:  0.87405 Val_loss =  0.43935722 Val_acc =  0.8474\n",
            "Iteration  3254 : Loss =  0.3639365  Acc:  0.87408334 Val_loss =  0.43935752 Val_acc =  0.8474\n",
            "Iteration  3255 : Loss =  0.36392325  Acc:  0.87408334 Val_loss =  0.43935785 Val_acc =  0.8474\n",
            "Iteration  3256 : Loss =  0.36390993  Acc:  0.87408334 Val_loss =  0.4393582 Val_acc =  0.8474\n",
            "Iteration  3257 : Loss =  0.36389667  Acc:  0.87408334 Val_loss =  0.43935853 Val_acc =  0.8473\n",
            "Iteration  3258 : Loss =  0.3638834  Acc:  0.8741 Val_loss =  0.4393589 Val_acc =  0.8473\n",
            "Iteration  3259 : Loss =  0.36387014  Acc:  0.87413335 Val_loss =  0.43935922 Val_acc =  0.8473\n",
            "Iteration  3260 : Loss =  0.3638569  Acc:  0.8741 Val_loss =  0.43935958 Val_acc =  0.8473\n",
            "Iteration  3261 : Loss =  0.36384362  Acc:  0.87411666 Val_loss =  0.43935996 Val_acc =  0.8473\n",
            "Iteration  3262 : Loss =  0.36383042  Acc:  0.87411666 Val_loss =  0.43936035 Val_acc =  0.8473\n",
            "Iteration  3263 : Loss =  0.36381713  Acc:  0.8741 Val_loss =  0.4393607 Val_acc =  0.8473\n",
            "Iteration  3264 : Loss =  0.3638039  Acc:  0.8741 Val_loss =  0.4393611 Val_acc =  0.8473\n",
            "Iteration  3265 : Loss =  0.36379066  Acc:  0.87413335 Val_loss =  0.43936148 Val_acc =  0.8473\n",
            "Iteration  3266 : Loss =  0.3637774  Acc:  0.87416667 Val_loss =  0.4393618 Val_acc =  0.8473\n",
            "Iteration  3267 : Loss =  0.3637642  Acc:  0.87416667 Val_loss =  0.4393622 Val_acc =  0.8473\n",
            "Iteration  3268 : Loss =  0.36375096  Acc:  0.87415 Val_loss =  0.4393626 Val_acc =  0.8473\n",
            "Iteration  3269 : Loss =  0.36373776  Acc:  0.87415 Val_loss =  0.439363 Val_acc =  0.8473\n",
            "Iteration  3270 : Loss =  0.36372453  Acc:  0.87415 Val_loss =  0.43936342 Val_acc =  0.8473\n",
            "Iteration  3271 : Loss =  0.36371136  Acc:  0.87415 Val_loss =  0.43936387 Val_acc =  0.8473\n",
            "Iteration  3272 : Loss =  0.36369815  Acc:  0.87416667 Val_loss =  0.4393642 Val_acc =  0.8473\n",
            "Iteration  3273 : Loss =  0.36368495  Acc:  0.87416667 Val_loss =  0.43936464 Val_acc =  0.8473\n",
            "Iteration  3274 : Loss =  0.36367178  Acc:  0.87416667 Val_loss =  0.4393651 Val_acc =  0.8472\n",
            "Iteration  3275 : Loss =  0.3636586  Acc:  0.87416667 Val_loss =  0.43936554 Val_acc =  0.8472\n",
            "Iteration  3276 : Loss =  0.36364543  Acc:  0.87416667 Val_loss =  0.43936595 Val_acc =  0.8472\n",
            "Iteration  3277 : Loss =  0.36363223  Acc:  0.87416667 Val_loss =  0.4393664 Val_acc =  0.8472\n",
            "Iteration  3278 : Loss =  0.3636191  Acc:  0.87416667 Val_loss =  0.43936685 Val_acc =  0.8472\n",
            "Iteration  3279 : Loss =  0.36360592  Acc:  0.87418336 Val_loss =  0.4393673 Val_acc =  0.8472\n",
            "Iteration  3280 : Loss =  0.36359277  Acc:  0.87415 Val_loss =  0.4393677 Val_acc =  0.8472\n",
            "Iteration  3281 : Loss =  0.36357963  Acc:  0.87415 Val_loss =  0.43936822 Val_acc =  0.8472\n",
            "Iteration  3282 : Loss =  0.36356646  Acc:  0.87413335 Val_loss =  0.43936867 Val_acc =  0.8472\n",
            "Iteration  3283 : Loss =  0.36355332  Acc:  0.87411666 Val_loss =  0.43936914 Val_acc =  0.8472\n",
            "Iteration  3284 : Loss =  0.3635402  Acc:  0.87411666 Val_loss =  0.43936962 Val_acc =  0.8472\n",
            "Iteration  3285 : Loss =  0.3635271  Acc:  0.8741 Val_loss =  0.43937013 Val_acc =  0.8472\n",
            "Iteration  3286 : Loss =  0.36351395  Acc:  0.8741 Val_loss =  0.43937054 Val_acc =  0.8472\n",
            "Iteration  3287 : Loss =  0.3635008  Acc:  0.8741 Val_loss =  0.43937105 Val_acc =  0.8472\n",
            "Iteration  3288 : Loss =  0.3634877  Acc:  0.87415 Val_loss =  0.43937153 Val_acc =  0.8471\n",
            "Iteration  3289 : Loss =  0.3634746  Acc:  0.87415 Val_loss =  0.43937206 Val_acc =  0.8471\n",
            "Iteration  3290 : Loss =  0.3634615  Acc:  0.87418336 Val_loss =  0.43937257 Val_acc =  0.8471\n",
            "Iteration  3291 : Loss =  0.36344838  Acc:  0.87418336 Val_loss =  0.43937305 Val_acc =  0.8472\n",
            "Iteration  3292 : Loss =  0.3634353  Acc:  0.87418336 Val_loss =  0.43937352 Val_acc =  0.8472\n",
            "Iteration  3293 : Loss =  0.36342221  Acc:  0.87418336 Val_loss =  0.43937406 Val_acc =  0.8473\n",
            "Iteration  3294 : Loss =  0.3634091  Acc:  0.8742 Val_loss =  0.4393746 Val_acc =  0.8473\n",
            "Iteration  3295 : Loss =  0.36339602  Acc:  0.87418336 Val_loss =  0.4393751 Val_acc =  0.8473\n",
            "Iteration  3296 : Loss =  0.36338294  Acc:  0.87418336 Val_loss =  0.43937567 Val_acc =  0.8473\n",
            "Iteration  3297 : Loss =  0.36336988  Acc:  0.87418336 Val_loss =  0.43937624 Val_acc =  0.8473\n",
            "Iteration  3298 : Loss =  0.36335683  Acc:  0.8742 Val_loss =  0.43937677 Val_acc =  0.8473\n",
            "Iteration  3299 : Loss =  0.36334375  Acc:  0.87416667 Val_loss =  0.4393773 Val_acc =  0.8473\n",
            "Iteration  3300 : Loss =  0.36333072  Acc:  0.87418336 Val_loss =  0.43937784 Val_acc =  0.8473\n",
            "Iteration  3301 : Loss =  0.36331764  Acc:  0.87418336 Val_loss =  0.43937838 Val_acc =  0.8472\n",
            "Iteration  3302 : Loss =  0.36330462  Acc:  0.87418336 Val_loss =  0.43937895 Val_acc =  0.8472\n",
            "Iteration  3303 : Loss =  0.36329153  Acc:  0.8742 Val_loss =  0.43937954 Val_acc =  0.8472\n",
            "Iteration  3304 : Loss =  0.3632785  Acc:  0.8742 Val_loss =  0.43938014 Val_acc =  0.8472\n",
            "Iteration  3305 : Loss =  0.36326548  Acc:  0.8742167 Val_loss =  0.43938068 Val_acc =  0.8472\n",
            "Iteration  3306 : Loss =  0.36325246  Acc:  0.8742167 Val_loss =  0.43938124 Val_acc =  0.8472\n",
            "Iteration  3307 : Loss =  0.36323947  Acc:  0.8742167 Val_loss =  0.43938184 Val_acc =  0.8472\n",
            "Iteration  3308 : Loss =  0.36322644  Acc:  0.8742 Val_loss =  0.43938243 Val_acc =  0.8472\n",
            "Iteration  3309 : Loss =  0.36321345  Acc:  0.8742 Val_loss =  0.439383 Val_acc =  0.8472\n",
            "Iteration  3310 : Loss =  0.36320043  Acc:  0.8742167 Val_loss =  0.4393836 Val_acc =  0.8472\n",
            "Iteration  3311 : Loss =  0.36318743  Acc:  0.8742167 Val_loss =  0.4393842 Val_acc =  0.8472\n",
            "Iteration  3312 : Loss =  0.3631744  Acc:  0.8742167 Val_loss =  0.43938488 Val_acc =  0.8472\n",
            "Iteration  3313 : Loss =  0.36316144  Acc:  0.8742167 Val_loss =  0.43938544 Val_acc =  0.8472\n",
            "Iteration  3314 : Loss =  0.36314845  Acc:  0.8742 Val_loss =  0.43938604 Val_acc =  0.8471\n",
            "Iteration  3315 : Loss =  0.3631355  Acc:  0.8742 Val_loss =  0.43938667 Val_acc =  0.847\n",
            "Iteration  3316 : Loss =  0.3631225  Acc:  0.8742 Val_loss =  0.4393873 Val_acc =  0.847\n",
            "Iteration  3317 : Loss =  0.36310953  Acc:  0.8742 Val_loss =  0.43938795 Val_acc =  0.847\n",
            "Iteration  3318 : Loss =  0.36309654  Acc:  0.87418336 Val_loss =  0.43938857 Val_acc =  0.847\n",
            "Iteration  3319 : Loss =  0.3630836  Acc:  0.8742 Val_loss =  0.4393892 Val_acc =  0.847\n",
            "Iteration  3320 : Loss =  0.36307064  Acc:  0.8742167 Val_loss =  0.43938985 Val_acc =  0.847\n",
            "Iteration  3321 : Loss =  0.36305767  Acc:  0.8742167 Val_loss =  0.43939054 Val_acc =  0.847\n",
            "Iteration  3322 : Loss =  0.36304474  Acc:  0.8742167 Val_loss =  0.43939123 Val_acc =  0.847\n",
            "Iteration  3323 : Loss =  0.3630318  Acc:  0.8742167 Val_loss =  0.43939185 Val_acc =  0.847\n",
            "Iteration  3324 : Loss =  0.36301887  Acc:  0.8742 Val_loss =  0.43939254 Val_acc =  0.847\n",
            "Iteration  3325 : Loss =  0.36300594  Acc:  0.8742 Val_loss =  0.43939316 Val_acc =  0.8471\n",
            "Iteration  3326 : Loss =  0.36299303  Acc:  0.8742167 Val_loss =  0.43939385 Val_acc =  0.8471\n",
            "Iteration  3327 : Loss =  0.36298007  Acc:  0.8742167 Val_loss =  0.43939453 Val_acc =  0.8471\n",
            "Iteration  3328 : Loss =  0.3629672  Acc:  0.8742333 Val_loss =  0.43939522 Val_acc =  0.8471\n",
            "Iteration  3329 : Loss =  0.36295426  Acc:  0.8742333 Val_loss =  0.43939593 Val_acc =  0.8472\n",
            "Iteration  3330 : Loss =  0.36294138  Acc:  0.8742167 Val_loss =  0.43939662 Val_acc =  0.8472\n",
            "Iteration  3331 : Loss =  0.36292845  Acc:  0.8742167 Val_loss =  0.43939728 Val_acc =  0.8472\n",
            "Iteration  3332 : Loss =  0.36291555  Acc:  0.8742333 Val_loss =  0.43939805 Val_acc =  0.8472\n",
            "Iteration  3333 : Loss =  0.36290267  Acc:  0.8742833 Val_loss =  0.43939874 Val_acc =  0.8473\n",
            "Iteration  3334 : Loss =  0.36288977  Acc:  0.8742833 Val_loss =  0.43939942 Val_acc =  0.8472\n",
            "Iteration  3335 : Loss =  0.3628769  Acc:  0.8742833 Val_loss =  0.43940014 Val_acc =  0.8472\n",
            "Iteration  3336 : Loss =  0.36286402  Acc:  0.8742833 Val_loss =  0.43940088 Val_acc =  0.8471\n",
            "Iteration  3337 : Loss =  0.36285114  Acc:  0.8743 Val_loss =  0.43940166 Val_acc =  0.8471\n",
            "Iteration  3338 : Loss =  0.36283824  Acc:  0.8743 Val_loss =  0.43940234 Val_acc =  0.8471\n",
            "Iteration  3339 : Loss =  0.3628254  Acc:  0.8742667 Val_loss =  0.43940303 Val_acc =  0.8471\n",
            "Iteration  3340 : Loss =  0.36281258  Acc:  0.8742667 Val_loss =  0.4394038 Val_acc =  0.8471\n",
            "Iteration  3341 : Loss =  0.3627997  Acc:  0.8742833 Val_loss =  0.43940458 Val_acc =  0.8472\n",
            "Iteration  3342 : Loss =  0.36278686  Acc:  0.8743 Val_loss =  0.43940532 Val_acc =  0.8473\n",
            "Iteration  3343 : Loss =  0.362774  Acc:  0.8743167 Val_loss =  0.43940607 Val_acc =  0.8473\n",
            "Iteration  3344 : Loss =  0.36276117  Acc:  0.8743333 Val_loss =  0.43940684 Val_acc =  0.8474\n",
            "Iteration  3345 : Loss =  0.3627483  Acc:  0.8743167 Val_loss =  0.43940762 Val_acc =  0.8474\n",
            "Iteration  3346 : Loss =  0.3627355  Acc:  0.8743167 Val_loss =  0.43940836 Val_acc =  0.8474\n",
            "Iteration  3347 : Loss =  0.36272267  Acc:  0.8743 Val_loss =  0.43940914 Val_acc =  0.8474\n",
            "Iteration  3348 : Loss =  0.36270985  Acc:  0.8742833 Val_loss =  0.43940997 Val_acc =  0.8474\n",
            "Iteration  3349 : Loss =  0.36269704  Acc:  0.8743167 Val_loss =  0.43941075 Val_acc =  0.8474\n",
            "Iteration  3350 : Loss =  0.36268425  Acc:  0.8743167 Val_loss =  0.43941152 Val_acc =  0.8474\n",
            "Iteration  3351 : Loss =  0.36267146  Acc:  0.8743 Val_loss =  0.4394123 Val_acc =  0.8474\n",
            "Iteration  3352 : Loss =  0.36265865  Acc:  0.8743 Val_loss =  0.4394131 Val_acc =  0.8474\n",
            "Iteration  3353 : Loss =  0.36264583  Acc:  0.8743 Val_loss =  0.4394139 Val_acc =  0.8474\n",
            "Iteration  3354 : Loss =  0.36263308  Acc:  0.8743 Val_loss =  0.4394147 Val_acc =  0.8474\n",
            "Iteration  3355 : Loss =  0.36262023  Acc:  0.8743 Val_loss =  0.4394155 Val_acc =  0.8474\n",
            "Iteration  3356 : Loss =  0.36260748  Acc:  0.8743 Val_loss =  0.43941635 Val_acc =  0.8475\n",
            "Iteration  3357 : Loss =  0.36259472  Acc:  0.8743167 Val_loss =  0.43941718 Val_acc =  0.8475\n",
            "Iteration  3358 : Loss =  0.36258194  Acc:  0.8743 Val_loss =  0.43941796 Val_acc =  0.8475\n",
            "Iteration  3359 : Loss =  0.3625692  Acc:  0.8743 Val_loss =  0.43941885 Val_acc =  0.8475\n",
            "Iteration  3360 : Loss =  0.3625564  Acc:  0.8743167 Val_loss =  0.43941963 Val_acc =  0.8475\n",
            "Iteration  3361 : Loss =  0.36254367  Acc:  0.8743333 Val_loss =  0.43942052 Val_acc =  0.8475\n",
            "Iteration  3362 : Loss =  0.36253092  Acc:  0.8743333 Val_loss =  0.43942133 Val_acc =  0.8475\n",
            "Iteration  3363 : Loss =  0.36251816  Acc:  0.8743333 Val_loss =  0.43942216 Val_acc =  0.8475\n",
            "Iteration  3364 : Loss =  0.36250544  Acc:  0.87435 Val_loss =  0.43942305 Val_acc =  0.8475\n",
            "Iteration  3365 : Loss =  0.3624927  Acc:  0.87438333 Val_loss =  0.43942392 Val_acc =  0.8475\n",
            "Iteration  3366 : Loss =  0.36247995  Acc:  0.87438333 Val_loss =  0.4394247 Val_acc =  0.8475\n",
            "Iteration  3367 : Loss =  0.36246723  Acc:  0.87438333 Val_loss =  0.43942565 Val_acc =  0.8475\n",
            "Iteration  3368 : Loss =  0.3624545  Acc:  0.87438333 Val_loss =  0.4394265 Val_acc =  0.8475\n",
            "Iteration  3369 : Loss =  0.3624418  Acc:  0.87443334 Val_loss =  0.4394274 Val_acc =  0.8475\n",
            "Iteration  3370 : Loss =  0.3624291  Acc:  0.87443334 Val_loss =  0.43942827 Val_acc =  0.8475\n",
            "Iteration  3371 : Loss =  0.36241633  Acc:  0.87443334 Val_loss =  0.43942916 Val_acc =  0.8475\n",
            "Iteration  3372 : Loss =  0.36240363  Acc:  0.87446666 Val_loss =  0.43943003 Val_acc =  0.8475\n",
            "Iteration  3373 : Loss =  0.36239097  Acc:  0.87448335 Val_loss =  0.43943092 Val_acc =  0.8475\n",
            "Iteration  3374 : Loss =  0.3623783  Acc:  0.87448335 Val_loss =  0.43943185 Val_acc =  0.8475\n",
            "Iteration  3375 : Loss =  0.36236557  Acc:  0.8745 Val_loss =  0.4394327 Val_acc =  0.8475\n",
            "Iteration  3376 : Loss =  0.3623529  Acc:  0.87453336 Val_loss =  0.43943363 Val_acc =  0.8475\n",
            "Iteration  3377 : Loss =  0.36234024  Acc:  0.87453336 Val_loss =  0.43943456 Val_acc =  0.8475\n",
            "Iteration  3378 : Loss =  0.36232755  Acc:  0.87453336 Val_loss =  0.43943545 Val_acc =  0.8475\n",
            "Iteration  3379 : Loss =  0.36231488  Acc:  0.87455 Val_loss =  0.43943644 Val_acc =  0.8475\n",
            "Iteration  3380 : Loss =  0.3623022  Acc:  0.87455 Val_loss =  0.4394373 Val_acc =  0.8475\n",
            "Iteration  3381 : Loss =  0.36228958  Acc:  0.8745833 Val_loss =  0.43943828 Val_acc =  0.8474\n",
            "Iteration  3382 : Loss =  0.36227688  Acc:  0.8745833 Val_loss =  0.4394392 Val_acc =  0.8474\n",
            "Iteration  3383 : Loss =  0.36226425  Acc:  0.8745667 Val_loss =  0.43944013 Val_acc =  0.8474\n",
            "Iteration  3384 : Loss =  0.3622516  Acc:  0.8746167 Val_loss =  0.4394411 Val_acc =  0.8474\n",
            "Iteration  3385 : Loss =  0.36223897  Acc:  0.8746167 Val_loss =  0.4394421 Val_acc =  0.8474\n",
            "Iteration  3386 : Loss =  0.3622263  Acc:  0.8746167 Val_loss =  0.43944296 Val_acc =  0.8474\n",
            "Iteration  3387 : Loss =  0.36221367  Acc:  0.8746167 Val_loss =  0.43944395 Val_acc =  0.8474\n",
            "Iteration  3388 : Loss =  0.36220104  Acc:  0.8746167 Val_loss =  0.43944493 Val_acc =  0.8474\n",
            "Iteration  3389 : Loss =  0.36218846  Acc:  0.8746167 Val_loss =  0.4394459 Val_acc =  0.8474\n",
            "Iteration  3390 : Loss =  0.36217585  Acc:  0.8746333 Val_loss =  0.43944687 Val_acc =  0.8474\n",
            "Iteration  3391 : Loss =  0.36216322  Acc:  0.87465 Val_loss =  0.43944785 Val_acc =  0.8474\n",
            "Iteration  3392 : Loss =  0.36215058  Acc:  0.8746667 Val_loss =  0.43944883 Val_acc =  0.8474\n",
            "Iteration  3393 : Loss =  0.36213803  Acc:  0.8746333 Val_loss =  0.43944982 Val_acc =  0.8474\n",
            "Iteration  3394 : Loss =  0.3621254  Acc:  0.87465 Val_loss =  0.43945077 Val_acc =  0.8474\n",
            "Iteration  3395 : Loss =  0.36211282  Acc:  0.8746833 Val_loss =  0.4394518 Val_acc =  0.8474\n",
            "Iteration  3396 : Loss =  0.36210018  Acc:  0.8746833 Val_loss =  0.43945283 Val_acc =  0.8474\n",
            "Iteration  3397 : Loss =  0.36208764  Acc:  0.8746667 Val_loss =  0.4394538 Val_acc =  0.8473\n",
            "Iteration  3398 : Loss =  0.36207506  Acc:  0.8746667 Val_loss =  0.43945482 Val_acc =  0.8473\n",
            "Iteration  3399 : Loss =  0.36206245  Acc:  0.8746833 Val_loss =  0.43945587 Val_acc =  0.8473\n",
            "Iteration  3400 : Loss =  0.36204994  Acc:  0.8746833 Val_loss =  0.43945685 Val_acc =  0.8473\n",
            "Iteration  3401 : Loss =  0.36203733  Acc:  0.8746833 Val_loss =  0.43945792 Val_acc =  0.8474\n",
            "Iteration  3402 : Loss =  0.3620248  Acc:  0.8747 Val_loss =  0.43945894 Val_acc =  0.8474\n",
            "Iteration  3403 : Loss =  0.36201224  Acc:  0.8747 Val_loss =  0.43945995 Val_acc =  0.8474\n",
            "Iteration  3404 : Loss =  0.36199966  Acc:  0.8747 Val_loss =  0.43946093 Val_acc =  0.8474\n",
            "Iteration  3405 : Loss =  0.3619871  Acc:  0.8747 Val_loss =  0.439462 Val_acc =  0.8474\n",
            "Iteration  3406 : Loss =  0.36197457  Acc:  0.8747 Val_loss =  0.43946308 Val_acc =  0.8474\n",
            "Iteration  3407 : Loss =  0.36196205  Acc:  0.87471664 Val_loss =  0.43946415 Val_acc =  0.8474\n",
            "Iteration  3408 : Loss =  0.36194947  Acc:  0.87471664 Val_loss =  0.43946514 Val_acc =  0.8474\n",
            "Iteration  3409 : Loss =  0.361937  Acc:  0.87471664 Val_loss =  0.4394662 Val_acc =  0.8474\n",
            "Iteration  3410 : Loss =  0.36192444  Acc:  0.87471664 Val_loss =  0.43946728 Val_acc =  0.8474\n",
            "Iteration  3411 : Loss =  0.36191195  Acc:  0.8747 Val_loss =  0.43946835 Val_acc =  0.8474\n",
            "Iteration  3412 : Loss =  0.3618994  Acc:  0.8747 Val_loss =  0.43946943 Val_acc =  0.8474\n",
            "Iteration  3413 : Loss =  0.36188692  Acc:  0.87471664 Val_loss =  0.4394705 Val_acc =  0.8474\n",
            "Iteration  3414 : Loss =  0.3618744  Acc:  0.8747 Val_loss =  0.43947163 Val_acc =  0.8474\n",
            "Iteration  3415 : Loss =  0.3618619  Acc:  0.8747 Val_loss =  0.43947265 Val_acc =  0.8475\n",
            "Iteration  3416 : Loss =  0.36184943  Acc:  0.8747 Val_loss =  0.43947384 Val_acc =  0.8475\n",
            "Iteration  3417 : Loss =  0.3618369  Acc:  0.8747 Val_loss =  0.4394749 Val_acc =  0.8475\n",
            "Iteration  3418 : Loss =  0.36182445  Acc:  0.87471664 Val_loss =  0.43947598 Val_acc =  0.8475\n",
            "Iteration  3419 : Loss =  0.36181194  Acc:  0.87471664 Val_loss =  0.4394771 Val_acc =  0.8475\n",
            "Iteration  3420 : Loss =  0.36179945  Acc:  0.87471664 Val_loss =  0.43947822 Val_acc =  0.8475\n",
            "Iteration  3421 : Loss =  0.361787  Acc:  0.87471664 Val_loss =  0.4394793 Val_acc =  0.8475\n",
            "Iteration  3422 : Loss =  0.3617745  Acc:  0.87471664 Val_loss =  0.43948048 Val_acc =  0.8475\n",
            "Iteration  3423 : Loss =  0.36176205  Acc:  0.8747333 Val_loss =  0.43948156 Val_acc =  0.8475\n",
            "Iteration  3424 : Loss =  0.36174962  Acc:  0.87475 Val_loss =  0.43948266 Val_acc =  0.8475\n",
            "Iteration  3425 : Loss =  0.36173713  Acc:  0.87476665 Val_loss =  0.4394838 Val_acc =  0.8475\n",
            "Iteration  3426 : Loss =  0.36172467  Acc:  0.87478334 Val_loss =  0.43948495 Val_acc =  0.8475\n",
            "Iteration  3427 : Loss =  0.36171225  Acc:  0.87481666 Val_loss =  0.4394861 Val_acc =  0.8475\n",
            "Iteration  3428 : Loss =  0.36169982  Acc:  0.8748 Val_loss =  0.43948725 Val_acc =  0.8474\n",
            "Iteration  3429 : Loss =  0.36168736  Acc:  0.87478334 Val_loss =  0.43948838 Val_acc =  0.8474\n",
            "Iteration  3430 : Loss =  0.36167493  Acc:  0.87478334 Val_loss =  0.43948954 Val_acc =  0.8474\n",
            "Iteration  3431 : Loss =  0.3616625  Acc:  0.87478334 Val_loss =  0.43949074 Val_acc =  0.8474\n",
            "Iteration  3432 : Loss =  0.3616501  Acc:  0.87478334 Val_loss =  0.4394919 Val_acc =  0.8474\n",
            "Iteration  3433 : Loss =  0.36163768  Acc:  0.8748 Val_loss =  0.43949306 Val_acc =  0.8474\n",
            "Iteration  3434 : Loss =  0.36162525  Acc:  0.8748 Val_loss =  0.4394942 Val_acc =  0.8474\n",
            "Iteration  3435 : Loss =  0.36161286  Acc:  0.8748 Val_loss =  0.4394954 Val_acc =  0.8474\n",
            "Iteration  3436 : Loss =  0.36160046  Acc:  0.8748 Val_loss =  0.43949658 Val_acc =  0.8474\n",
            "Iteration  3437 : Loss =  0.36158806  Acc:  0.87481666 Val_loss =  0.43949774 Val_acc =  0.8475\n",
            "Iteration  3438 : Loss =  0.36157566  Acc:  0.87481666 Val_loss =  0.43949896 Val_acc =  0.8475\n",
            "Iteration  3439 : Loss =  0.36156324  Acc:  0.87485 Val_loss =  0.43950015 Val_acc =  0.8475\n",
            "Iteration  3440 : Loss =  0.36155087  Acc:  0.87485 Val_loss =  0.43950132 Val_acc =  0.8475\n",
            "Iteration  3441 : Loss =  0.3615385  Acc:  0.87485 Val_loss =  0.43950254 Val_acc =  0.8475\n",
            "Iteration  3442 : Loss =  0.3615261  Acc:  0.87483335 Val_loss =  0.43950376 Val_acc =  0.8475\n",
            "Iteration  3443 : Loss =  0.36151373  Acc:  0.87481666 Val_loss =  0.43950498 Val_acc =  0.8475\n",
            "Iteration  3444 : Loss =  0.36150137  Acc:  0.87485 Val_loss =  0.4395062 Val_acc =  0.8475\n",
            "Iteration  3445 : Loss =  0.361489  Acc:  0.87485 Val_loss =  0.43950742 Val_acc =  0.8476\n",
            "Iteration  3446 : Loss =  0.36147666  Acc:  0.87485 Val_loss =  0.4395086 Val_acc =  0.8476\n",
            "Iteration  3447 : Loss =  0.3614643  Acc:  0.87485 Val_loss =  0.43950987 Val_acc =  0.8476\n",
            "Iteration  3448 : Loss =  0.36145195  Acc:  0.87486666 Val_loss =  0.4395111 Val_acc =  0.8476\n",
            "Iteration  3449 : Loss =  0.36143962  Acc:  0.87486666 Val_loss =  0.43951234 Val_acc =  0.8476\n",
            "Iteration  3450 : Loss =  0.36142725  Acc:  0.87486666 Val_loss =  0.43951356 Val_acc =  0.8476\n",
            "Iteration  3451 : Loss =  0.36141494  Acc:  0.87485 Val_loss =  0.43951485 Val_acc =  0.8476\n",
            "Iteration  3452 : Loss =  0.3614026  Acc:  0.87485 Val_loss =  0.43951607 Val_acc =  0.8476\n",
            "Iteration  3453 : Loss =  0.3613903  Acc:  0.87483335 Val_loss =  0.43951732 Val_acc =  0.8477\n",
            "Iteration  3454 : Loss =  0.36137792  Acc:  0.87486666 Val_loss =  0.4395186 Val_acc =  0.8477\n",
            "Iteration  3455 : Loss =  0.36136562  Acc:  0.87486666 Val_loss =  0.43951982 Val_acc =  0.8477\n",
            "Iteration  3456 : Loss =  0.3613533  Acc:  0.87486666 Val_loss =  0.4395211 Val_acc =  0.8477\n",
            "Iteration  3457 : Loss =  0.36134103  Acc:  0.87486666 Val_loss =  0.43952236 Val_acc =  0.8477\n",
            "Iteration  3458 : Loss =  0.36132872  Acc:  0.87486666 Val_loss =  0.43952364 Val_acc =  0.8477\n",
            "Iteration  3459 : Loss =  0.3613164  Acc:  0.87486666 Val_loss =  0.43952495 Val_acc =  0.8477\n",
            "Iteration  3460 : Loss =  0.3613041  Acc:  0.87485 Val_loss =  0.43952626 Val_acc =  0.8477\n",
            "Iteration  3461 : Loss =  0.36129183  Acc:  0.87485 Val_loss =  0.43952754 Val_acc =  0.8478\n",
            "Iteration  3462 : Loss =  0.36127952  Acc:  0.87485 Val_loss =  0.43952882 Val_acc =  0.8478\n",
            "Iteration  3463 : Loss =  0.36126724  Acc:  0.87483335 Val_loss =  0.43953013 Val_acc =  0.8478\n",
            "Iteration  3464 : Loss =  0.36125496  Acc:  0.87483335 Val_loss =  0.43953145 Val_acc =  0.8479\n",
            "Iteration  3465 : Loss =  0.3612427  Acc:  0.87485 Val_loss =  0.43953273 Val_acc =  0.8479\n",
            "Iteration  3466 : Loss =  0.36123043  Acc:  0.87485 Val_loss =  0.43953407 Val_acc =  0.8479\n",
            "Iteration  3467 : Loss =  0.36121815  Acc:  0.87485 Val_loss =  0.43953535 Val_acc =  0.8479\n",
            "Iteration  3468 : Loss =  0.36120594  Acc:  0.87485 Val_loss =  0.43953672 Val_acc =  0.8479\n",
            "Iteration  3469 : Loss =  0.36119366  Acc:  0.87488335 Val_loss =  0.439538 Val_acc =  0.8479\n",
            "Iteration  3470 : Loss =  0.3611814  Acc:  0.87488335 Val_loss =  0.43953934 Val_acc =  0.8479\n",
            "Iteration  3471 : Loss =  0.36116913  Acc:  0.87488335 Val_loss =  0.4395407 Val_acc =  0.8479\n",
            "Iteration  3472 : Loss =  0.3611569  Acc:  0.87486666 Val_loss =  0.439542 Val_acc =  0.8479\n",
            "Iteration  3473 : Loss =  0.36114466  Acc:  0.87488335 Val_loss =  0.43954337 Val_acc =  0.8479\n",
            "Iteration  3474 : Loss =  0.3611324  Acc:  0.8749 Val_loss =  0.43954474 Val_acc =  0.8479\n",
            "Iteration  3475 : Loss =  0.36112025  Acc:  0.8749 Val_loss =  0.4395461 Val_acc =  0.848\n",
            "Iteration  3476 : Loss =  0.361108  Acc:  0.8749167 Val_loss =  0.43954742 Val_acc =  0.848\n",
            "Iteration  3477 : Loss =  0.36109576  Acc:  0.8749167 Val_loss =  0.4395488 Val_acc =  0.848\n",
            "Iteration  3478 : Loss =  0.36108357  Acc:  0.8749167 Val_loss =  0.43955016 Val_acc =  0.8481\n",
            "Iteration  3479 : Loss =  0.36107135  Acc:  0.8749167 Val_loss =  0.4395515 Val_acc =  0.8481\n",
            "Iteration  3480 : Loss =  0.36105913  Acc:  0.87493336 Val_loss =  0.43955293 Val_acc =  0.8481\n",
            "Iteration  3481 : Loss =  0.36104694  Acc:  0.8749167 Val_loss =  0.4395543 Val_acc =  0.8481\n",
            "Iteration  3482 : Loss =  0.36103475  Acc:  0.8749 Val_loss =  0.43955567 Val_acc =  0.8481\n",
            "Iteration  3483 : Loss =  0.36102253  Acc:  0.87488335 Val_loss =  0.43955705 Val_acc =  0.8481\n",
            "Iteration  3484 : Loss =  0.36101034  Acc:  0.87488335 Val_loss =  0.4395584 Val_acc =  0.8481\n",
            "Iteration  3485 : Loss =  0.36099818  Acc:  0.87488335 Val_loss =  0.43955982 Val_acc =  0.8481\n",
            "Iteration  3486 : Loss =  0.360986  Acc:  0.87488335 Val_loss =  0.43956122 Val_acc =  0.8481\n",
            "Iteration  3487 : Loss =  0.36097383  Acc:  0.87488335 Val_loss =  0.43956265 Val_acc =  0.8481\n",
            "Iteration  3488 : Loss =  0.36096165  Acc:  0.87488335 Val_loss =  0.43956405 Val_acc =  0.8481\n",
            "Iteration  3489 : Loss =  0.3609495  Acc:  0.87486666 Val_loss =  0.43956542 Val_acc =  0.8481\n",
            "Iteration  3490 : Loss =  0.3609373  Acc:  0.87488335 Val_loss =  0.43956688 Val_acc =  0.8481\n",
            "Iteration  3491 : Loss =  0.3609252  Acc:  0.87488335 Val_loss =  0.43956825 Val_acc =  0.8481\n",
            "Iteration  3492 : Loss =  0.360913  Acc:  0.87486666 Val_loss =  0.4395697 Val_acc =  0.8481\n",
            "Iteration  3493 : Loss =  0.36090088  Acc:  0.87486666 Val_loss =  0.43957114 Val_acc =  0.8481\n",
            "Iteration  3494 : Loss =  0.36088875  Acc:  0.8749 Val_loss =  0.43957257 Val_acc =  0.8481\n",
            "Iteration  3495 : Loss =  0.3608766  Acc:  0.8749 Val_loss =  0.43957403 Val_acc =  0.8481\n",
            "Iteration  3496 : Loss =  0.36086446  Acc:  0.8749167 Val_loss =  0.43957543 Val_acc =  0.8481\n",
            "Iteration  3497 : Loss =  0.36085233  Acc:  0.8749167 Val_loss =  0.4395769 Val_acc =  0.8481\n",
            "Iteration  3498 : Loss =  0.3608402  Acc:  0.87493336 Val_loss =  0.43957832 Val_acc =  0.8481\n",
            "Iteration  3499 : Loss =  0.36082807  Acc:  0.87495 Val_loss =  0.43957978 Val_acc =  0.8481\n",
            "Iteration  3500 : Loss =  0.36081594  Acc:  0.87495 Val_loss =  0.43958125 Val_acc =  0.8481\n",
            "Iteration  3501 : Loss =  0.36080384  Acc:  0.87495 Val_loss =  0.4395827 Val_acc =  0.8481\n",
            "Iteration  3502 : Loss =  0.36079174  Acc:  0.8749667 Val_loss =  0.43958417 Val_acc =  0.8481\n",
            "Iteration  3503 : Loss =  0.3607796  Acc:  0.8749667 Val_loss =  0.43958566 Val_acc =  0.8481\n",
            "Iteration  3504 : Loss =  0.3607675  Acc:  0.8749833 Val_loss =  0.43958712 Val_acc =  0.8482\n",
            "Iteration  3505 : Loss =  0.36075544  Acc:  0.875 Val_loss =  0.43958864 Val_acc =  0.8482\n",
            "Iteration  3506 : Loss =  0.3607433  Acc:  0.8749833 Val_loss =  0.43959013 Val_acc =  0.8482\n",
            "Iteration  3507 : Loss =  0.36073124  Acc:  0.875 Val_loss =  0.43959162 Val_acc =  0.8481\n",
            "Iteration  3508 : Loss =  0.36071917  Acc:  0.875 Val_loss =  0.43959308 Val_acc =  0.8481\n",
            "Iteration  3509 : Loss =  0.3607071  Acc:  0.875 Val_loss =  0.43959463 Val_acc =  0.8481\n",
            "Iteration  3510 : Loss =  0.36069503  Acc:  0.875 Val_loss =  0.4395961 Val_acc =  0.8481\n",
            "Iteration  3511 : Loss =  0.36068293  Acc:  0.8750167 Val_loss =  0.4395976 Val_acc =  0.8481\n",
            "Iteration  3512 : Loss =  0.36067086  Acc:  0.8750167 Val_loss =  0.43959913 Val_acc =  0.8481\n",
            "Iteration  3513 : Loss =  0.36065882  Acc:  0.8750167 Val_loss =  0.4396006 Val_acc =  0.8481\n",
            "Iteration  3514 : Loss =  0.36064675  Acc:  0.8750167 Val_loss =  0.43960214 Val_acc =  0.8481\n",
            "Iteration  3515 : Loss =  0.3606347  Acc:  0.8750167 Val_loss =  0.43960366 Val_acc =  0.8481\n",
            "Iteration  3516 : Loss =  0.36062264  Acc:  0.8750333 Val_loss =  0.43960518 Val_acc =  0.8481\n",
            "Iteration  3517 : Loss =  0.3606106  Acc:  0.8750167 Val_loss =  0.43960673 Val_acc =  0.8481\n",
            "Iteration  3518 : Loss =  0.36059856  Acc:  0.8750167 Val_loss =  0.4396083 Val_acc =  0.8481\n",
            "Iteration  3519 : Loss =  0.36058652  Acc:  0.875 Val_loss =  0.43960983 Val_acc =  0.848\n",
            "Iteration  3520 : Loss =  0.3605745  Acc:  0.875 Val_loss =  0.43961138 Val_acc =  0.848\n",
            "Iteration  3521 : Loss =  0.3605625  Acc:  0.875 Val_loss =  0.43961293 Val_acc =  0.848\n",
            "Iteration  3522 : Loss =  0.36055046  Acc:  0.8750167 Val_loss =  0.43961444 Val_acc =  0.848\n",
            "Iteration  3523 : Loss =  0.36053845  Acc:  0.87505 Val_loss =  0.43961602 Val_acc =  0.848\n",
            "Iteration  3524 : Loss =  0.36052644  Acc:  0.87506664 Val_loss =  0.43961757 Val_acc =  0.848\n",
            "Iteration  3525 : Loss =  0.36051443  Acc:  0.8750833 Val_loss =  0.43961915 Val_acc =  0.848\n",
            "Iteration  3526 : Loss =  0.36050242  Acc:  0.8751 Val_loss =  0.4396207 Val_acc =  0.8479\n",
            "Iteration  3527 : Loss =  0.36049044  Acc:  0.8751 Val_loss =  0.43962225 Val_acc =  0.8479\n",
            "Iteration  3528 : Loss =  0.36047843  Acc:  0.8751 Val_loss =  0.43962386 Val_acc =  0.8479\n",
            "Iteration  3529 : Loss =  0.36046642  Acc:  0.8751 Val_loss =  0.43962544 Val_acc =  0.8479\n",
            "Iteration  3530 : Loss =  0.36045444  Acc:  0.8751 Val_loss =  0.43962705 Val_acc =  0.8479\n",
            "Iteration  3531 : Loss =  0.36044246  Acc:  0.87511665 Val_loss =  0.4396286 Val_acc =  0.848\n",
            "Iteration  3532 : Loss =  0.36043048  Acc:  0.87513334 Val_loss =  0.4396302 Val_acc =  0.848\n",
            "Iteration  3533 : Loss =  0.3604185  Acc:  0.87513334 Val_loss =  0.43963185 Val_acc =  0.848\n",
            "Iteration  3534 : Loss =  0.36040655  Acc:  0.87515 Val_loss =  0.43963346 Val_acc =  0.848\n",
            "Iteration  3535 : Loss =  0.36039457  Acc:  0.87516665 Val_loss =  0.43963507 Val_acc =  0.848\n",
            "Iteration  3536 : Loss =  0.36038262  Acc:  0.87516665 Val_loss =  0.43963662 Val_acc =  0.848\n",
            "Iteration  3537 : Loss =  0.36037064  Acc:  0.87516665 Val_loss =  0.43963823 Val_acc =  0.848\n",
            "Iteration  3538 : Loss =  0.36035866  Acc:  0.87516665 Val_loss =  0.4396399 Val_acc =  0.848\n",
            "Iteration  3539 : Loss =  0.3603467  Acc:  0.87516665 Val_loss =  0.4396415 Val_acc =  0.848\n",
            "Iteration  3540 : Loss =  0.36033484  Acc:  0.87515 Val_loss =  0.4396431 Val_acc =  0.848\n",
            "Iteration  3541 : Loss =  0.36032286  Acc:  0.87516665 Val_loss =  0.43964478 Val_acc =  0.848\n",
            "Iteration  3542 : Loss =  0.3603109  Acc:  0.87515 Val_loss =  0.4396464 Val_acc =  0.8481\n",
            "Iteration  3543 : Loss =  0.360299  Acc:  0.87515 Val_loss =  0.43964803 Val_acc =  0.848\n",
            "Iteration  3544 : Loss =  0.36028704  Acc:  0.87513334 Val_loss =  0.4396497 Val_acc =  0.8481\n",
            "Iteration  3545 : Loss =  0.36027512  Acc:  0.87515 Val_loss =  0.4396513 Val_acc =  0.848\n",
            "Iteration  3546 : Loss =  0.36026323  Acc:  0.87515 Val_loss =  0.43965298 Val_acc =  0.8481\n",
            "Iteration  3547 : Loss =  0.3602513  Acc:  0.87515 Val_loss =  0.43965465 Val_acc =  0.848\n",
            "Iteration  3548 : Loss =  0.3602394  Acc:  0.87515 Val_loss =  0.43965635 Val_acc =  0.8481\n",
            "Iteration  3549 : Loss =  0.36022747  Acc:  0.87515 Val_loss =  0.43965802 Val_acc =  0.848\n",
            "Iteration  3550 : Loss =  0.3602156  Acc:  0.87513334 Val_loss =  0.43965963 Val_acc =  0.8481\n",
            "Iteration  3551 : Loss =  0.3602037  Acc:  0.87513334 Val_loss =  0.43966132 Val_acc =  0.848\n",
            "Iteration  3552 : Loss =  0.3601918  Acc:  0.87515 Val_loss =  0.439663 Val_acc =  0.848\n",
            "Iteration  3553 : Loss =  0.36017987  Acc:  0.87515 Val_loss =  0.4396647 Val_acc =  0.848\n",
            "Iteration  3554 : Loss =  0.360168  Acc:  0.87515 Val_loss =  0.43966636 Val_acc =  0.8479\n",
            "Iteration  3555 : Loss =  0.36015612  Acc:  0.87515 Val_loss =  0.43966806 Val_acc =  0.8479\n",
            "Iteration  3556 : Loss =  0.36014426  Acc:  0.87516665 Val_loss =  0.43966973 Val_acc =  0.8479\n",
            "Iteration  3557 : Loss =  0.3601324  Acc:  0.87513334 Val_loss =  0.4396715 Val_acc =  0.8479\n",
            "Iteration  3558 : Loss =  0.3601205  Acc:  0.87515 Val_loss =  0.43967316 Val_acc =  0.8479\n",
            "Iteration  3559 : Loss =  0.36010867  Acc:  0.87513334 Val_loss =  0.4396749 Val_acc =  0.8479\n",
            "Iteration  3560 : Loss =  0.3600968  Acc:  0.87516665 Val_loss =  0.43967655 Val_acc =  0.8479\n",
            "Iteration  3561 : Loss =  0.36008498  Acc:  0.8751 Val_loss =  0.43967843 Val_acc =  0.8479\n",
            "Iteration  3562 : Loss =  0.36007318  Acc:  0.8752 Val_loss =  0.43968007 Val_acc =  0.848\n",
            "Iteration  3563 : Loss =  0.36006135  Acc:  0.8751 Val_loss =  0.4396819 Val_acc =  0.8477\n",
            "Iteration  3564 : Loss =  0.3600496  Acc:  0.87523335 Val_loss =  0.4396836 Val_acc =  0.8479\n",
            "Iteration  3565 : Loss =  0.36003786  Acc:  0.87515 Val_loss =  0.43968558 Val_acc =  0.8475\n",
            "Iteration  3566 : Loss =  0.36002618  Acc:  0.8752667 Val_loss =  0.4396873 Val_acc =  0.8477\n",
            "Iteration  3567 : Loss =  0.3600146  Acc:  0.87511665 Val_loss =  0.43968955 Val_acc =  0.8475\n",
            "Iteration  3568 : Loss =  0.36000323  Acc:  0.8752667 Val_loss =  0.43969145 Val_acc =  0.8475\n",
            "Iteration  3569 : Loss =  0.3599921  Acc:  0.87515 Val_loss =  0.4396943 Val_acc =  0.8472\n",
            "Iteration  3570 : Loss =  0.3599814  Acc:  0.87528336 Val_loss =  0.43969667 Val_acc =  0.8473\n",
            "Iteration  3571 : Loss =  0.35997134  Acc:  0.87511665 Val_loss =  0.43970093 Val_acc =  0.8473\n",
            "Iteration  3572 : Loss =  0.35996243  Acc:  0.8753833 Val_loss =  0.43970484 Val_acc =  0.8473\n",
            "Iteration  3573 : Loss =  0.359955  Acc:  0.87516665 Val_loss =  0.4397122 Val_acc =  0.8474\n",
            "Iteration  3574 : Loss =  0.35994986  Acc:  0.8753667 Val_loss =  0.43971947 Val_acc =  0.847\n",
            "Iteration  3575 : Loss =  0.35994714  Acc:  0.87518334 Val_loss =  0.4397323 Val_acc =  0.847\n",
            "Iteration  3576 : Loss =  0.35994682  Acc:  0.8755 Val_loss =  0.43974385 Val_acc =  0.8472\n",
            "Iteration  3577 : Loss =  0.35994574  Acc:  0.87516665 Val_loss =  0.43975917 Val_acc =  0.8468\n",
            "Iteration  3578 : Loss =  0.35994014  Acc:  0.87558335 Val_loss =  0.43976444 Val_acc =  0.8472\n",
            "Iteration  3579 : Loss =  0.35992292  Acc:  0.87516665 Val_loss =  0.43976367 Val_acc =  0.8467\n",
            "Iteration  3580 : Loss =  0.35989517  Acc:  0.8755 Val_loss =  0.43974614 Val_acc =  0.8472\n",
            "Iteration  3581 : Loss =  0.359863  Acc:  0.8752 Val_loss =  0.43972892 Val_acc =  0.8472\n",
            "Iteration  3582 : Loss =  0.3598386  Acc:  0.87535 Val_loss =  0.43971646 Val_acc =  0.8471\n",
            "Iteration  3583 : Loss =  0.35982734  Acc:  0.8753333 Val_loss =  0.4397187 Val_acc =  0.847\n",
            "Iteration  3584 : Loss =  0.35982525  Acc:  0.87518334 Val_loss =  0.43973145 Val_acc =  0.847\n",
            "Iteration  3585 : Loss =  0.3598231  Acc:  0.87546664 Val_loss =  0.4397411 Val_acc =  0.847\n",
            "Iteration  3586 : Loss =  0.35981262  Acc:  0.87523335 Val_loss =  0.43974677 Val_acc =  0.8469\n",
            "Iteration  3587 : Loss =  0.3597935  Acc:  0.8753833 Val_loss =  0.43973848 Val_acc =  0.8469\n",
            "Iteration  3588 : Loss =  0.35977185  Acc:  0.87521666 Val_loss =  0.43973145 Val_acc =  0.847\n",
            "Iteration  3589 : Loss =  0.35975537  Acc:  0.87528336 Val_loss =  0.43972784 Val_acc =  0.8472\n",
            "Iteration  3590 : Loss =  0.35974637  Acc:  0.8753 Val_loss =  0.43973193 Val_acc =  0.847\n",
            "Iteration  3591 : Loss =  0.3597405  Acc:  0.8752 Val_loss =  0.43974093 Val_acc =  0.847\n",
            "Iteration  3592 : Loss =  0.3597319  Acc:  0.8754333 Val_loss =  0.43974423 Val_acc =  0.847\n",
            "Iteration  3593 : Loss =  0.35971773  Acc:  0.87523335 Val_loss =  0.4397454 Val_acc =  0.847\n",
            "Iteration  3594 : Loss =  0.35970077  Acc:  0.8753667 Val_loss =  0.43974015 Val_acc =  0.8467\n",
            "Iteration  3595 : Loss =  0.35968566  Acc:  0.87523335 Val_loss =  0.43973902 Val_acc =  0.8471\n",
            "Iteration  3596 : Loss =  0.35967454  Acc:  0.87528336 Val_loss =  0.43974164 Val_acc =  0.8472\n",
            "Iteration  3597 : Loss =  0.35966596  Acc:  0.8754 Val_loss =  0.43974566 Val_acc =  0.8467\n",
            "Iteration  3598 : Loss =  0.3596564  Acc:  0.8752667 Val_loss =  0.43975082 Val_acc =  0.8469\n",
            "Iteration  3599 : Loss =  0.35964397  Acc:  0.8754333 Val_loss =  0.4397505 Val_acc =  0.8467\n",
            "Iteration  3600 : Loss =  0.3596296  Acc:  0.87528336 Val_loss =  0.4397505 Val_acc =  0.8469\n",
            "Iteration  3601 : Loss =  0.35961586  Acc:  0.8753333 Val_loss =  0.43974936 Val_acc =  0.8472\n",
            "Iteration  3602 : Loss =  0.35960424  Acc:  0.8753333 Val_loss =  0.43975127 Val_acc =  0.8471\n",
            "Iteration  3603 : Loss =  0.35959414  Acc:  0.8753 Val_loss =  0.43975523 Val_acc =  0.8471\n",
            "Iteration  3604 : Loss =  0.3595838  Acc:  0.8753667 Val_loss =  0.43975732 Val_acc =  0.8467\n",
            "Iteration  3605 : Loss =  0.359572  Acc:  0.8753333 Val_loss =  0.43976 Val_acc =  0.8468\n",
            "Iteration  3606 : Loss =  0.35955903  Acc:  0.8753833 Val_loss =  0.43975952 Val_acc =  0.8468\n",
            "Iteration  3607 : Loss =  0.35954615  Acc:  0.87525 Val_loss =  0.43976054 Val_acc =  0.8471\n",
            "Iteration  3608 : Loss =  0.35953438  Acc:  0.87528336 Val_loss =  0.43976212 Val_acc =  0.847\n",
            "Iteration  3609 : Loss =  0.35952353  Acc:  0.8754167 Val_loss =  0.4397644 Val_acc =  0.8469\n",
            "Iteration  3610 : Loss =  0.3595127  Acc:  0.8753333 Val_loss =  0.43976763 Val_acc =  0.847\n",
            "Iteration  3611 : Loss =  0.35950118  Acc:  0.8754 Val_loss =  0.43976864 Val_acc =  0.8468\n",
            "Iteration  3612 : Loss =  0.35948896  Acc:  0.8752667 Val_loss =  0.4397706 Val_acc =  0.847\n",
            "Iteration  3613 : Loss =  0.3594767  Acc:  0.87535 Val_loss =  0.4397712 Val_acc =  0.8469\n",
            "Iteration  3614 : Loss =  0.35946485  Acc:  0.8753 Val_loss =  0.4397729 Val_acc =  0.8471\n",
            "Iteration  3615 : Loss =  0.35945356  Acc:  0.8752667 Val_loss =  0.4397753 Val_acc =  0.847\n",
            "Iteration  3616 : Loss =  0.35944244  Acc:  0.8754 Val_loss =  0.4397771 Val_acc =  0.8469\n",
            "Iteration  3617 : Loss =  0.35943106  Acc:  0.87523335 Val_loss =  0.4397797 Val_acc =  0.8469\n",
            "Iteration  3618 : Loss =  0.35941926  Acc:  0.8753833 Val_loss =  0.4397807 Val_acc =  0.8469\n",
            "Iteration  3619 : Loss =  0.3594073  Acc:  0.87525 Val_loss =  0.43978262 Val_acc =  0.8469\n",
            "Iteration  3620 : Loss =  0.3593955  Acc:  0.87528336 Val_loss =  0.439784 Val_acc =  0.8469\n",
            "Iteration  3621 : Loss =  0.35938406  Acc:  0.8753167 Val_loss =  0.43978584 Val_acc =  0.8468\n",
            "Iteration  3622 : Loss =  0.35937276  Acc:  0.87528336 Val_loss =  0.43978828 Val_acc =  0.8468\n",
            "Iteration  3623 : Loss =  0.35936138  Acc:  0.8753833 Val_loss =  0.4397899 Val_acc =  0.8468\n",
            "Iteration  3624 : Loss =  0.35934982  Acc:  0.87528336 Val_loss =  0.43979213 Val_acc =  0.8468\n",
            "Iteration  3625 : Loss =  0.35933805  Acc:  0.87535 Val_loss =  0.4397935 Val_acc =  0.8468\n",
            "Iteration  3626 : Loss =  0.35932636  Acc:  0.87528336 Val_loss =  0.4397954 Val_acc =  0.8467\n",
            "Iteration  3627 : Loss =  0.35931483  Acc:  0.87535 Val_loss =  0.43979722 Val_acc =  0.8467\n",
            "Iteration  3628 : Loss =  0.35930339  Acc:  0.8753333 Val_loss =  0.43979907 Val_acc =  0.8467\n",
            "Iteration  3629 : Loss =  0.35929203  Acc:  0.8752667 Val_loss =  0.43980137 Val_acc =  0.8467\n",
            "Iteration  3630 : Loss =  0.35928053  Acc:  0.87535 Val_loss =  0.4398029 Val_acc =  0.8467\n",
            "Iteration  3631 : Loss =  0.35926896  Acc:  0.8752667 Val_loss =  0.43980518 Val_acc =  0.8467\n",
            "Iteration  3632 : Loss =  0.35925737  Acc:  0.8753333 Val_loss =  0.4398067 Val_acc =  0.8466\n",
            "Iteration  3633 : Loss =  0.3592458  Acc:  0.8753167 Val_loss =  0.43980864 Val_acc =  0.8467\n",
            "Iteration  3634 : Loss =  0.3592343  Acc:  0.87528336 Val_loss =  0.4398106 Val_acc =  0.8467\n",
            "Iteration  3635 : Loss =  0.35922292  Acc:  0.8753167 Val_loss =  0.43981245 Val_acc =  0.8466\n",
            "Iteration  3636 : Loss =  0.3592115  Acc:  0.87523335 Val_loss =  0.43981466 Val_acc =  0.8467\n",
            "Iteration  3637 : Loss =  0.3592  Acc:  0.87535 Val_loss =  0.4398163 Val_acc =  0.8466\n",
            "Iteration  3638 : Loss =  0.35918847  Acc:  0.8752667 Val_loss =  0.4398185 Val_acc =  0.8467\n",
            "Iteration  3639 : Loss =  0.35917696  Acc:  0.8753 Val_loss =  0.4398202 Val_acc =  0.8466\n",
            "Iteration  3640 : Loss =  0.35916546  Acc:  0.87523335 Val_loss =  0.43982217 Val_acc =  0.8467\n",
            "Iteration  3641 : Loss =  0.35915402  Acc:  0.87525 Val_loss =  0.43982422 Val_acc =  0.8467\n",
            "Iteration  3642 : Loss =  0.35914257  Acc:  0.8753 Val_loss =  0.43982607 Val_acc =  0.8466\n",
            "Iteration  3643 : Loss =  0.3591312  Acc:  0.87525 Val_loss =  0.43982822 Val_acc =  0.8467\n",
            "Iteration  3644 : Loss =  0.35911968  Acc:  0.8753167 Val_loss =  0.43982998 Val_acc =  0.8466\n",
            "Iteration  3645 : Loss =  0.35910827  Acc:  0.8752667 Val_loss =  0.43983212 Val_acc =  0.8467\n",
            "Iteration  3646 : Loss =  0.35909674  Acc:  0.8753 Val_loss =  0.43983394 Val_acc =  0.8466\n",
            "Iteration  3647 : Loss =  0.35908532  Acc:  0.87528336 Val_loss =  0.43983594 Val_acc =  0.8467\n",
            "Iteration  3648 : Loss =  0.3590739  Acc:  0.8752667 Val_loss =  0.43983793 Val_acc =  0.8467\n",
            "Iteration  3649 : Loss =  0.35906246  Acc:  0.8753333 Val_loss =  0.43983984 Val_acc =  0.8466\n",
            "Iteration  3650 : Loss =  0.35905105  Acc:  0.8753 Val_loss =  0.43984196 Val_acc =  0.8467\n",
            "Iteration  3651 : Loss =  0.35903963  Acc:  0.87535 Val_loss =  0.43984383 Val_acc =  0.8466\n",
            "Iteration  3652 : Loss =  0.3590282  Acc:  0.8753167 Val_loss =  0.43984595 Val_acc =  0.8467\n",
            "Iteration  3653 : Loss =  0.3590168  Acc:  0.8753333 Val_loss =  0.43984786 Val_acc =  0.8466\n",
            "Iteration  3654 : Loss =  0.35900536  Acc:  0.8753167 Val_loss =  0.4398499 Val_acc =  0.8467\n",
            "Iteration  3655 : Loss =  0.35899395  Acc:  0.8753 Val_loss =  0.4398519 Val_acc =  0.8468\n",
            "Iteration  3656 : Loss =  0.35898256  Acc:  0.8753167 Val_loss =  0.4398539 Val_acc =  0.8467\n",
            "Iteration  3657 : Loss =  0.35897115  Acc:  0.87528336 Val_loss =  0.43985596 Val_acc =  0.8467\n",
            "Iteration  3658 : Loss =  0.35895976  Acc:  0.8753333 Val_loss =  0.4398579 Val_acc =  0.8466\n",
            "Iteration  3659 : Loss =  0.35894838  Acc:  0.87528336 Val_loss =  0.43986002 Val_acc =  0.8467\n",
            "Iteration  3660 : Loss =  0.35893697  Acc:  0.8753333 Val_loss =  0.43986192 Val_acc =  0.8466\n",
            "Iteration  3661 : Loss =  0.35892558  Acc:  0.87528336 Val_loss =  0.43986407 Val_acc =  0.8467\n",
            "Iteration  3662 : Loss =  0.35891423  Acc:  0.87528336 Val_loss =  0.43986607 Val_acc =  0.8467\n",
            "Iteration  3663 : Loss =  0.35890284  Acc:  0.8753167 Val_loss =  0.43986806 Val_acc =  0.8467\n",
            "Iteration  3664 : Loss =  0.35889146  Acc:  0.8753167 Val_loss =  0.43987012 Val_acc =  0.8467\n",
            "Iteration  3665 : Loss =  0.35888013  Acc:  0.87535 Val_loss =  0.43987212 Val_acc =  0.8467\n",
            "Iteration  3666 : Loss =  0.35886875  Acc:  0.8753333 Val_loss =  0.43987426 Val_acc =  0.8467\n",
            "Iteration  3667 : Loss =  0.3588574  Acc:  0.8753833 Val_loss =  0.43987626 Val_acc =  0.8467\n",
            "Iteration  3668 : Loss =  0.35884604  Acc:  0.8754 Val_loss =  0.43987837 Val_acc =  0.8468\n",
            "Iteration  3669 : Loss =  0.35883462  Acc:  0.8754167 Val_loss =  0.43988037 Val_acc =  0.8468\n",
            "Iteration  3670 : Loss =  0.3588233  Acc:  0.8754 Val_loss =  0.43988246 Val_acc =  0.8467\n",
            "Iteration  3671 : Loss =  0.35881197  Acc:  0.8754167 Val_loss =  0.43988457 Val_acc =  0.8468\n",
            "Iteration  3672 : Loss =  0.35880065  Acc:  0.8754333 Val_loss =  0.43988657 Val_acc =  0.8468\n",
            "Iteration  3673 : Loss =  0.3587893  Acc:  0.8754333 Val_loss =  0.4398887 Val_acc =  0.8467\n",
            "Iteration  3674 : Loss =  0.35877797  Acc:  0.8754333 Val_loss =  0.4398907 Val_acc =  0.8468\n",
            "Iteration  3675 : Loss =  0.35876665  Acc:  0.8754333 Val_loss =  0.43989286 Val_acc =  0.8467\n",
            "Iteration  3676 : Loss =  0.35875532  Acc:  0.8754 Val_loss =  0.4398949 Val_acc =  0.8468\n",
            "Iteration  3677 : Loss =  0.35874403  Acc:  0.8754167 Val_loss =  0.43989706 Val_acc =  0.8467\n",
            "Iteration  3678 : Loss =  0.35873267  Acc:  0.8754333 Val_loss =  0.43989912 Val_acc =  0.8468\n",
            "Iteration  3679 : Loss =  0.35872135  Acc:  0.8754333 Val_loss =  0.43990123 Val_acc =  0.8468\n",
            "Iteration  3680 : Loss =  0.35871002  Acc:  0.8754333 Val_loss =  0.43990338 Val_acc =  0.8467\n",
            "Iteration  3681 : Loss =  0.35869873  Acc:  0.87545 Val_loss =  0.43990546 Val_acc =  0.8468\n",
            "Iteration  3682 : Loss =  0.35868743  Acc:  0.87545 Val_loss =  0.43990758 Val_acc =  0.8467\n",
            "Iteration  3683 : Loss =  0.3586761  Acc:  0.87546664 Val_loss =  0.43990967 Val_acc =  0.8468\n",
            "Iteration  3684 : Loss =  0.35866484  Acc:  0.87551665 Val_loss =  0.4399118 Val_acc =  0.8467\n",
            "Iteration  3685 : Loss =  0.35865355  Acc:  0.87546664 Val_loss =  0.43991393 Val_acc =  0.8468\n",
            "Iteration  3686 : Loss =  0.35864225  Acc:  0.87551665 Val_loss =  0.43991607 Val_acc =  0.8467\n",
            "Iteration  3687 : Loss =  0.35863099  Acc:  0.87548333 Val_loss =  0.43991816 Val_acc =  0.8468\n",
            "Iteration  3688 : Loss =  0.35861972  Acc:  0.87553334 Val_loss =  0.4399203 Val_acc =  0.8467\n",
            "Iteration  3689 : Loss =  0.3586084  Acc:  0.87553334 Val_loss =  0.43992245 Val_acc =  0.8467\n",
            "Iteration  3690 : Loss =  0.35859713  Acc:  0.87555 Val_loss =  0.4399246 Val_acc =  0.8468\n",
            "Iteration  3691 : Loss =  0.35858586  Acc:  0.87555 Val_loss =  0.43992674 Val_acc =  0.8467\n",
            "Iteration  3692 : Loss =  0.3585746  Acc:  0.87556666 Val_loss =  0.43992892 Val_acc =  0.8468\n",
            "Iteration  3693 : Loss =  0.3585634  Acc:  0.87555 Val_loss =  0.43993106 Val_acc =  0.8467\n",
            "Iteration  3694 : Loss =  0.35855207  Acc:  0.87555 Val_loss =  0.4399332 Val_acc =  0.8468\n",
            "Iteration  3695 : Loss =  0.35854086  Acc:  0.87555 Val_loss =  0.43993545 Val_acc =  0.8467\n",
            "Iteration  3696 : Loss =  0.35852963  Acc:  0.87555 Val_loss =  0.43993756 Val_acc =  0.8468\n",
            "Iteration  3697 : Loss =  0.35851836  Acc:  0.87555 Val_loss =  0.43993974 Val_acc =  0.8467\n",
            "Iteration  3698 : Loss =  0.3585071  Acc:  0.87555 Val_loss =  0.43994188 Val_acc =  0.8467\n",
            "Iteration  3699 : Loss =  0.35849586  Acc:  0.87555 Val_loss =  0.4399441 Val_acc =  0.8467\n",
            "Iteration  3700 : Loss =  0.35848463  Acc:  0.87555 Val_loss =  0.4399463 Val_acc =  0.8467\n",
            "Iteration  3701 : Loss =  0.35847336  Acc:  0.87556666 Val_loss =  0.43994844 Val_acc =  0.8467\n",
            "Iteration  3702 : Loss =  0.35846218  Acc:  0.87558335 Val_loss =  0.43995067 Val_acc =  0.8467\n",
            "Iteration  3703 : Loss =  0.35845098  Acc:  0.8756 Val_loss =  0.43995282 Val_acc =  0.8468\n",
            "Iteration  3704 : Loss =  0.35843974  Acc:  0.8756 Val_loss =  0.4399551 Val_acc =  0.8467\n",
            "Iteration  3705 : Loss =  0.3584285  Acc:  0.87561667 Val_loss =  0.43995723 Val_acc =  0.8467\n",
            "Iteration  3706 : Loss =  0.35841733  Acc:  0.87563336 Val_loss =  0.43995947 Val_acc =  0.8467\n",
            "Iteration  3707 : Loss =  0.35840613  Acc:  0.87563336 Val_loss =  0.4399616 Val_acc =  0.8467\n",
            "Iteration  3708 : Loss =  0.3583949  Acc:  0.87563336 Val_loss =  0.43996388 Val_acc =  0.8467\n",
            "Iteration  3709 : Loss =  0.35838366  Acc:  0.87563336 Val_loss =  0.43996605 Val_acc =  0.8467\n",
            "Iteration  3710 : Loss =  0.35837248  Acc:  0.87563336 Val_loss =  0.43996835 Val_acc =  0.8467\n",
            "Iteration  3711 : Loss =  0.3583613  Acc:  0.87563336 Val_loss =  0.4399705 Val_acc =  0.8467\n",
            "Iteration  3712 : Loss =  0.35835013  Acc:  0.87563336 Val_loss =  0.43997276 Val_acc =  0.8467\n",
            "Iteration  3713 : Loss =  0.35833892  Acc:  0.87565 Val_loss =  0.439975 Val_acc =  0.8467\n",
            "Iteration  3714 : Loss =  0.35832775  Acc:  0.8756667 Val_loss =  0.4399772 Val_acc =  0.8467\n",
            "Iteration  3715 : Loss =  0.35831654  Acc:  0.8756833 Val_loss =  0.4399795 Val_acc =  0.8467\n",
            "Iteration  3716 : Loss =  0.3583054  Acc:  0.8756833 Val_loss =  0.4399817 Val_acc =  0.8467\n",
            "Iteration  3717 : Loss =  0.35829422  Acc:  0.8756833 Val_loss =  0.439984 Val_acc =  0.8467\n",
            "Iteration  3718 : Loss =  0.35828304  Acc:  0.8756833 Val_loss =  0.43998623 Val_acc =  0.8468\n",
            "Iteration  3719 : Loss =  0.3582719  Acc:  0.8756833 Val_loss =  0.43998846 Val_acc =  0.8468\n",
            "Iteration  3720 : Loss =  0.35826075  Acc:  0.8756833 Val_loss =  0.43999073 Val_acc =  0.8468\n",
            "Iteration  3721 : Loss =  0.35824957  Acc:  0.8757167 Val_loss =  0.43999296 Val_acc =  0.8468\n",
            "Iteration  3722 : Loss =  0.3582384  Acc:  0.8757167 Val_loss =  0.43999523 Val_acc =  0.8468\n",
            "Iteration  3723 : Loss =  0.35822728  Acc:  0.8757167 Val_loss =  0.43999752 Val_acc =  0.8468\n",
            "Iteration  3724 : Loss =  0.35821614  Acc:  0.8757167 Val_loss =  0.43999982 Val_acc =  0.8468\n",
            "Iteration  3725 : Loss =  0.35820502  Acc:  0.87575 Val_loss =  0.44000205 Val_acc =  0.8468\n",
            "Iteration  3726 : Loss =  0.35819384  Acc:  0.87575 Val_loss =  0.44000435 Val_acc =  0.8467\n",
            "Iteration  3727 : Loss =  0.35818273  Acc:  0.87575 Val_loss =  0.44000664 Val_acc =  0.8467\n",
            "Iteration  3728 : Loss =  0.3581716  Acc:  0.8757667 Val_loss =  0.44000888 Val_acc =  0.8467\n",
            "Iteration  3729 : Loss =  0.35816044  Acc:  0.87575 Val_loss =  0.44001123 Val_acc =  0.8467\n",
            "Iteration  3730 : Loss =  0.35814935  Acc:  0.87575 Val_loss =  0.44001353 Val_acc =  0.8467\n",
            "Iteration  3731 : Loss =  0.3581382  Acc:  0.8757833 Val_loss =  0.44001582 Val_acc =  0.8467\n",
            "Iteration  3732 : Loss =  0.3581271  Acc:  0.8757833 Val_loss =  0.44001806 Val_acc =  0.8467\n",
            "Iteration  3733 : Loss =  0.358116  Acc:  0.8757833 Val_loss =  0.4400204 Val_acc =  0.8467\n",
            "Iteration  3734 : Loss =  0.35810488  Acc:  0.8758 Val_loss =  0.44002277 Val_acc =  0.8467\n",
            "Iteration  3735 : Loss =  0.35809377  Acc:  0.87583333 Val_loss =  0.440025 Val_acc =  0.8467\n",
            "Iteration  3736 : Loss =  0.35808268  Acc:  0.87583333 Val_loss =  0.44002736 Val_acc =  0.8467\n",
            "Iteration  3737 : Loss =  0.35807163  Acc:  0.87585 Val_loss =  0.44002968 Val_acc =  0.8467\n",
            "Iteration  3738 : Loss =  0.35806048  Acc:  0.87585 Val_loss =  0.44003204 Val_acc =  0.8467\n",
            "Iteration  3739 : Loss =  0.35804942  Acc:  0.87585 Val_loss =  0.4400344 Val_acc =  0.8467\n",
            "Iteration  3740 : Loss =  0.35803834  Acc:  0.87586665 Val_loss =  0.44003668 Val_acc =  0.8467\n",
            "Iteration  3741 : Loss =  0.35802725  Acc:  0.87586665 Val_loss =  0.440039 Val_acc =  0.8467\n",
            "Iteration  3742 : Loss =  0.35801613  Acc:  0.87586665 Val_loss =  0.44004136 Val_acc =  0.8467\n",
            "Iteration  3743 : Loss =  0.35800508  Acc:  0.87586665 Val_loss =  0.4400437 Val_acc =  0.8467\n",
            "Iteration  3744 : Loss =  0.35799402  Acc:  0.87588334 Val_loss =  0.44004598 Val_acc =  0.8467\n",
            "Iteration  3745 : Loss =  0.35798296  Acc:  0.87588334 Val_loss =  0.44004843 Val_acc =  0.8467\n",
            "Iteration  3746 : Loss =  0.35797188  Acc:  0.87588334 Val_loss =  0.44005078 Val_acc =  0.8467\n",
            "Iteration  3747 : Loss =  0.35796082  Acc:  0.87588334 Val_loss =  0.44005314 Val_acc =  0.8467\n",
            "Iteration  3748 : Loss =  0.35794973  Acc:  0.87588334 Val_loss =  0.44005552 Val_acc =  0.8467\n",
            "Iteration  3749 : Loss =  0.35793874  Acc:  0.87588334 Val_loss =  0.44005787 Val_acc =  0.8467\n",
            "Iteration  3750 : Loss =  0.35792768  Acc:  0.87588334 Val_loss =  0.4400602 Val_acc =  0.8467\n",
            "Iteration  3751 : Loss =  0.35791665  Acc:  0.87586665 Val_loss =  0.4400626 Val_acc =  0.8468\n",
            "Iteration  3752 : Loss =  0.3579056  Acc:  0.87586665 Val_loss =  0.440065 Val_acc =  0.8468\n",
            "Iteration  3753 : Loss =  0.35789457  Acc:  0.87588334 Val_loss =  0.44006732 Val_acc =  0.8468\n",
            "Iteration  3754 : Loss =  0.35788354  Acc:  0.8759 Val_loss =  0.44006974 Val_acc =  0.8468\n",
            "Iteration  3755 : Loss =  0.35787246  Acc:  0.8759 Val_loss =  0.44007212 Val_acc =  0.8468\n",
            "Iteration  3756 : Loss =  0.35786146  Acc:  0.8759 Val_loss =  0.4400745 Val_acc =  0.8467\n",
            "Iteration  3757 : Loss =  0.35785043  Acc:  0.8759 Val_loss =  0.44007692 Val_acc =  0.8467\n",
            "Iteration  3758 : Loss =  0.35783947  Acc:  0.8759 Val_loss =  0.4400793 Val_acc =  0.8467\n",
            "Iteration  3759 : Loss =  0.35782838  Acc:  0.8759 Val_loss =  0.44008175 Val_acc =  0.8467\n",
            "Iteration  3760 : Loss =  0.35781738  Acc:  0.8759 Val_loss =  0.44008413 Val_acc =  0.8467\n",
            "Iteration  3761 : Loss =  0.35780638  Acc:  0.87593335 Val_loss =  0.4400865 Val_acc =  0.8467\n",
            "Iteration  3762 : Loss =  0.3577954  Acc:  0.87595 Val_loss =  0.44008896 Val_acc =  0.8467\n",
            "Iteration  3763 : Loss =  0.35778436  Acc:  0.87595 Val_loss =  0.44009137 Val_acc =  0.8467\n",
            "Iteration  3764 : Loss =  0.35777336  Acc:  0.87595 Val_loss =  0.44009385 Val_acc =  0.8467\n",
            "Iteration  3765 : Loss =  0.3577624  Acc:  0.87595 Val_loss =  0.44009623 Val_acc =  0.8467\n",
            "Iteration  3766 : Loss =  0.3577514  Acc:  0.87596667 Val_loss =  0.44009867 Val_acc =  0.8467\n",
            "Iteration  3767 : Loss =  0.35774043  Acc:  0.87598336 Val_loss =  0.4401011 Val_acc =  0.8467\n",
            "Iteration  3768 : Loss =  0.35772943  Acc:  0.87598336 Val_loss =  0.44010356 Val_acc =  0.8467\n",
            "Iteration  3769 : Loss =  0.35771847  Acc:  0.876 Val_loss =  0.44010594 Val_acc =  0.8466\n",
            "Iteration  3770 : Loss =  0.3577075  Acc:  0.876 Val_loss =  0.44010845 Val_acc =  0.8467\n",
            "Iteration  3771 : Loss =  0.3576965  Acc:  0.876 Val_loss =  0.44011083 Val_acc =  0.8466\n",
            "Iteration  3772 : Loss =  0.35768554  Acc:  0.876 Val_loss =  0.44011334 Val_acc =  0.8467\n",
            "Iteration  3773 : Loss =  0.35767457  Acc:  0.8760167 Val_loss =  0.44011578 Val_acc =  0.8466\n",
            "Iteration  3774 : Loss =  0.3576636  Acc:  0.8760167 Val_loss =  0.44011825 Val_acc =  0.8467\n",
            "Iteration  3775 : Loss =  0.35765266  Acc:  0.8760333 Val_loss =  0.44012067 Val_acc =  0.8466\n",
            "Iteration  3776 : Loss =  0.35764173  Acc:  0.8760167 Val_loss =  0.44012323 Val_acc =  0.8467\n",
            "Iteration  3777 : Loss =  0.35763076  Acc:  0.8760333 Val_loss =  0.44012558 Val_acc =  0.8467\n",
            "Iteration  3778 : Loss =  0.3576198  Acc:  0.8760167 Val_loss =  0.44012824 Val_acc =  0.8468\n",
            "Iteration  3779 : Loss =  0.35760885  Acc:  0.87605 Val_loss =  0.44013053 Val_acc =  0.8466\n",
            "Iteration  3780 : Loss =  0.35759795  Acc:  0.8760333 Val_loss =  0.4401332 Val_acc =  0.8468\n",
            "Iteration  3781 : Loss =  0.35758704  Acc:  0.8760333 Val_loss =  0.44013545 Val_acc =  0.8466\n",
            "Iteration  3782 : Loss =  0.35757613  Acc:  0.87605 Val_loss =  0.44013834 Val_acc =  0.8468\n",
            "Iteration  3783 : Loss =  0.3575653  Acc:  0.8760333 Val_loss =  0.44014043 Val_acc =  0.8465\n",
            "Iteration  3784 : Loss =  0.35755444  Acc:  0.876 Val_loss =  0.44014356 Val_acc =  0.8467\n",
            "Iteration  3785 : Loss =  0.35754365  Acc:  0.87605 Val_loss =  0.44014555 Val_acc =  0.8465\n",
            "Iteration  3786 : Loss =  0.35753295  Acc:  0.876 Val_loss =  0.44014913 Val_acc =  0.8467\n",
            "Iteration  3787 : Loss =  0.35752237  Acc:  0.87605 Val_loss =  0.44015092 Val_acc =  0.8465\n",
            "Iteration  3788 : Loss =  0.357512  Acc:  0.8760167 Val_loss =  0.44015536 Val_acc =  0.8468\n",
            "Iteration  3789 : Loss =  0.357502  Acc:  0.8761333 Val_loss =  0.44015712 Val_acc =  0.8464\n",
            "Iteration  3790 : Loss =  0.3574925  Acc:  0.87593335 Val_loss =  0.44016328 Val_acc =  0.8466\n",
            "Iteration  3791 : Loss =  0.35748398  Acc:  0.87618333 Val_loss =  0.44016543 Val_acc =  0.8465\n",
            "Iteration  3792 : Loss =  0.35747677  Acc:  0.87586665 Val_loss =  0.44017524 Val_acc =  0.8463\n",
            "Iteration  3793 : Loss =  0.35747162  Acc:  0.87628335 Val_loss =  0.44017926 Val_acc =  0.8469\n",
            "Iteration  3794 : Loss =  0.35746917  Acc:  0.87598336 Val_loss =  0.4401962 Val_acc =  0.8461\n",
            "Iteration  3795 : Loss =  0.3574703  Acc:  0.87645 Val_loss =  0.440204 Val_acc =  0.8471\n",
            "Iteration  3796 : Loss =  0.35747358  Acc:  0.87591666 Val_loss =  0.44022992 Val_acc =  0.8462\n",
            "Iteration  3797 : Loss =  0.35747695  Acc:  0.8763833 Val_loss =  0.44023666 Val_acc =  0.8472\n",
            "Iteration  3798 : Loss =  0.35747156  Acc:  0.87591666 Val_loss =  0.44025683 Val_acc =  0.846\n",
            "Iteration  3799 : Loss =  0.3574533  Acc:  0.8763667 Val_loss =  0.4402394 Val_acc =  0.8472\n",
            "Iteration  3800 : Loss =  0.3574194  Acc:  0.876 Val_loss =  0.4402293 Val_acc =  0.8462\n",
            "Iteration  3801 : Loss =  0.3573834  Acc:  0.87626666 Val_loss =  0.4401978 Val_acc =  0.8467\n",
            "Iteration  3802 : Loss =  0.35735902  Acc:  0.87605 Val_loss =  0.44018993 Val_acc =  0.8465\n",
            "Iteration  3803 : Loss =  0.35735196  Acc:  0.876 Val_loss =  0.44019735 Val_acc =  0.8464\n",
            "Iteration  3804 : Loss =  0.35735482  Acc:  0.8763 Val_loss =  0.44020888 Val_acc =  0.8467\n",
            "Iteration  3805 : Loss =  0.3573542  Acc:  0.8760167 Val_loss =  0.44022992 Val_acc =  0.8461\n",
            "Iteration  3806 : Loss =  0.35734195  Acc:  0.8764 Val_loss =  0.44022197 Val_acc =  0.8468\n",
            "Iteration  3807 : Loss =  0.35731915  Acc:  0.87591666 Val_loss =  0.4402199 Val_acc =  0.8461\n",
            "Iteration  3808 : Loss =  0.35729668  Acc:  0.87623334 Val_loss =  0.44020557 Val_acc =  0.8462\n",
            "Iteration  3809 : Loss =  0.3572832  Acc:  0.8761167 Val_loss =  0.44020626 Val_acc =  0.8461\n",
            "Iteration  3810 : Loss =  0.35727853  Acc:  0.8760333 Val_loss =  0.44021788 Val_acc =  0.8461\n",
            "Iteration  3811 : Loss =  0.3572748  Acc:  0.87626666 Val_loss =  0.44022247 Val_acc =  0.8466\n",
            "Iteration  3812 : Loss =  0.35726485  Acc:  0.87595 Val_loss =  0.44023234 Val_acc =  0.846\n",
            "Iteration  3813 : Loss =  0.35724843  Acc:  0.87626666 Val_loss =  0.44022304 Val_acc =  0.8464\n",
            "Iteration  3814 : Loss =  0.35723105  Acc:  0.8760667 Val_loss =  0.44022274 Val_acc =  0.8463\n",
            "Iteration  3815 : Loss =  0.3572184  Acc:  0.8760833 Val_loss =  0.44022235 Val_acc =  0.8463\n",
            "Iteration  3816 : Loss =  0.35721087  Acc:  0.87623334 Val_loss =  0.44022623 Val_acc =  0.8462\n",
            "Iteration  3817 : Loss =  0.35720396  Acc:  0.87596667 Val_loss =  0.44023687 Val_acc =  0.8459\n",
            "Iteration  3818 : Loss =  0.3571937  Acc:  0.87628335 Val_loss =  0.4402349 Val_acc =  0.8463\n",
            "Iteration  3819 : Loss =  0.35717982  Acc:  0.8760833 Val_loss =  0.44023857 Val_acc =  0.8462\n",
            "Iteration  3820 : Loss =  0.3571656  Acc:  0.8760833 Val_loss =  0.44023466 Val_acc =  0.8462\n",
            "Iteration  3821 : Loss =  0.357154  Acc:  0.8761167 Val_loss =  0.44023693 Val_acc =  0.8463\n",
            "Iteration  3822 : Loss =  0.35714507  Acc:  0.87615 Val_loss =  0.44024283 Val_acc =  0.8463\n",
            "Iteration  3823 : Loss =  0.3571364  Acc:  0.87631667 Val_loss =  0.44024444 Val_acc =  0.8464\n",
            "Iteration  3824 : Loss =  0.35712582  Acc:  0.8761 Val_loss =  0.44025078 Val_acc =  0.8463\n",
            "Iteration  3825 : Loss =  0.35711333  Acc:  0.87616664 Val_loss =  0.4402482 Val_acc =  0.846\n",
            "Iteration  3826 : Loss =  0.35710078  Acc:  0.8761333 Val_loss =  0.44025093 Val_acc =  0.8463\n",
            "Iteration  3827 : Loss =  0.35708973  Acc:  0.8761167 Val_loss =  0.44025278 Val_acc =  0.8464\n",
            "Iteration  3828 : Loss =  0.35708004  Acc:  0.87615 Val_loss =  0.44025508 Val_acc =  0.8462\n",
            "Iteration  3829 : Loss =  0.35707042  Acc:  0.87615 Val_loss =  0.44026113 Val_acc =  0.8463\n",
            "Iteration  3830 : Loss =  0.35705975  Acc:  0.87616664 Val_loss =  0.44026098 Val_acc =  0.8461\n",
            "Iteration  3831 : Loss =  0.3570481  Acc:  0.87621665 Val_loss =  0.44026494 Val_acc =  0.8463\n",
            "Iteration  3832 : Loss =  0.3570364  Acc:  0.87615 Val_loss =  0.44026503 Val_acc =  0.8463\n",
            "Iteration  3833 : Loss =  0.35702553  Acc:  0.87618333 Val_loss =  0.44026762 Val_acc =  0.8464\n",
            "Iteration  3834 : Loss =  0.35701537  Acc:  0.8761333 Val_loss =  0.44027168 Val_acc =  0.8464\n",
            "Iteration  3835 : Loss =  0.35700527  Acc:  0.87618333 Val_loss =  0.44027305 Val_acc =  0.8462\n",
            "Iteration  3836 : Loss =  0.35699466  Acc:  0.87623334 Val_loss =  0.44027779 Val_acc =  0.8463\n",
            "Iteration  3837 : Loss =  0.35698348  Acc:  0.87615 Val_loss =  0.44027802 Val_acc =  0.8462\n",
            "Iteration  3838 : Loss =  0.3569723  Acc:  0.87616664 Val_loss =  0.44028115 Val_acc =  0.8464\n",
            "Iteration  3839 : Loss =  0.35696146  Acc:  0.87616664 Val_loss =  0.4402834 Val_acc =  0.8464\n",
            "Iteration  3840 : Loss =  0.3569511  Acc:  0.87618333 Val_loss =  0.44028565 Val_acc =  0.8463\n",
            "Iteration  3841 : Loss =  0.35694075  Acc:  0.87621665 Val_loss =  0.44028986 Val_acc =  0.8463\n",
            "Iteration  3842 : Loss =  0.35693017  Acc:  0.87616664 Val_loss =  0.44029102 Val_acc =  0.8462\n",
            "Iteration  3843 : Loss =  0.35691926  Acc:  0.87625 Val_loss =  0.44029477 Val_acc =  0.8463\n",
            "Iteration  3844 : Loss =  0.35690832  Acc:  0.87623334 Val_loss =  0.44029608 Val_acc =  0.8463\n",
            "Iteration  3845 : Loss =  0.3568976  Acc:  0.8762 Val_loss =  0.44029897 Val_acc =  0.8463\n",
            "Iteration  3846 : Loss =  0.35688704  Acc:  0.87625 Val_loss =  0.44030195 Val_acc =  0.8464\n",
            "Iteration  3847 : Loss =  0.35687658  Acc:  0.87621665 Val_loss =  0.44030395 Val_acc =  0.8463\n",
            "Iteration  3848 : Loss =  0.356866  Acc:  0.87626666 Val_loss =  0.44030783 Val_acc =  0.8463\n",
            "Iteration  3849 : Loss =  0.35685533  Acc:  0.87618333 Val_loss =  0.4403093 Val_acc =  0.8463\n",
            "Iteration  3850 : Loss =  0.35684454  Acc:  0.8763 Val_loss =  0.44031253 Val_acc =  0.8464\n",
            "Iteration  3851 : Loss =  0.35683382  Acc:  0.87621665 Val_loss =  0.44031465 Val_acc =  0.8463\n",
            "Iteration  3852 : Loss =  0.35682318  Acc:  0.8762 Val_loss =  0.44031727 Val_acc =  0.8463\n",
            "Iteration  3853 : Loss =  0.3568127  Acc:  0.87631667 Val_loss =  0.44032052 Val_acc =  0.8464\n",
            "Iteration  3854 : Loss =  0.35680214  Acc:  0.87621665 Val_loss =  0.44032246 Val_acc =  0.8464\n",
            "Iteration  3855 : Loss =  0.35679153  Acc:  0.87633336 Val_loss =  0.44032592 Val_acc =  0.8463\n",
            "Iteration  3856 : Loss =  0.35678086  Acc:  0.87623334 Val_loss =  0.44032782 Val_acc =  0.8464\n",
            "Iteration  3857 : Loss =  0.3567702  Acc:  0.8763 Val_loss =  0.44033086 Val_acc =  0.8464\n",
            "Iteration  3858 : Loss =  0.35675958  Acc:  0.87631667 Val_loss =  0.4403334 Val_acc =  0.8463\n",
            "Iteration  3859 : Loss =  0.35674897  Acc:  0.8763 Val_loss =  0.44033593 Val_acc =  0.8464\n",
            "Iteration  3860 : Loss =  0.35673848  Acc:  0.87633336 Val_loss =  0.44033906 Val_acc =  0.8464\n",
            "Iteration  3861 : Loss =  0.35672787  Acc:  0.87628335 Val_loss =  0.4403412 Val_acc =  0.8465\n",
            "Iteration  3862 : Loss =  0.35671726  Acc:  0.8763667 Val_loss =  0.44034442 Val_acc =  0.8463\n",
            "Iteration  3863 : Loss =  0.35670668  Acc:  0.87635 Val_loss =  0.44034663 Val_acc =  0.8464\n",
            "Iteration  3864 : Loss =  0.35669604  Acc:  0.87635 Val_loss =  0.44034952 Val_acc =  0.8463\n",
            "Iteration  3865 : Loss =  0.3566855  Acc:  0.8763667 Val_loss =  0.44035223 Val_acc =  0.8465\n",
            "Iteration  3866 : Loss =  0.35667494  Acc:  0.8763833 Val_loss =  0.44035468 Val_acc =  0.8465\n",
            "Iteration  3867 : Loss =  0.3566644  Acc:  0.8764 Val_loss =  0.4403578 Val_acc =  0.8464\n",
            "Iteration  3868 : Loss =  0.3566538  Acc:  0.8763833 Val_loss =  0.44036007 Val_acc =  0.8464\n",
            "Iteration  3869 : Loss =  0.35664326  Acc:  0.8764 Val_loss =  0.44036317 Val_acc =  0.8465\n",
            "Iteration  3870 : Loss =  0.35663268  Acc:  0.8764 Val_loss =  0.44036558 Val_acc =  0.8465\n",
            "Iteration  3871 : Loss =  0.3566221  Acc:  0.8764 Val_loss =  0.44036844 Val_acc =  0.8464\n",
            "Iteration  3872 : Loss =  0.35661152  Acc:  0.8764 Val_loss =  0.4403712 Val_acc =  0.8464\n",
            "Iteration  3873 : Loss =  0.35660103  Acc:  0.8764167 Val_loss =  0.44037372 Val_acc =  0.8465\n",
            "Iteration  3874 : Loss =  0.3565905  Acc:  0.8764167 Val_loss =  0.44037676 Val_acc =  0.8464\n",
            "Iteration  3875 : Loss =  0.35657996  Acc:  0.8764333 Val_loss =  0.4403792 Val_acc =  0.8465\n",
            "Iteration  3876 : Loss =  0.3565694  Acc:  0.8764333 Val_loss =  0.4403822 Val_acc =  0.8464\n",
            "Iteration  3877 : Loss =  0.35655886  Acc:  0.8764167 Val_loss =  0.44038466 Val_acc =  0.8465\n",
            "Iteration  3878 : Loss =  0.3565483  Acc:  0.8764167 Val_loss =  0.44038755 Val_acc =  0.8464\n",
            "Iteration  3879 : Loss =  0.3565378  Acc:  0.8764167 Val_loss =  0.4403903 Val_acc =  0.8464\n",
            "Iteration  3880 : Loss =  0.35652727  Acc:  0.87645 Val_loss =  0.44039297 Val_acc =  0.8464\n",
            "Iteration  3881 : Loss =  0.35651678  Acc:  0.8764667 Val_loss =  0.4403959 Val_acc =  0.8464\n",
            "Iteration  3882 : Loss =  0.35650626  Acc:  0.8765 Val_loss =  0.44039842 Val_acc =  0.8464\n",
            "Iteration  3883 : Loss =  0.35649574  Acc:  0.8765 Val_loss =  0.44040138 Val_acc =  0.8464\n",
            "Iteration  3884 : Loss =  0.35648522  Acc:  0.87651664 Val_loss =  0.44040397 Val_acc =  0.8464\n",
            "Iteration  3885 : Loss =  0.3564747  Acc:  0.87651664 Val_loss =  0.44040683 Val_acc =  0.8464\n",
            "Iteration  3886 : Loss =  0.3564642  Acc:  0.87651664 Val_loss =  0.44040957 Val_acc =  0.8464\n",
            "Iteration  3887 : Loss =  0.35645372  Acc:  0.87651664 Val_loss =  0.4404123 Val_acc =  0.8464\n",
            "Iteration  3888 : Loss =  0.35644323  Acc:  0.8765 Val_loss =  0.44041517 Val_acc =  0.8464\n",
            "Iteration  3889 : Loss =  0.3564327  Acc:  0.8765 Val_loss =  0.4404179 Val_acc =  0.8464\n",
            "Iteration  3890 : Loss =  0.35642225  Acc:  0.87651664 Val_loss =  0.4404208 Val_acc =  0.8464\n",
            "Iteration  3891 : Loss =  0.35641176  Acc:  0.87651664 Val_loss =  0.44042343 Val_acc =  0.8464\n",
            "Iteration  3892 : Loss =  0.35640123  Acc:  0.87651664 Val_loss =  0.44042638 Val_acc =  0.8464\n",
            "Iteration  3893 : Loss =  0.35639074  Acc:  0.87651664 Val_loss =  0.44042906 Val_acc =  0.8464\n",
            "Iteration  3894 : Loss =  0.35638028  Acc:  0.8765333 Val_loss =  0.44043183 Val_acc =  0.8464\n",
            "Iteration  3895 : Loss =  0.35636982  Acc:  0.8765333 Val_loss =  0.44043472 Val_acc =  0.8465\n",
            "Iteration  3896 : Loss =  0.35635933  Acc:  0.8765333 Val_loss =  0.44043747 Val_acc =  0.8465\n",
            "Iteration  3897 : Loss =  0.3563489  Acc:  0.8765333 Val_loss =  0.44044033 Val_acc =  0.8465\n",
            "Iteration  3898 : Loss =  0.3563384  Acc:  0.8765333 Val_loss =  0.44044307 Val_acc =  0.8465\n",
            "Iteration  3899 : Loss =  0.35632798  Acc:  0.8765333 Val_loss =  0.44044596 Val_acc =  0.8465\n",
            "Iteration  3900 : Loss =  0.35631752  Acc:  0.87651664 Val_loss =  0.44044873 Val_acc =  0.8465\n",
            "Iteration  3901 : Loss =  0.35630703  Acc:  0.87651664 Val_loss =  0.44045162 Val_acc =  0.8464\n",
            "Iteration  3902 : Loss =  0.35629657  Acc:  0.87651664 Val_loss =  0.4404544 Val_acc =  0.8464\n",
            "Iteration  3903 : Loss =  0.35628617  Acc:  0.8765 Val_loss =  0.44045722 Val_acc =  0.8464\n",
            "Iteration  3904 : Loss =  0.3562757  Acc:  0.87651664 Val_loss =  0.44046006 Val_acc =  0.8464\n",
            "Iteration  3905 : Loss =  0.35626528  Acc:  0.8764833 Val_loss =  0.4404629 Val_acc =  0.8464\n",
            "Iteration  3906 : Loss =  0.35625482  Acc:  0.8765333 Val_loss =  0.44046578 Val_acc =  0.8464\n",
            "Iteration  3907 : Loss =  0.35624442  Acc:  0.8764833 Val_loss =  0.44046855 Val_acc =  0.8464\n",
            "Iteration  3908 : Loss =  0.35623395  Acc:  0.87655 Val_loss =  0.44047147 Val_acc =  0.8464\n",
            "Iteration  3909 : Loss =  0.35622352  Acc:  0.87655 Val_loss =  0.44047427 Val_acc =  0.8465\n",
            "Iteration  3910 : Loss =  0.3562131  Acc:  0.87655 Val_loss =  0.44047716 Val_acc =  0.8465\n",
            "Iteration  3911 : Loss =  0.3562027  Acc:  0.8765333 Val_loss =  0.44048 Val_acc =  0.8465\n",
            "Iteration  3912 : Loss =  0.35619226  Acc:  0.8765333 Val_loss =  0.44048285 Val_acc =  0.8465\n",
            "Iteration  3913 : Loss =  0.35618186  Acc:  0.8765333 Val_loss =  0.44048575 Val_acc =  0.8465\n",
            "Iteration  3914 : Loss =  0.35617146  Acc:  0.87656665 Val_loss =  0.44048858 Val_acc =  0.8465\n",
            "Iteration  3915 : Loss =  0.35616106  Acc:  0.87651664 Val_loss =  0.4404915 Val_acc =  0.8465\n",
            "Iteration  3916 : Loss =  0.35615066  Acc:  0.87656665 Val_loss =  0.44049433 Val_acc =  0.8465\n",
            "Iteration  3917 : Loss =  0.35614023  Acc:  0.87655 Val_loss =  0.44049728 Val_acc =  0.8465\n",
            "Iteration  3918 : Loss =  0.35612985  Acc:  0.8765333 Val_loss =  0.4405001 Val_acc =  0.8465\n",
            "Iteration  3919 : Loss =  0.35611942  Acc:  0.8765333 Val_loss =  0.44050303 Val_acc =  0.8465\n",
            "Iteration  3920 : Loss =  0.35610905  Acc:  0.8765333 Val_loss =  0.44050586 Val_acc =  0.8465\n",
            "Iteration  3921 : Loss =  0.35609865  Acc:  0.8765333 Val_loss =  0.44050878 Val_acc =  0.8465\n",
            "Iteration  3922 : Loss =  0.35608828  Acc:  0.87656665 Val_loss =  0.44051167 Val_acc =  0.8466\n",
            "Iteration  3923 : Loss =  0.3560779  Acc:  0.87656665 Val_loss =  0.44051456 Val_acc =  0.8466\n",
            "Iteration  3924 : Loss =  0.3560675  Acc:  0.87655 Val_loss =  0.4405175 Val_acc =  0.8466\n",
            "Iteration  3925 : Loss =  0.35605717  Acc:  0.87656665 Val_loss =  0.44052038 Val_acc =  0.8466\n",
            "Iteration  3926 : Loss =  0.35604677  Acc:  0.87656665 Val_loss =  0.4405233 Val_acc =  0.8466\n",
            "Iteration  3927 : Loss =  0.3560364  Acc:  0.87658334 Val_loss =  0.44052616 Val_acc =  0.8466\n",
            "Iteration  3928 : Loss =  0.35602605  Acc:  0.87658334 Val_loss =  0.4405291 Val_acc =  0.8466\n",
            "Iteration  3929 : Loss =  0.35601568  Acc:  0.8766 Val_loss =  0.44053203 Val_acc =  0.8466\n",
            "Iteration  3930 : Loss =  0.3560053  Acc:  0.87661666 Val_loss =  0.44053495 Val_acc =  0.8466\n",
            "Iteration  3931 : Loss =  0.35599494  Acc:  0.8766 Val_loss =  0.4405379 Val_acc =  0.8467\n",
            "Iteration  3932 : Loss =  0.35598463  Acc:  0.8766 Val_loss =  0.44054082 Val_acc =  0.8467\n",
            "Iteration  3933 : Loss =  0.35597426  Acc:  0.8766 Val_loss =  0.44054374 Val_acc =  0.8467\n",
            "Iteration  3934 : Loss =  0.35596395  Acc:  0.87658334 Val_loss =  0.4405467 Val_acc =  0.8468\n",
            "Iteration  3935 : Loss =  0.35595357  Acc:  0.87658334 Val_loss =  0.44054967 Val_acc =  0.8468\n",
            "Iteration  3936 : Loss =  0.35594323  Acc:  0.87658334 Val_loss =  0.44055253 Val_acc =  0.8468\n",
            "Iteration  3937 : Loss =  0.3559329  Acc:  0.87658334 Val_loss =  0.4405555 Val_acc =  0.8468\n",
            "Iteration  3938 : Loss =  0.35592255  Acc:  0.87658334 Val_loss =  0.44055843 Val_acc =  0.8468\n",
            "Iteration  3939 : Loss =  0.3559122  Acc:  0.8766 Val_loss =  0.4405614 Val_acc =  0.8469\n",
            "Iteration  3940 : Loss =  0.3559019  Acc:  0.8766 Val_loss =  0.44056436 Val_acc =  0.8469\n",
            "Iteration  3941 : Loss =  0.35589162  Acc:  0.8766 Val_loss =  0.44056734 Val_acc =  0.8469\n",
            "Iteration  3942 : Loss =  0.35588124  Acc:  0.8766 Val_loss =  0.44057032 Val_acc =  0.8469\n",
            "Iteration  3943 : Loss =  0.35587093  Acc:  0.87661666 Val_loss =  0.44057325 Val_acc =  0.8469\n",
            "Iteration  3944 : Loss =  0.35586062  Acc:  0.87661666 Val_loss =  0.44057626 Val_acc =  0.8469\n",
            "Iteration  3945 : Loss =  0.35585034  Acc:  0.87661666 Val_loss =  0.4405792 Val_acc =  0.8469\n",
            "Iteration  3946 : Loss =  0.35584  Acc:  0.87661666 Val_loss =  0.44058222 Val_acc =  0.8469\n",
            "Iteration  3947 : Loss =  0.3558297  Acc:  0.87661666 Val_loss =  0.44058517 Val_acc =  0.8469\n",
            "Iteration  3948 : Loss =  0.3558194  Acc:  0.87663335 Val_loss =  0.44058818 Val_acc =  0.8469\n",
            "Iteration  3949 : Loss =  0.3558091  Acc:  0.87663335 Val_loss =  0.44059116 Val_acc =  0.8469\n",
            "Iteration  3950 : Loss =  0.35579884  Acc:  0.87665 Val_loss =  0.44059414 Val_acc =  0.8469\n",
            "Iteration  3951 : Loss =  0.35578853  Acc:  0.87665 Val_loss =  0.44059718 Val_acc =  0.8469\n",
            "Iteration  3952 : Loss =  0.35577825  Acc:  0.87665 Val_loss =  0.4406001 Val_acc =  0.8469\n",
            "Iteration  3953 : Loss =  0.35576797  Acc:  0.87665 Val_loss =  0.44060314 Val_acc =  0.8469\n",
            "Iteration  3954 : Loss =  0.35575765  Acc:  0.87665 Val_loss =  0.44060615 Val_acc =  0.8468\n",
            "Iteration  3955 : Loss =  0.3557474  Acc:  0.87665 Val_loss =  0.44060913 Val_acc =  0.8468\n",
            "Iteration  3956 : Loss =  0.35573712  Acc:  0.87666667 Val_loss =  0.44061217 Val_acc =  0.8468\n",
            "Iteration  3957 : Loss =  0.3557268  Acc:  0.87668335 Val_loss =  0.44061515 Val_acc =  0.8468\n",
            "Iteration  3958 : Loss =  0.35571656  Acc:  0.87666667 Val_loss =  0.44061816 Val_acc =  0.8468\n",
            "Iteration  3959 : Loss =  0.3557063  Acc:  0.87668335 Val_loss =  0.44062123 Val_acc =  0.8468\n",
            "Iteration  3960 : Loss =  0.35569602  Acc:  0.8767 Val_loss =  0.4406242 Val_acc =  0.8468\n",
            "Iteration  3961 : Loss =  0.3556858  Acc:  0.8767 Val_loss =  0.44062725 Val_acc =  0.8468\n",
            "Iteration  3962 : Loss =  0.35567552  Acc:  0.8767 Val_loss =  0.4406303 Val_acc =  0.8468\n",
            "Iteration  3963 : Loss =  0.35566524  Acc:  0.87668335 Val_loss =  0.44063336 Val_acc =  0.8468\n",
            "Iteration  3964 : Loss =  0.355655  Acc:  0.8767 Val_loss =  0.44063637 Val_acc =  0.8468\n",
            "Iteration  3965 : Loss =  0.3556448  Acc:  0.8767 Val_loss =  0.4406394 Val_acc =  0.8468\n",
            "Iteration  3966 : Loss =  0.3556345  Acc:  0.8767167 Val_loss =  0.44064248 Val_acc =  0.8468\n",
            "Iteration  3967 : Loss =  0.3556243  Acc:  0.87673336 Val_loss =  0.44064552 Val_acc =  0.8468\n",
            "Iteration  3968 : Loss =  0.35561407  Acc:  0.87673336 Val_loss =  0.44064853 Val_acc =  0.8468\n",
            "Iteration  3969 : Loss =  0.3556038  Acc:  0.87673336 Val_loss =  0.44065163 Val_acc =  0.8468\n",
            "Iteration  3970 : Loss =  0.35559356  Acc:  0.87675 Val_loss =  0.44065464 Val_acc =  0.8468\n",
            "Iteration  3971 : Loss =  0.35558334  Acc:  0.87673336 Val_loss =  0.4406577 Val_acc =  0.8468\n",
            "Iteration  3972 : Loss =  0.35557312  Acc:  0.87673336 Val_loss =  0.4406608 Val_acc =  0.8467\n",
            "Iteration  3973 : Loss =  0.3555629  Acc:  0.87673336 Val_loss =  0.44066387 Val_acc =  0.8467\n",
            "Iteration  3974 : Loss =  0.3555527  Acc:  0.87673336 Val_loss =  0.44066694 Val_acc =  0.8467\n",
            "Iteration  3975 : Loss =  0.35554248  Acc:  0.87673336 Val_loss =  0.44067 Val_acc =  0.8467\n",
            "Iteration  3976 : Loss =  0.3555323  Acc:  0.87673336 Val_loss =  0.44067305 Val_acc =  0.8467\n",
            "Iteration  3977 : Loss =  0.35552207  Acc:  0.87673336 Val_loss =  0.44067618 Val_acc =  0.8467\n",
            "Iteration  3978 : Loss =  0.35551184  Acc:  0.87673336 Val_loss =  0.44067925 Val_acc =  0.8467\n",
            "Iteration  3979 : Loss =  0.35550162  Acc:  0.87673336 Val_loss =  0.44068232 Val_acc =  0.8467\n",
            "Iteration  3980 : Loss =  0.35549143  Acc:  0.87673336 Val_loss =  0.44068545 Val_acc =  0.8466\n",
            "Iteration  3981 : Loss =  0.35548124  Acc:  0.87673336 Val_loss =  0.4406885 Val_acc =  0.8466\n",
            "Iteration  3982 : Loss =  0.35547107  Acc:  0.87675 Val_loss =  0.4406916 Val_acc =  0.8466\n",
            "Iteration  3983 : Loss =  0.35546088  Acc:  0.8767667 Val_loss =  0.44069472 Val_acc =  0.8466\n",
            "Iteration  3984 : Loss =  0.3554507  Acc:  0.8767667 Val_loss =  0.4406978 Val_acc =  0.8466\n",
            "Iteration  3985 : Loss =  0.3554405  Acc:  0.8767667 Val_loss =  0.44070092 Val_acc =  0.8466\n",
            "Iteration  3986 : Loss =  0.3554303  Acc:  0.8767667 Val_loss =  0.44070405 Val_acc =  0.8466\n",
            "Iteration  3987 : Loss =  0.35542014  Acc:  0.8767667 Val_loss =  0.44070718 Val_acc =  0.8466\n",
            "Iteration  3988 : Loss =  0.35540995  Acc:  0.8767667 Val_loss =  0.44071025 Val_acc =  0.8466\n",
            "Iteration  3989 : Loss =  0.35539982  Acc:  0.8767667 Val_loss =  0.44071338 Val_acc =  0.8468\n",
            "Iteration  3990 : Loss =  0.35538962  Acc:  0.8767667 Val_loss =  0.4407165 Val_acc =  0.8468\n",
            "Iteration  3991 : Loss =  0.35537946  Acc:  0.8767667 Val_loss =  0.44071963 Val_acc =  0.8468\n",
            "Iteration  3992 : Loss =  0.35536927  Acc:  0.8767833 Val_loss =  0.4407228 Val_acc =  0.8468\n",
            "Iteration  3993 : Loss =  0.3553591  Acc:  0.8767833 Val_loss =  0.44072592 Val_acc =  0.8468\n",
            "Iteration  3994 : Loss =  0.355349  Acc:  0.8767833 Val_loss =  0.44072905 Val_acc =  0.8468\n",
            "Iteration  3995 : Loss =  0.35533884  Acc:  0.8767833 Val_loss =  0.44073218 Val_acc =  0.8468\n",
            "Iteration  3996 : Loss =  0.35532868  Acc:  0.8767833 Val_loss =  0.44073534 Val_acc =  0.8468\n",
            "Iteration  3997 : Loss =  0.35531855  Acc:  0.8767833 Val_loss =  0.44073847 Val_acc =  0.8469\n",
            "Iteration  3998 : Loss =  0.35530838  Acc:  0.8768 Val_loss =  0.44074166 Val_acc =  0.8469\n",
            "Iteration  3999 : Loss =  0.35529825  Acc:  0.8767833 Val_loss =  0.44074473 Val_acc =  0.8469\n",
            "Iteration  4000 : Loss =  0.3552881  Acc:  0.8768 Val_loss =  0.44074795 Val_acc =  0.8469\n",
            "Iteration  4001 : Loss =  0.355278  Acc:  0.8768167 Val_loss =  0.44075108 Val_acc =  0.8469\n",
            "Iteration  4002 : Loss =  0.35526785  Acc:  0.8768167 Val_loss =  0.4407543 Val_acc =  0.8469\n",
            "Iteration  4003 : Loss =  0.35525775  Acc:  0.8768333 Val_loss =  0.44075736 Val_acc =  0.8469\n",
            "Iteration  4004 : Loss =  0.35524762  Acc:  0.87685 Val_loss =  0.44076064 Val_acc =  0.847\n",
            "Iteration  4005 : Loss =  0.3552375  Acc:  0.87686664 Val_loss =  0.4407637 Val_acc =  0.847\n",
            "Iteration  4006 : Loss =  0.35522738  Acc:  0.87686664 Val_loss =  0.44076705 Val_acc =  0.8471\n",
            "Iteration  4007 : Loss =  0.35521725  Acc:  0.87685 Val_loss =  0.44077003 Val_acc =  0.847\n",
            "Iteration  4008 : Loss =  0.35520718  Acc:  0.8768833 Val_loss =  0.44077343 Val_acc =  0.8471\n",
            "Iteration  4009 : Loss =  0.35519704  Acc:  0.8768333 Val_loss =  0.44077638 Val_acc =  0.847\n",
            "Iteration  4010 : Loss =  0.35518694  Acc:  0.87686664 Val_loss =  0.4407799 Val_acc =  0.8471\n",
            "Iteration  4011 : Loss =  0.35517684  Acc:  0.87685 Val_loss =  0.44078273 Val_acc =  0.847\n",
            "Iteration  4012 : Loss =  0.35516673  Acc:  0.8768333 Val_loss =  0.4407864 Val_acc =  0.8471\n",
            "Iteration  4013 : Loss =  0.35515672  Acc:  0.87685 Val_loss =  0.44078907 Val_acc =  0.847\n",
            "Iteration  4014 : Loss =  0.35514662  Acc:  0.87685 Val_loss =  0.44079298 Val_acc =  0.8471\n",
            "Iteration  4015 : Loss =  0.3551366  Acc:  0.87686664 Val_loss =  0.44079542 Val_acc =  0.8469\n",
            "Iteration  4016 : Loss =  0.3551266  Acc:  0.8768833 Val_loss =  0.44079974 Val_acc =  0.847\n",
            "Iteration  4017 : Loss =  0.3551166  Acc:  0.87685 Val_loss =  0.44080177 Val_acc =  0.8469\n",
            "Iteration  4018 : Loss =  0.35510677  Acc:  0.87686664 Val_loss =  0.4408069 Val_acc =  0.8471\n",
            "Iteration  4019 : Loss =  0.35509703  Acc:  0.8769 Val_loss =  0.4408083 Val_acc =  0.8471\n",
            "Iteration  4020 : Loss =  0.35508752  Acc:  0.87691665 Val_loss =  0.44081485 Val_acc =  0.8469\n",
            "Iteration  4021 : Loss =  0.35507846  Acc:  0.87685 Val_loss =  0.44081554 Val_acc =  0.847\n",
            "Iteration  4022 : Loss =  0.35506985  Acc:  0.87696666 Val_loss =  0.4408249 Val_acc =  0.8467\n",
            "Iteration  4023 : Loss =  0.35506234  Acc:  0.87695 Val_loss =  0.4408249 Val_acc =  0.8471\n",
            "Iteration  4024 : Loss =  0.3550563  Acc:  0.8768833 Val_loss =  0.4408397 Val_acc =  0.8465\n",
            "Iteration  4025 : Loss =  0.35505268  Acc:  0.8770667 Val_loss =  0.44084013 Val_acc =  0.8471\n",
            "Iteration  4026 : Loss =  0.3550523  Acc:  0.8767833 Val_loss =  0.44086534 Val_acc =  0.8464\n",
            "Iteration  4027 : Loss =  0.35505635  Acc:  0.87715 Val_loss =  0.44086808 Val_acc =  0.8473\n",
            "Iteration  4028 : Loss =  0.35506335  Acc:  0.8766 Val_loss =  0.44090766 Val_acc =  0.8462\n",
            "Iteration  4029 : Loss =  0.35507149  Acc:  0.87705 Val_loss =  0.44090724 Val_acc =  0.8473\n",
            "Iteration  4030 : Loss =  0.3550694  Acc:  0.8766 Val_loss =  0.4409442 Val_acc =  0.8462\n",
            "Iteration  4031 : Loss =  0.35505173  Acc:  0.87703335 Val_loss =  0.44091317 Val_acc =  0.8473\n",
            "Iteration  4032 : Loss =  0.35501367  Acc:  0.87655 Val_loss =  0.44091138 Val_acc =  0.8462\n",
            "Iteration  4033 : Loss =  0.35497245  Acc:  0.87705 Val_loss =  0.44086534 Val_acc =  0.8471\n",
            "Iteration  4034 : Loss =  0.3549461  Acc:  0.87691665 Val_loss =  0.44085908 Val_acc =  0.8471\n",
            "Iteration  4035 : Loss =  0.35494173  Acc:  0.87685 Val_loss =  0.44087085 Val_acc =  0.8468\n",
            "Iteration  4036 : Loss =  0.3549492  Acc:  0.87703335 Val_loss =  0.44088078 Val_acc =  0.8472\n",
            "Iteration  4037 : Loss =  0.35495076  Acc:  0.8767167 Val_loss =  0.44091278 Val_acc =  0.8464\n",
            "Iteration  4038 : Loss =  0.35493678  Acc:  0.8771667 Val_loss =  0.44089347 Val_acc =  0.8473\n",
            "Iteration  4039 : Loss =  0.3549106  Acc:  0.8769 Val_loss =  0.44089535 Val_acc =  0.8465\n",
            "Iteration  4040 : Loss =  0.35488757  Acc:  0.8768333 Val_loss =  0.44087666 Val_acc =  0.8469\n",
            "Iteration  4041 : Loss =  0.35487747  Acc:  0.8768167 Val_loss =  0.44087973 Val_acc =  0.8468\n",
            "Iteration  4042 : Loss =  0.3548767  Acc:  0.87685 Val_loss =  0.44090006 Val_acc =  0.8466\n",
            "Iteration  4043 : Loss =  0.35487413  Acc:  0.8770667 Val_loss =  0.4408987 Val_acc =  0.8471\n",
            "Iteration  4044 : Loss =  0.35486192  Acc:  0.87695 Val_loss =  0.44091317 Val_acc =  0.8465\n",
            "Iteration  4045 : Loss =  0.3548432  Acc:  0.87695 Val_loss =  0.4408964 Val_acc =  0.8471\n",
            "Iteration  4046 : Loss =  0.3548267  Acc:  0.87693334 Val_loss =  0.44089848 Val_acc =  0.8471\n",
            "Iteration  4047 : Loss =  0.35481763  Acc:  0.87695 Val_loss =  0.44090346 Val_acc =  0.8471\n",
            "Iteration  4048 : Loss =  0.3548132  Acc:  0.87696666 Val_loss =  0.44090596 Val_acc =  0.8471\n",
            "Iteration  4049 : Loss =  0.3548064  Acc:  0.87691665 Val_loss =  0.44092217 Val_acc =  0.8466\n",
            "Iteration  4050 : Loss =  0.35479417  Acc:  0.87698334 Val_loss =  0.4409129 Val_acc =  0.8472\n",
            "Iteration  4051 : Loss =  0.3547792  Acc:  0.87695 Val_loss =  0.44091836 Val_acc =  0.847\n",
            "Iteration  4052 : Loss =  0.35476667  Acc:  0.87691665 Val_loss =  0.44091582 Val_acc =  0.8467\n",
            "Iteration  4053 : Loss =  0.35475826  Acc:  0.8768833 Val_loss =  0.4409187 Val_acc =  0.8468\n",
            "Iteration  4054 : Loss =  0.35475138  Acc:  0.87696666 Val_loss =  0.44093075 Val_acc =  0.8469\n",
            "Iteration  4055 : Loss =  0.3547424  Acc:  0.87698334 Val_loss =  0.4409274 Val_acc =  0.847\n",
            "Iteration  4056 : Loss =  0.3547305  Acc:  0.87693334 Val_loss =  0.4409357 Val_acc =  0.847\n",
            "Iteration  4057 : Loss =  0.35471797  Acc:  0.87686664 Val_loss =  0.4409315 Val_acc =  0.8469\n",
            "Iteration  4058 : Loss =  0.3547073  Acc:  0.8768833 Val_loss =  0.44093516 Val_acc =  0.8467\n",
            "Iteration  4059 : Loss =  0.35469866  Acc:  0.8768833 Val_loss =  0.44094208 Val_acc =  0.8471\n",
            "Iteration  4060 : Loss =  0.3546903  Acc:  0.87695 Val_loss =  0.44094205 Val_acc =  0.847\n",
            "Iteration  4061 : Loss =  0.35468048  Acc:  0.87696666 Val_loss =  0.4409511 Val_acc =  0.847\n",
            "Iteration  4062 : Loss =  0.3546692  Acc:  0.87693334 Val_loss =  0.4409479 Val_acc =  0.8468\n",
            "Iteration  4063 : Loss =  0.35465807  Acc:  0.87695 Val_loss =  0.44095278 Val_acc =  0.847\n",
            "Iteration  4064 : Loss =  0.35464808  Acc:  0.87696666 Val_loss =  0.44095576 Val_acc =  0.847\n",
            "Iteration  4065 : Loss =  0.35463905  Acc:  0.87686664 Val_loss =  0.44095752 Val_acc =  0.8469\n",
            "Iteration  4066 : Loss =  0.35462987  Acc:  0.87691665 Val_loss =  0.44096544 Val_acc =  0.847\n",
            "Iteration  4067 : Loss =  0.35461983  Acc:  0.87693334 Val_loss =  0.44096416 Val_acc =  0.8468\n",
            "Iteration  4068 : Loss =  0.3546092  Acc:  0.87696666 Val_loss =  0.44097003 Val_acc =  0.8471\n",
            "Iteration  4069 : Loss =  0.3545987  Acc:  0.8769 Val_loss =  0.44097084 Val_acc =  0.8467\n",
            "Iteration  4070 : Loss =  0.3545889  Acc:  0.8768833 Val_loss =  0.44097403 Val_acc =  0.8467\n",
            "Iteration  4071 : Loss =  0.35457957  Acc:  0.87698334 Val_loss =  0.44097978 Val_acc =  0.8471\n",
            "Iteration  4072 : Loss =  0.35457006  Acc:  0.87693334 Val_loss =  0.44098037 Val_acc =  0.8469\n",
            "Iteration  4073 : Loss =  0.35456002  Acc:  0.87696666 Val_loss =  0.44098672 Val_acc =  0.8471\n",
            "Iteration  4074 : Loss =  0.35454974  Acc:  0.8768833 Val_loss =  0.44098702 Val_acc =  0.8468\n",
            "Iteration  4075 : Loss =  0.35453957  Acc:  0.87693334 Val_loss =  0.44099122 Val_acc =  0.8468\n",
            "Iteration  4076 : Loss =  0.35452983  Acc:  0.87691665 Val_loss =  0.44099492 Val_acc =  0.8468\n",
            "Iteration  4077 : Loss =  0.35452026  Acc:  0.8769 Val_loss =  0.44099697 Val_acc =  0.8468\n",
            "Iteration  4078 : Loss =  0.35451058  Acc:  0.87695 Val_loss =  0.4410027 Val_acc =  0.847\n",
            "Iteration  4079 : Loss =  0.35450065  Acc:  0.8769 Val_loss =  0.4410035 Val_acc =  0.8468\n",
            "Iteration  4080 : Loss =  0.35449055  Acc:  0.87695 Val_loss =  0.44100845 Val_acc =  0.8469\n",
            "Iteration  4081 : Loss =  0.3544806  Acc:  0.87698334 Val_loss =  0.44101068 Val_acc =  0.8467\n",
            "Iteration  4082 : Loss =  0.35447082  Acc:  0.87695 Val_loss =  0.44101387 Val_acc =  0.8466\n",
            "Iteration  4083 : Loss =  0.35446116  Acc:  0.87695 Val_loss =  0.44101846 Val_acc =  0.8468\n",
            "Iteration  4084 : Loss =  0.35445142  Acc:  0.87693334 Val_loss =  0.44102022 Val_acc =  0.8467\n",
            "Iteration  4085 : Loss =  0.3544416  Acc:  0.87695 Val_loss =  0.4410253 Val_acc =  0.8468\n",
            "Iteration  4086 : Loss =  0.35443163  Acc:  0.87698334 Val_loss =  0.44102705 Val_acc =  0.8466\n",
            "Iteration  4087 : Loss =  0.35442173  Acc:  0.87696666 Val_loss =  0.44103107 Val_acc =  0.8467\n",
            "Iteration  4088 : Loss =  0.35441196  Acc:  0.87696666 Val_loss =  0.44103444 Val_acc =  0.8467\n",
            "Iteration  4089 : Loss =  0.3544022  Acc:  0.87696666 Val_loss =  0.44103715 Val_acc =  0.8466\n",
            "Iteration  4090 : Loss =  0.3543925  Acc:  0.87698334 Val_loss =  0.4410417 Val_acc =  0.8467\n",
            "Iteration  4091 : Loss =  0.3543827  Acc:  0.87696666 Val_loss =  0.44104376 Val_acc =  0.8468\n",
            "Iteration  4092 : Loss =  0.35437286  Acc:  0.87698334 Val_loss =  0.4410482 Val_acc =  0.8467\n",
            "Iteration  4093 : Loss =  0.354363  Acc:  0.87698334 Val_loss =  0.44105077 Val_acc =  0.8466\n",
            "Iteration  4094 : Loss =  0.3543532  Acc:  0.877 Val_loss =  0.44105428 Val_acc =  0.8466\n",
            "Iteration  4095 : Loss =  0.35434344  Acc:  0.87701666 Val_loss =  0.441058 Val_acc =  0.8467\n",
            "Iteration  4096 : Loss =  0.35433373  Acc:  0.87698334 Val_loss =  0.4410607 Val_acc =  0.8468\n",
            "Iteration  4097 : Loss =  0.35432395  Acc:  0.87701666 Val_loss =  0.44106504 Val_acc =  0.8468\n",
            "Iteration  4098 : Loss =  0.35431412  Acc:  0.877 Val_loss =  0.4410675 Val_acc =  0.8468\n",
            "Iteration  4099 : Loss =  0.35430437  Acc:  0.87703335 Val_loss =  0.44107148 Val_acc =  0.8468\n",
            "Iteration  4100 : Loss =  0.35429457  Acc:  0.877 Val_loss =  0.44107455 Val_acc =  0.8468\n",
            "Iteration  4101 : Loss =  0.35428482  Acc:  0.877 Val_loss =  0.44107783 Val_acc =  0.8468\n",
            "Iteration  4102 : Loss =  0.35427508  Acc:  0.87701666 Val_loss =  0.4410817 Val_acc =  0.8468\n",
            "Iteration  4103 : Loss =  0.3542653  Acc:  0.87701666 Val_loss =  0.44108447 Val_acc =  0.8469\n",
            "Iteration  4104 : Loss =  0.35425556  Acc:  0.87701666 Val_loss =  0.4410886 Val_acc =  0.8468\n",
            "Iteration  4105 : Loss =  0.35424578  Acc:  0.87701666 Val_loss =  0.44109136 Val_acc =  0.8469\n",
            "Iteration  4106 : Loss =  0.35423604  Acc:  0.87701666 Val_loss =  0.4410951 Val_acc =  0.8469\n",
            "Iteration  4107 : Loss =  0.35422626  Acc:  0.87701666 Val_loss =  0.4410984 Val_acc =  0.8468\n",
            "Iteration  4108 : Loss =  0.35421655  Acc:  0.877 Val_loss =  0.44110167 Val_acc =  0.8469\n",
            "Iteration  4109 : Loss =  0.35420683  Acc:  0.877 Val_loss =  0.44110546 Val_acc =  0.8469\n",
            "Iteration  4110 : Loss =  0.35419708  Acc:  0.87703335 Val_loss =  0.4411084 Val_acc =  0.8469\n",
            "Iteration  4111 : Loss =  0.35418734  Acc:  0.877 Val_loss =  0.4411123 Val_acc =  0.8469\n",
            "Iteration  4112 : Loss =  0.3541776  Acc:  0.87703335 Val_loss =  0.44111532 Val_acc =  0.8468\n",
            "Iteration  4113 : Loss =  0.3541679  Acc:  0.87703335 Val_loss =  0.44111896 Val_acc =  0.8468\n",
            "Iteration  4114 : Loss =  0.35415813  Acc:  0.87705 Val_loss =  0.44112235 Val_acc =  0.8468\n",
            "Iteration  4115 : Loss =  0.35414845  Acc:  0.8770667 Val_loss =  0.44112563 Val_acc =  0.8468\n",
            "Iteration  4116 : Loss =  0.35413873  Acc:  0.87701666 Val_loss =  0.44112936 Val_acc =  0.8467\n",
            "Iteration  4117 : Loss =  0.35412902  Acc:  0.8770667 Val_loss =  0.44113246 Val_acc =  0.8466\n",
            "Iteration  4118 : Loss =  0.35411927  Acc:  0.87703335 Val_loss =  0.44113624 Val_acc =  0.8467\n",
            "Iteration  4119 : Loss =  0.35410956  Acc:  0.8770667 Val_loss =  0.4411394 Val_acc =  0.8466\n",
            "Iteration  4120 : Loss =  0.35409987  Acc:  0.8770667 Val_loss =  0.441143 Val_acc =  0.8466\n",
            "Iteration  4121 : Loss =  0.35409018  Acc:  0.8770667 Val_loss =  0.44114643 Val_acc =  0.8466\n",
            "Iteration  4122 : Loss =  0.35408044  Acc:  0.87708336 Val_loss =  0.4411498 Val_acc =  0.8466\n",
            "Iteration  4123 : Loss =  0.35407078  Acc:  0.8770667 Val_loss =  0.4411534 Val_acc =  0.8467\n",
            "Iteration  4124 : Loss =  0.35406104  Acc:  0.87708336 Val_loss =  0.4411567 Val_acc =  0.8466\n",
            "Iteration  4125 : Loss =  0.35405138  Acc:  0.8770667 Val_loss =  0.44116035 Val_acc =  0.8467\n",
            "Iteration  4126 : Loss =  0.35404167  Acc:  0.8770667 Val_loss =  0.44116363 Val_acc =  0.8466\n",
            "Iteration  4127 : Loss =  0.354032  Acc:  0.87708336 Val_loss =  0.44116724 Val_acc =  0.8466\n",
            "Iteration  4128 : Loss =  0.3540223  Acc:  0.87708336 Val_loss =  0.44117066 Val_acc =  0.8466\n",
            "Iteration  4129 : Loss =  0.35401264  Acc:  0.87708336 Val_loss =  0.44117412 Val_acc =  0.8466\n",
            "Iteration  4130 : Loss =  0.35400292  Acc:  0.87708336 Val_loss =  0.4411777 Val_acc =  0.8466\n",
            "Iteration  4131 : Loss =  0.35399327  Acc:  0.8771 Val_loss =  0.441181 Val_acc =  0.8466\n",
            "Iteration  4132 : Loss =  0.35398358  Acc:  0.8771 Val_loss =  0.44118467 Val_acc =  0.8466\n",
            "Iteration  4133 : Loss =  0.35397393  Acc:  0.8771 Val_loss =  0.44118798 Val_acc =  0.8466\n",
            "Iteration  4134 : Loss =  0.35396427  Acc:  0.8771 Val_loss =  0.44119164 Val_acc =  0.8466\n",
            "Iteration  4135 : Loss =  0.35395455  Acc:  0.8771167 Val_loss =  0.44119507 Val_acc =  0.8466\n",
            "Iteration  4136 : Loss =  0.35394493  Acc:  0.8771167 Val_loss =  0.44119853 Val_acc =  0.8466\n",
            "Iteration  4137 : Loss =  0.3539353  Acc:  0.8771333 Val_loss =  0.4412021 Val_acc =  0.8466\n",
            "Iteration  4138 : Loss =  0.35392562  Acc:  0.87715 Val_loss =  0.44120553 Val_acc =  0.8466\n",
            "Iteration  4139 : Loss =  0.35391596  Acc:  0.87715 Val_loss =  0.44120917 Val_acc =  0.8466\n",
            "Iteration  4140 : Loss =  0.3539063  Acc:  0.8771667 Val_loss =  0.44121253 Val_acc =  0.8466\n",
            "Iteration  4141 : Loss =  0.35389668  Acc:  0.87715 Val_loss =  0.4412162 Val_acc =  0.8466\n",
            "Iteration  4142 : Loss =  0.35388702  Acc:  0.87715 Val_loss =  0.44121963 Val_acc =  0.8466\n",
            "Iteration  4143 : Loss =  0.35387734  Acc:  0.87715 Val_loss =  0.44122314 Val_acc =  0.8466\n",
            "Iteration  4144 : Loss =  0.3538677  Acc:  0.87715 Val_loss =  0.44122672 Val_acc =  0.8466\n",
            "Iteration  4145 : Loss =  0.35385808  Acc:  0.8771667 Val_loss =  0.44123018 Val_acc =  0.8466\n",
            "Iteration  4146 : Loss =  0.35384843  Acc:  0.87715 Val_loss =  0.44123378 Val_acc =  0.8466\n",
            "Iteration  4147 : Loss =  0.35383883  Acc:  0.8771667 Val_loss =  0.4412372 Val_acc =  0.8466\n",
            "Iteration  4148 : Loss =  0.3538292  Acc:  0.87715 Val_loss =  0.44124088 Val_acc =  0.8466\n",
            "Iteration  4149 : Loss =  0.35381955  Acc:  0.8771333 Val_loss =  0.44124433 Val_acc =  0.8465\n",
            "Iteration  4150 : Loss =  0.35380995  Acc:  0.8771333 Val_loss =  0.4412479 Val_acc =  0.8465\n",
            "Iteration  4151 : Loss =  0.35380033  Acc:  0.8771333 Val_loss =  0.44125143 Val_acc =  0.8465\n",
            "Iteration  4152 : Loss =  0.35379073  Acc:  0.8771333 Val_loss =  0.44125497 Val_acc =  0.8465\n",
            "Iteration  4153 : Loss =  0.35378113  Acc:  0.8771333 Val_loss =  0.44125855 Val_acc =  0.8465\n",
            "Iteration  4154 : Loss =  0.35377148  Acc:  0.87715 Val_loss =  0.44126207 Val_acc =  0.8465\n",
            "Iteration  4155 : Loss =  0.35376185  Acc:  0.87715 Val_loss =  0.4412656 Val_acc =  0.8465\n",
            "Iteration  4156 : Loss =  0.3537523  Acc:  0.87715 Val_loss =  0.4412692 Val_acc =  0.8465\n",
            "Iteration  4157 : Loss =  0.35374263  Acc:  0.8771667 Val_loss =  0.4412728 Val_acc =  0.8466\n",
            "Iteration  4158 : Loss =  0.35373306  Acc:  0.8771833 Val_loss =  0.4412763 Val_acc =  0.8467\n",
            "Iteration  4159 : Loss =  0.35372344  Acc:  0.8771667 Val_loss =  0.4412799 Val_acc =  0.8467\n",
            "Iteration  4160 : Loss =  0.35371387  Acc:  0.8771833 Val_loss =  0.4412835 Val_acc =  0.8467\n",
            "Iteration  4161 : Loss =  0.3537043  Acc:  0.87721664 Val_loss =  0.44128707 Val_acc =  0.8468\n",
            "Iteration  4162 : Loss =  0.3536947  Acc:  0.87721664 Val_loss =  0.44129062 Val_acc =  0.8468\n",
            "Iteration  4163 : Loss =  0.35368508  Acc:  0.87721664 Val_loss =  0.4412942 Val_acc =  0.8467\n",
            "Iteration  4164 : Loss =  0.3536755  Acc:  0.87721664 Val_loss =  0.44129786 Val_acc =  0.8467\n",
            "Iteration  4165 : Loss =  0.35366595  Acc:  0.8772333 Val_loss =  0.44130138 Val_acc =  0.8467\n",
            "Iteration  4166 : Loss =  0.35365635  Acc:  0.8772333 Val_loss =  0.44130498 Val_acc =  0.8467\n",
            "Iteration  4167 : Loss =  0.3536468  Acc:  0.8772333 Val_loss =  0.44130856 Val_acc =  0.8467\n",
            "Iteration  4168 : Loss =  0.35363725  Acc:  0.87721664 Val_loss =  0.4413122 Val_acc =  0.8467\n",
            "Iteration  4169 : Loss =  0.35362768  Acc:  0.87721664 Val_loss =  0.44131577 Val_acc =  0.8467\n",
            "Iteration  4170 : Loss =  0.3536181  Acc:  0.8772 Val_loss =  0.44131938 Val_acc =  0.8467\n",
            "Iteration  4171 : Loss =  0.35360852  Acc:  0.8772 Val_loss =  0.441323 Val_acc =  0.8467\n",
            "Iteration  4172 : Loss =  0.35359895  Acc:  0.8772 Val_loss =  0.44132662 Val_acc =  0.8467\n",
            "Iteration  4173 : Loss =  0.3535894  Acc:  0.8772 Val_loss =  0.44133022 Val_acc =  0.8467\n",
            "Iteration  4174 : Loss =  0.35357985  Acc:  0.8772 Val_loss =  0.44133383 Val_acc =  0.8467\n",
            "Iteration  4175 : Loss =  0.35357028  Acc:  0.87715 Val_loss =  0.4413375 Val_acc =  0.8467\n",
            "Iteration  4176 : Loss =  0.35356075  Acc:  0.8771667 Val_loss =  0.44134107 Val_acc =  0.8467\n",
            "Iteration  4177 : Loss =  0.35355118  Acc:  0.8771333 Val_loss =  0.44134468 Val_acc =  0.8467\n",
            "Iteration  4178 : Loss =  0.35354167  Acc:  0.87715 Val_loss =  0.44134828 Val_acc =  0.8467\n",
            "Iteration  4179 : Loss =  0.3535321  Acc:  0.8771333 Val_loss =  0.44135195 Val_acc =  0.8468\n",
            "Iteration  4180 : Loss =  0.35352257  Acc:  0.87715 Val_loss =  0.44135556 Val_acc =  0.8468\n",
            "Iteration  4181 : Loss =  0.35351303  Acc:  0.8771667 Val_loss =  0.4413592 Val_acc =  0.8468\n",
            "Iteration  4182 : Loss =  0.3535035  Acc:  0.87715 Val_loss =  0.44136283 Val_acc =  0.8468\n",
            "Iteration  4183 : Loss =  0.35349396  Acc:  0.8771667 Val_loss =  0.4413665 Val_acc =  0.8468\n",
            "Iteration  4184 : Loss =  0.35348445  Acc:  0.8771833 Val_loss =  0.44137013 Val_acc =  0.8468\n",
            "Iteration  4185 : Loss =  0.35347494  Acc:  0.8771833 Val_loss =  0.44137383 Val_acc =  0.8468\n",
            "Iteration  4186 : Loss =  0.3534654  Acc:  0.8771833 Val_loss =  0.44137743 Val_acc =  0.8468\n",
            "Iteration  4187 : Loss =  0.35345587  Acc:  0.8771667 Val_loss =  0.4413811 Val_acc =  0.8468\n",
            "Iteration  4188 : Loss =  0.35344636  Acc:  0.8771667 Val_loss =  0.44138476 Val_acc =  0.8468\n",
            "Iteration  4189 : Loss =  0.35343686  Acc:  0.8771667 Val_loss =  0.44138843 Val_acc =  0.8468\n",
            "Iteration  4190 : Loss =  0.35342735  Acc:  0.87715 Val_loss =  0.4413921 Val_acc =  0.8468\n",
            "Iteration  4191 : Loss =  0.35341784  Acc:  0.87715 Val_loss =  0.44139576 Val_acc =  0.8468\n",
            "Iteration  4192 : Loss =  0.3534083  Acc:  0.87715 Val_loss =  0.44139943 Val_acc =  0.8468\n",
            "Iteration  4193 : Loss =  0.3533988  Acc:  0.8771333 Val_loss =  0.44140312 Val_acc =  0.8468\n",
            "Iteration  4194 : Loss =  0.35338932  Acc:  0.8771333 Val_loss =  0.44140673 Val_acc =  0.8468\n",
            "Iteration  4195 : Loss =  0.35337982  Acc:  0.8771333 Val_loss =  0.44141045 Val_acc =  0.8469\n",
            "Iteration  4196 : Loss =  0.3533703  Acc:  0.8771167 Val_loss =  0.44141415 Val_acc =  0.8469\n",
            "Iteration  4197 : Loss =  0.35336083  Acc:  0.8771 Val_loss =  0.4414178 Val_acc =  0.8469\n",
            "Iteration  4198 : Loss =  0.35335132  Acc:  0.8771333 Val_loss =  0.44142154 Val_acc =  0.8469\n",
            "Iteration  4199 : Loss =  0.35334185  Acc:  0.87715 Val_loss =  0.4414252 Val_acc =  0.8469\n",
            "Iteration  4200 : Loss =  0.35333237  Acc:  0.87715 Val_loss =  0.4414289 Val_acc =  0.8469\n",
            "Iteration  4201 : Loss =  0.35332292  Acc:  0.87715 Val_loss =  0.44143263 Val_acc =  0.8469\n",
            "Iteration  4202 : Loss =  0.3533134  Acc:  0.8771333 Val_loss =  0.4414363 Val_acc =  0.8468\n",
            "Iteration  4203 : Loss =  0.35330394  Acc:  0.8771333 Val_loss =  0.44144 Val_acc =  0.8468\n",
            "Iteration  4204 : Loss =  0.35329446  Acc:  0.8771333 Val_loss =  0.4414437 Val_acc =  0.8468\n",
            "Iteration  4205 : Loss =  0.35328498  Acc:  0.8771333 Val_loss =  0.44144747 Val_acc =  0.8468\n",
            "Iteration  4206 : Loss =  0.3532755  Acc:  0.8771667 Val_loss =  0.44145113 Val_acc =  0.8468\n",
            "Iteration  4207 : Loss =  0.353266  Acc:  0.8771667 Val_loss =  0.4414549 Val_acc =  0.8468\n",
            "Iteration  4208 : Loss =  0.3532566  Acc:  0.8771667 Val_loss =  0.44145855 Val_acc =  0.8468\n",
            "Iteration  4209 : Loss =  0.35324714  Acc:  0.8771667 Val_loss =  0.4414623 Val_acc =  0.8468\n",
            "Iteration  4210 : Loss =  0.3532377  Acc:  0.8771833 Val_loss =  0.441466 Val_acc =  0.8468\n",
            "Iteration  4211 : Loss =  0.35322824  Acc:  0.8771833 Val_loss =  0.44146973 Val_acc =  0.8468\n",
            "Iteration  4212 : Loss =  0.3532188  Acc:  0.8771833 Val_loss =  0.44147342 Val_acc =  0.8468\n",
            "Iteration  4213 : Loss =  0.35320935  Acc:  0.8771833 Val_loss =  0.44147724 Val_acc =  0.8468\n",
            "Iteration  4214 : Loss =  0.3531999  Acc:  0.8771833 Val_loss =  0.44148096 Val_acc =  0.8468\n",
            "Iteration  4215 : Loss =  0.35319042  Acc:  0.8771833 Val_loss =  0.44148466 Val_acc =  0.8468\n",
            "Iteration  4216 : Loss =  0.35318097  Acc:  0.8771833 Val_loss =  0.4414884 Val_acc =  0.8468\n",
            "Iteration  4217 : Loss =  0.3531716  Acc:  0.8772 Val_loss =  0.4414922 Val_acc =  0.8468\n",
            "Iteration  4218 : Loss =  0.3531621  Acc:  0.87721664 Val_loss =  0.4414959 Val_acc =  0.8468\n",
            "Iteration  4219 : Loss =  0.3531527  Acc:  0.87721664 Val_loss =  0.44149965 Val_acc =  0.8468\n",
            "Iteration  4220 : Loss =  0.35314327  Acc:  0.87721664 Val_loss =  0.4415034 Val_acc =  0.8468\n",
            "Iteration  4221 : Loss =  0.35313386  Acc:  0.8772333 Val_loss =  0.4415072 Val_acc =  0.8468\n",
            "Iteration  4222 : Loss =  0.3531244  Acc:  0.8772333 Val_loss =  0.44151095 Val_acc =  0.8468\n",
            "Iteration  4223 : Loss =  0.353115  Acc:  0.8772333 Val_loss =  0.4415147 Val_acc =  0.8468\n",
            "Iteration  4224 : Loss =  0.3531056  Acc:  0.87725 Val_loss =  0.44151846 Val_acc =  0.8468\n",
            "Iteration  4225 : Loss =  0.35309616  Acc:  0.87725 Val_loss =  0.4415222 Val_acc =  0.8468\n",
            "Iteration  4226 : Loss =  0.35308674  Acc:  0.87725 Val_loss =  0.44152597 Val_acc =  0.8468\n",
            "Iteration  4227 : Loss =  0.35307735  Acc:  0.87725 Val_loss =  0.44152978 Val_acc =  0.8468\n",
            "Iteration  4228 : Loss =  0.35306793  Acc:  0.87726665 Val_loss =  0.4415336 Val_acc =  0.8468\n",
            "Iteration  4229 : Loss =  0.35305852  Acc:  0.87726665 Val_loss =  0.4415373 Val_acc =  0.8468\n",
            "Iteration  4230 : Loss =  0.35304916  Acc:  0.87726665 Val_loss =  0.4415411 Val_acc =  0.8467\n",
            "Iteration  4231 : Loss =  0.3530397  Acc:  0.87726665 Val_loss =  0.44154492 Val_acc =  0.8467\n",
            "Iteration  4232 : Loss =  0.35303032  Acc:  0.87728333 Val_loss =  0.44154873 Val_acc =  0.8467\n",
            "Iteration  4233 : Loss =  0.35302097  Acc:  0.87728333 Val_loss =  0.4415525 Val_acc =  0.8467\n",
            "Iteration  4234 : Loss =  0.35301158  Acc:  0.87726665 Val_loss =  0.4415563 Val_acc =  0.8467\n",
            "Iteration  4235 : Loss =  0.35300216  Acc:  0.87726665 Val_loss =  0.44156006 Val_acc =  0.8466\n",
            "Iteration  4236 : Loss =  0.35299277  Acc:  0.87728333 Val_loss =  0.44156387 Val_acc =  0.8466\n",
            "Iteration  4237 : Loss =  0.3529834  Acc:  0.8773 Val_loss =  0.4415677 Val_acc =  0.8466\n",
            "Iteration  4238 : Loss =  0.35297403  Acc:  0.87731665 Val_loss =  0.44157153 Val_acc =  0.8466\n",
            "Iteration  4239 : Loss =  0.35296464  Acc:  0.87731665 Val_loss =  0.4415753 Val_acc =  0.8466\n",
            "Iteration  4240 : Loss =  0.35295528  Acc:  0.87731665 Val_loss =  0.44157916 Val_acc =  0.8466\n",
            "Iteration  4241 : Loss =  0.3529459  Acc:  0.87731665 Val_loss =  0.44158292 Val_acc =  0.8466\n",
            "Iteration  4242 : Loss =  0.35293654  Acc:  0.87731665 Val_loss =  0.44158676 Val_acc =  0.8466\n",
            "Iteration  4243 : Loss =  0.35292715  Acc:  0.87731665 Val_loss =  0.44159064 Val_acc =  0.8466\n",
            "Iteration  4244 : Loss =  0.35291776  Acc:  0.8773 Val_loss =  0.4415944 Val_acc =  0.8466\n",
            "Iteration  4245 : Loss =  0.35290843  Acc:  0.8773 Val_loss =  0.44159824 Val_acc =  0.8466\n",
            "Iteration  4246 : Loss =  0.35289907  Acc:  0.8773 Val_loss =  0.4416021 Val_acc =  0.8466\n",
            "Iteration  4247 : Loss =  0.35288972  Acc:  0.8773 Val_loss =  0.4416059 Val_acc =  0.8466\n",
            "Iteration  4248 : Loss =  0.35288033  Acc:  0.8773 Val_loss =  0.44160977 Val_acc =  0.8466\n",
            "Iteration  4249 : Loss =  0.35287103  Acc:  0.8773 Val_loss =  0.44161358 Val_acc =  0.8466\n",
            "Iteration  4250 : Loss =  0.35286164  Acc:  0.87731665 Val_loss =  0.4416175 Val_acc =  0.8466\n",
            "Iteration  4251 : Loss =  0.35285234  Acc:  0.87731665 Val_loss =  0.44162124 Val_acc =  0.8466\n",
            "Iteration  4252 : Loss =  0.35284296  Acc:  0.8773 Val_loss =  0.4416252 Val_acc =  0.8466\n",
            "Iteration  4253 : Loss =  0.35283366  Acc:  0.8773 Val_loss =  0.4416289 Val_acc =  0.8466\n",
            "Iteration  4254 : Loss =  0.35282433  Acc:  0.8773 Val_loss =  0.4416329 Val_acc =  0.8466\n",
            "Iteration  4255 : Loss =  0.35281497  Acc:  0.8773 Val_loss =  0.44163662 Val_acc =  0.8466\n",
            "Iteration  4256 : Loss =  0.35280564  Acc:  0.87728333 Val_loss =  0.44164062 Val_acc =  0.8466\n",
            "Iteration  4257 : Loss =  0.35279632  Acc:  0.87728333 Val_loss =  0.44164428 Val_acc =  0.8466\n",
            "Iteration  4258 : Loss =  0.352787  Acc:  0.8773 Val_loss =  0.44164842 Val_acc =  0.8466\n",
            "Iteration  4259 : Loss =  0.35277766  Acc:  0.87728333 Val_loss =  0.44165194 Val_acc =  0.8466\n",
            "Iteration  4260 : Loss =  0.35276836  Acc:  0.87731665 Val_loss =  0.4416563 Val_acc =  0.8466\n",
            "Iteration  4261 : Loss =  0.35275906  Acc:  0.87728333 Val_loss =  0.44165963 Val_acc =  0.8466\n",
            "Iteration  4262 : Loss =  0.35274974  Acc:  0.87731665 Val_loss =  0.44166422 Val_acc =  0.8467\n",
            "Iteration  4263 : Loss =  0.35274044  Acc:  0.8773 Val_loss =  0.44166723 Val_acc =  0.8466\n",
            "Iteration  4264 : Loss =  0.3527312  Acc:  0.87728333 Val_loss =  0.44167233 Val_acc =  0.8467\n",
            "Iteration  4265 : Loss =  0.35272193  Acc:  0.8773 Val_loss =  0.4416748 Val_acc =  0.8464\n",
            "Iteration  4266 : Loss =  0.35271275  Acc:  0.87731665 Val_loss =  0.44168067 Val_acc =  0.8467\n",
            "Iteration  4267 : Loss =  0.35270357  Acc:  0.8773 Val_loss =  0.44168234 Val_acc =  0.8464\n",
            "Iteration  4268 : Loss =  0.3526946  Acc:  0.8773 Val_loss =  0.4416896 Val_acc =  0.8467\n",
            "Iteration  4269 : Loss =  0.3526858  Acc:  0.87736666 Val_loss =  0.44169 Val_acc =  0.8464\n",
            "Iteration  4270 : Loss =  0.35267732  Acc:  0.87721664 Val_loss =  0.4417 Val_acc =  0.8468\n",
            "Iteration  4271 : Loss =  0.3526694  Acc:  0.8774833 Val_loss =  0.44169852 Val_acc =  0.8463\n",
            "Iteration  4272 : Loss =  0.35266244  Acc:  0.8771833 Val_loss =  0.44171366 Val_acc =  0.8467\n",
            "Iteration  4273 : Loss =  0.35265714  Acc:  0.8775333 Val_loss =  0.44171014 Val_acc =  0.8465\n",
            "Iteration  4274 : Loss =  0.35265428  Acc:  0.8771167 Val_loss =  0.4417356 Val_acc =  0.8468\n",
            "Iteration  4275 : Loss =  0.35265553  Acc:  0.87755 Val_loss =  0.4417311 Val_acc =  0.8467\n",
            "Iteration  4276 : Loss =  0.3526618  Acc:  0.8771667 Val_loss =  0.44177577 Val_acc =  0.8463\n",
            "Iteration  4277 : Loss =  0.35267466  Acc:  0.8774667 Val_loss =  0.44177145 Val_acc =  0.8472\n",
            "Iteration  4278 : Loss =  0.35268888  Acc:  0.87696666 Val_loss =  0.44183776 Val_acc =  0.8461\n",
            "Iteration  4279 : Loss =  0.35269833  Acc:  0.8775333 Val_loss =  0.44181666 Val_acc =  0.8475\n",
            "Iteration  4280 : Loss =  0.35268313  Acc:  0.87705 Val_loss =  0.44186196 Val_acc =  0.8459\n",
            "Iteration  4281 : Loss =  0.35264316  Acc:  0.87745 Val_loss =  0.44179004 Val_acc =  0.8473\n",
            "Iteration  4282 : Loss =  0.35259026  Acc:  0.8770667 Val_loss =  0.44178203 Val_acc =  0.8465\n",
            "Iteration  4283 : Loss =  0.3525561  Acc:  0.8774 Val_loss =  0.44174483 Val_acc =  0.8464\n",
            "Iteration  4284 : Loss =  0.35255343  Acc:  0.87755 Val_loss =  0.44175118 Val_acc =  0.8464\n",
            "Iteration  4285 : Loss =  0.35256797  Acc:  0.8771 Val_loss =  0.44180036 Val_acc =  0.8463\n",
            "Iteration  4286 : Loss =  0.35257435  Acc:  0.87743336 Val_loss =  0.4417895 Val_acc =  0.847\n",
            "Iteration  4287 : Loss =  0.35255605  Acc:  0.87715 Val_loss =  0.4418169 Val_acc =  0.8464\n",
            "Iteration  4288 : Loss =  0.35252404  Acc:  0.87755 Val_loss =  0.4417714 Val_acc =  0.8465\n",
            "Iteration  4289 : Loss =  0.35250026  Acc:  0.87731665 Val_loss =  0.44177192 Val_acc =  0.8466\n",
            "Iteration  4290 : Loss =  0.35249612  Acc:  0.8771833 Val_loss =  0.44178545 Val_acc =  0.8467\n",
            "Iteration  4291 : Loss =  0.3525011  Acc:  0.8775 Val_loss =  0.44178683 Val_acc =  0.8466\n",
            "Iteration  4292 : Loss =  0.35249707  Acc:  0.87708336 Val_loss =  0.4418202 Val_acc =  0.8466\n",
            "Iteration  4293 : Loss =  0.35247907  Acc:  0.8774833 Val_loss =  0.4417917 Val_acc =  0.8465\n",
            "Iteration  4294 : Loss =  0.35245734  Acc:  0.8772 Val_loss =  0.4417981 Val_acc =  0.8468\n",
            "Iteration  4295 : Loss =  0.3524452  Acc:  0.8773 Val_loss =  0.4417959 Val_acc =  0.8467\n",
            "Iteration  4296 : Loss =  0.3524429  Acc:  0.8775333 Val_loss =  0.44179815 Val_acc =  0.8465\n",
            "Iteration  4297 : Loss =  0.35244015  Acc:  0.8771667 Val_loss =  0.44182524 Val_acc =  0.847\n",
            "Iteration  4298 : Loss =  0.3524291  Acc:  0.8774833 Val_loss =  0.4418085 Val_acc =  0.8465\n",
            "Iteration  4299 : Loss =  0.3524125  Acc:  0.87721664 Val_loss =  0.44181934 Val_acc =  0.8468\n",
            "Iteration  4300 : Loss =  0.35239902  Acc:  0.8773 Val_loss =  0.44181263 Val_acc =  0.8465\n",
            "Iteration  4301 : Loss =  0.35239226  Acc:  0.8775 Val_loss =  0.44181523 Val_acc =  0.8463\n",
            "Iteration  4302 : Loss =  0.3523877  Acc:  0.8772 Val_loss =  0.44183487 Val_acc =  0.8468\n",
            "Iteration  4303 : Loss =  0.3523793  Acc:  0.8774833 Val_loss =  0.4418253 Val_acc =  0.8466\n",
            "Iteration  4304 : Loss =  0.35236642  Acc:  0.8771833 Val_loss =  0.441838 Val_acc =  0.8468\n",
            "Iteration  4305 : Loss =  0.35235375  Acc:  0.87738335 Val_loss =  0.44183114 Val_acc =  0.8466\n",
            "Iteration  4306 : Loss =  0.35234478  Acc:  0.8774167 Val_loss =  0.4418348 Val_acc =  0.8466\n",
            "Iteration  4307 : Loss =  0.3523383  Acc:  0.87721664 Val_loss =  0.4418484 Val_acc =  0.8468\n",
            "Iteration  4308 : Loss =  0.3523306  Acc:  0.8775 Val_loss =  0.4418433 Val_acc =  0.8466\n",
            "Iteration  4309 : Loss =  0.35231996  Acc:  0.8772 Val_loss =  0.44185612 Val_acc =  0.8468\n",
            "Iteration  4310 : Loss =  0.35230845  Acc:  0.8774167 Val_loss =  0.4418504 Val_acc =  0.8466\n",
            "Iteration  4311 : Loss =  0.35229865  Acc:  0.87736666 Val_loss =  0.44185528 Val_acc =  0.8466\n",
            "Iteration  4312 : Loss =  0.35229078  Acc:  0.87726665 Val_loss =  0.44186425 Val_acc =  0.8467\n",
            "Iteration  4313 : Loss =  0.35228294  Acc:  0.8775 Val_loss =  0.4418621 Val_acc =  0.8464\n",
            "Iteration  4314 : Loss =  0.35227352  Acc:  0.87725 Val_loss =  0.44187394 Val_acc =  0.8468\n",
            "Iteration  4315 : Loss =  0.35226303  Acc:  0.87743336 Val_loss =  0.44186974 Val_acc =  0.8466\n",
            "Iteration  4316 : Loss =  0.35225305  Acc:  0.87728333 Val_loss =  0.4418757 Val_acc =  0.8467\n",
            "Iteration  4317 : Loss =  0.35224435  Acc:  0.87731665 Val_loss =  0.44188136 Val_acc =  0.8467\n",
            "Iteration  4318 : Loss =  0.35223612  Acc:  0.8774833 Val_loss =  0.44188145 Val_acc =  0.8466\n",
            "Iteration  4319 : Loss =  0.35222724  Acc:  0.87728333 Val_loss =  0.44189185 Val_acc =  0.8467\n",
            "Iteration  4320 : Loss =  0.35221756  Acc:  0.8774167 Val_loss =  0.44188932 Val_acc =  0.8466\n",
            "Iteration  4321 : Loss =  0.35220775  Acc:  0.87725 Val_loss =  0.44189608 Val_acc =  0.8468\n",
            "Iteration  4322 : Loss =  0.35219857  Acc:  0.87725 Val_loss =  0.44189957 Val_acc =  0.8468\n",
            "Iteration  4323 : Loss =  0.3521899  Acc:  0.87738335 Val_loss =  0.44190136 Val_acc =  0.8466\n",
            "Iteration  4324 : Loss =  0.3521812  Acc:  0.87735 Val_loss =  0.44191015 Val_acc =  0.8467\n",
            "Iteration  4325 : Loss =  0.35217193  Acc:  0.87738335 Val_loss =  0.4419092 Val_acc =  0.8466\n",
            "Iteration  4326 : Loss =  0.35216242  Acc:  0.87725 Val_loss =  0.44191635 Val_acc =  0.8468\n",
            "Iteration  4327 : Loss =  0.35215312  Acc:  0.87736666 Val_loss =  0.4419185 Val_acc =  0.8467\n",
            "Iteration  4328 : Loss =  0.35214415  Acc:  0.8774 Val_loss =  0.44192174 Val_acc =  0.8466\n",
            "Iteration  4329 : Loss =  0.35213536  Acc:  0.87728333 Val_loss =  0.4419287 Val_acc =  0.8467\n",
            "Iteration  4330 : Loss =  0.35212636  Acc:  0.8774167 Val_loss =  0.44192916 Val_acc =  0.8466\n",
            "Iteration  4331 : Loss =  0.35211712  Acc:  0.87731665 Val_loss =  0.44193628 Val_acc =  0.8468\n",
            "Iteration  4332 : Loss =  0.35210782  Acc:  0.87736666 Val_loss =  0.44193783 Val_acc =  0.8466\n",
            "Iteration  4333 : Loss =  0.3520987  Acc:  0.87733334 Val_loss =  0.4419422 Val_acc =  0.8466\n",
            "Iteration  4334 : Loss =  0.3520898  Acc:  0.87726665 Val_loss =  0.44194755 Val_acc =  0.8468\n",
            "Iteration  4335 : Loss =  0.35208085  Acc:  0.8774167 Val_loss =  0.4419493 Val_acc =  0.8466\n",
            "Iteration  4336 : Loss =  0.35207182  Acc:  0.8773 Val_loss =  0.441956 Val_acc =  0.8468\n",
            "Iteration  4337 : Loss =  0.35206264  Acc:  0.87736666 Val_loss =  0.44195756 Val_acc =  0.8466\n",
            "Iteration  4338 : Loss =  0.35205346  Acc:  0.87735 Val_loss =  0.44196266 Val_acc =  0.8467\n",
            "Iteration  4339 : Loss =  0.35204446  Acc:  0.87735 Val_loss =  0.44196674 Val_acc =  0.8467\n",
            "Iteration  4340 : Loss =  0.3520355  Acc:  0.8774 Val_loss =  0.44196963 Val_acc =  0.8466\n",
            "Iteration  4341 : Loss =  0.3520265  Acc:  0.87736666 Val_loss =  0.4419756 Val_acc =  0.8468\n",
            "Iteration  4342 : Loss =  0.35201746  Acc:  0.8774 Val_loss =  0.4419775 Val_acc =  0.8466\n",
            "Iteration  4343 : Loss =  0.35200834  Acc:  0.87736666 Val_loss =  0.441983 Val_acc =  0.8468\n",
            "Iteration  4344 : Loss =  0.35199928  Acc:  0.87738335 Val_loss =  0.4419863 Val_acc =  0.8467\n",
            "Iteration  4345 : Loss =  0.35199022  Acc:  0.8774167 Val_loss =  0.44199005 Val_acc =  0.8467\n",
            "Iteration  4346 : Loss =  0.35198125  Acc:  0.87736666 Val_loss =  0.4419951 Val_acc =  0.8469\n",
            "Iteration  4347 : Loss =  0.35197225  Acc:  0.8774167 Val_loss =  0.4419977 Val_acc =  0.8467\n",
            "Iteration  4348 : Loss =  0.35196322  Acc:  0.87736666 Val_loss =  0.44200322 Val_acc =  0.8469\n",
            "Iteration  4349 : Loss =  0.35195416  Acc:  0.87743336 Val_loss =  0.4420061 Val_acc =  0.8467\n",
            "Iteration  4350 : Loss =  0.35194513  Acc:  0.87743336 Val_loss =  0.44201055 Val_acc =  0.8468\n",
            "Iteration  4351 : Loss =  0.35193613  Acc:  0.8774 Val_loss =  0.44201484 Val_acc =  0.8468\n",
            "Iteration  4352 : Loss =  0.3519271  Acc:  0.87745 Val_loss =  0.44201812 Val_acc =  0.8467\n",
            "Iteration  4353 : Loss =  0.35191816  Acc:  0.8774167 Val_loss =  0.44202328 Val_acc =  0.8469\n",
            "Iteration  4354 : Loss =  0.3519091  Acc:  0.87745 Val_loss =  0.44202617 Val_acc =  0.8467\n",
            "Iteration  4355 : Loss =  0.3519001  Acc:  0.8774667 Val_loss =  0.44203106 Val_acc =  0.8468\n",
            "Iteration  4356 : Loss =  0.35189107  Acc:  0.87743336 Val_loss =  0.44203472 Val_acc =  0.8467\n",
            "Iteration  4357 : Loss =  0.3518821  Acc:  0.87745 Val_loss =  0.44203857 Val_acc =  0.8467\n",
            "Iteration  4358 : Loss =  0.3518731  Acc:  0.8774667 Val_loss =  0.44204327 Val_acc =  0.8468\n",
            "Iteration  4359 : Loss =  0.35186413  Acc:  0.8774833 Val_loss =  0.4420465 Val_acc =  0.8467\n",
            "Iteration  4360 : Loss =  0.3518551  Acc:  0.8774833 Val_loss =  0.44205138 Val_acc =  0.8468\n",
            "Iteration  4361 : Loss =  0.35184616  Acc:  0.8774667 Val_loss =  0.44205475 Val_acc =  0.8467\n",
            "Iteration  4362 : Loss =  0.3518371  Acc:  0.8774667 Val_loss =  0.4420592 Val_acc =  0.8467\n",
            "Iteration  4363 : Loss =  0.35182816  Acc:  0.8774667 Val_loss =  0.44206327 Val_acc =  0.8467\n",
            "Iteration  4364 : Loss =  0.35181922  Acc:  0.8774667 Val_loss =  0.442067 Val_acc =  0.8468\n",
            "Iteration  4365 : Loss =  0.35181022  Acc:  0.8774667 Val_loss =  0.44207162 Val_acc =  0.8469\n",
            "Iteration  4366 : Loss =  0.35180122  Acc:  0.8775 Val_loss =  0.44207504 Val_acc =  0.8468\n",
            "Iteration  4367 : Loss =  0.35179225  Acc:  0.8774667 Val_loss =  0.4420797 Val_acc =  0.8469\n",
            "Iteration  4368 : Loss =  0.35178328  Acc:  0.8775 Val_loss =  0.4420834 Val_acc =  0.8468\n",
            "Iteration  4369 : Loss =  0.35177428  Acc:  0.8775 Val_loss =  0.4420876 Val_acc =  0.8468\n",
            "Iteration  4370 : Loss =  0.35176536  Acc:  0.8775 Val_loss =  0.44209185 Val_acc =  0.8469\n",
            "Iteration  4371 : Loss =  0.3517564  Acc:  0.8775 Val_loss =  0.44209555 Val_acc =  0.8469\n",
            "Iteration  4372 : Loss =  0.3517474  Acc:  0.8775167 Val_loss =  0.4421001 Val_acc =  0.847\n",
            "Iteration  4373 : Loss =  0.35173845  Acc:  0.8775167 Val_loss =  0.4421038 Val_acc =  0.847\n",
            "Iteration  4374 : Loss =  0.35172948  Acc:  0.8775167 Val_loss =  0.4421082 Val_acc =  0.8471\n",
            "Iteration  4375 : Loss =  0.35172057  Acc:  0.8775 Val_loss =  0.4421122 Val_acc =  0.8471\n",
            "Iteration  4376 : Loss =  0.3517116  Acc:  0.8775167 Val_loss =  0.4421162 Val_acc =  0.8471\n",
            "Iteration  4377 : Loss =  0.35170263  Acc:  0.8775167 Val_loss =  0.44212052 Val_acc =  0.8471\n",
            "Iteration  4378 : Loss =  0.3516937  Acc:  0.8775833 Val_loss =  0.4421243 Val_acc =  0.8471\n",
            "Iteration  4379 : Loss =  0.35168478  Acc:  0.8775667 Val_loss =  0.4421288 Val_acc =  0.847\n",
            "Iteration  4380 : Loss =  0.35167584  Acc:  0.8776 Val_loss =  0.44213262 Val_acc =  0.847\n",
            "Iteration  4381 : Loss =  0.35166687  Acc:  0.8776 Val_loss =  0.4421369 Val_acc =  0.847\n",
            "Iteration  4382 : Loss =  0.35165796  Acc:  0.87761664 Val_loss =  0.44214103 Val_acc =  0.847\n",
            "Iteration  4383 : Loss =  0.35164902  Acc:  0.87761664 Val_loss =  0.44214502 Val_acc =  0.847\n",
            "Iteration  4384 : Loss =  0.35164008  Acc:  0.8775833 Val_loss =  0.44214937 Val_acc =  0.847\n",
            "Iteration  4385 : Loss =  0.3516311  Acc:  0.8776 Val_loss =  0.44215322 Val_acc =  0.847\n",
            "Iteration  4386 : Loss =  0.35162222  Acc:  0.8775833 Val_loss =  0.44215763 Val_acc =  0.8469\n",
            "Iteration  4387 : Loss =  0.35161328  Acc:  0.87761664 Val_loss =  0.44216156 Val_acc =  0.847\n",
            "Iteration  4388 : Loss =  0.35160437  Acc:  0.8776 Val_loss =  0.44216582 Val_acc =  0.847\n",
            "Iteration  4389 : Loss =  0.35159543  Acc:  0.8776 Val_loss =  0.44216993 Val_acc =  0.847\n",
            "Iteration  4390 : Loss =  0.35158655  Acc:  0.8776 Val_loss =  0.44217402 Val_acc =  0.8471\n",
            "Iteration  4391 : Loss =  0.35157764  Acc:  0.87761664 Val_loss =  0.4421783 Val_acc =  0.8471\n",
            "Iteration  4392 : Loss =  0.35156873  Acc:  0.87761664 Val_loss =  0.44218227 Val_acc =  0.8471\n",
            "Iteration  4393 : Loss =  0.35155982  Acc:  0.87761664 Val_loss =  0.44218662 Val_acc =  0.8471\n",
            "Iteration  4394 : Loss =  0.3515509  Acc:  0.87761664 Val_loss =  0.44219062 Val_acc =  0.8471\n",
            "Iteration  4395 : Loss =  0.351542  Acc:  0.87761664 Val_loss =  0.44219482 Val_acc =  0.8471\n",
            "Iteration  4396 : Loss =  0.35153311  Acc:  0.87763333 Val_loss =  0.44219902 Val_acc =  0.8471\n",
            "Iteration  4397 : Loss =  0.35152414  Acc:  0.87765 Val_loss =  0.44220313 Val_acc =  0.8471\n",
            "Iteration  4398 : Loss =  0.3515153  Acc:  0.87765 Val_loss =  0.44220737 Val_acc =  0.8471\n",
            "Iteration  4399 : Loss =  0.35150638  Acc:  0.87765 Val_loss =  0.44221142 Val_acc =  0.8471\n",
            "Iteration  4400 : Loss =  0.3514975  Acc:  0.87766665 Val_loss =  0.4422157 Val_acc =  0.8471\n",
            "Iteration  4401 : Loss =  0.35148862  Acc:  0.87768334 Val_loss =  0.44221982 Val_acc =  0.8472\n",
            "Iteration  4402 : Loss =  0.3514797  Acc:  0.8777 Val_loss =  0.44222403 Val_acc =  0.8472\n",
            "Iteration  4403 : Loss =  0.35147086  Acc:  0.87771666 Val_loss =  0.44222817 Val_acc =  0.8472\n",
            "Iteration  4404 : Loss =  0.35146198  Acc:  0.87771666 Val_loss =  0.44223237 Val_acc =  0.8472\n",
            "Iteration  4405 : Loss =  0.3514531  Acc:  0.87771666 Val_loss =  0.44223663 Val_acc =  0.8472\n",
            "Iteration  4406 : Loss =  0.3514442  Acc:  0.87771666 Val_loss =  0.44224072 Val_acc =  0.8472\n",
            "Iteration  4407 : Loss =  0.35143533  Acc:  0.87771666 Val_loss =  0.442245 Val_acc =  0.8472\n",
            "Iteration  4408 : Loss =  0.35142642  Acc:  0.87771666 Val_loss =  0.44224912 Val_acc =  0.8472\n",
            "Iteration  4409 : Loss =  0.35141757  Acc:  0.87771666 Val_loss =  0.44225338 Val_acc =  0.8472\n",
            "Iteration  4410 : Loss =  0.35140872  Acc:  0.87773335 Val_loss =  0.44225752 Val_acc =  0.8472\n",
            "Iteration  4411 : Loss =  0.35139987  Acc:  0.87775 Val_loss =  0.44226176 Val_acc =  0.8472\n",
            "Iteration  4412 : Loss =  0.351391  Acc:  0.87775 Val_loss =  0.44226602 Val_acc =  0.8472\n",
            "Iteration  4413 : Loss =  0.35138214  Acc:  0.87775 Val_loss =  0.44227016 Val_acc =  0.8472\n",
            "Iteration  4414 : Loss =  0.35137329  Acc:  0.87775 Val_loss =  0.44227442 Val_acc =  0.8472\n",
            "Iteration  4415 : Loss =  0.35136437  Acc:  0.87775 Val_loss =  0.44227856 Val_acc =  0.8472\n",
            "Iteration  4416 : Loss =  0.3513556  Acc:  0.87773335 Val_loss =  0.44228283 Val_acc =  0.8472\n",
            "Iteration  4417 : Loss =  0.35134673  Acc:  0.87771666 Val_loss =  0.442287 Val_acc =  0.8472\n",
            "Iteration  4418 : Loss =  0.35133782  Acc:  0.87771666 Val_loss =  0.44229126 Val_acc =  0.8472\n",
            "Iteration  4419 : Loss =  0.35132903  Acc:  0.87771666 Val_loss =  0.44229552 Val_acc =  0.8472\n",
            "Iteration  4420 : Loss =  0.35132018  Acc:  0.87771666 Val_loss =  0.4422997 Val_acc =  0.8472\n",
            "Iteration  4421 : Loss =  0.35131133  Acc:  0.8777 Val_loss =  0.44230396 Val_acc =  0.8472\n",
            "Iteration  4422 : Loss =  0.3513025  Acc:  0.8777 Val_loss =  0.44230816 Val_acc =  0.8472\n",
            "Iteration  4423 : Loss =  0.35129365  Acc:  0.8777 Val_loss =  0.44231245 Val_acc =  0.8472\n",
            "Iteration  4424 : Loss =  0.35128483  Acc:  0.8777 Val_loss =  0.44231665 Val_acc =  0.8472\n",
            "Iteration  4425 : Loss =  0.35127598  Acc:  0.8777 Val_loss =  0.4423209 Val_acc =  0.8472\n",
            "Iteration  4426 : Loss =  0.35126716  Acc:  0.8777 Val_loss =  0.4423251 Val_acc =  0.8472\n",
            "Iteration  4427 : Loss =  0.35125834  Acc:  0.87771666 Val_loss =  0.4423294 Val_acc =  0.8472\n",
            "Iteration  4428 : Loss =  0.3512495  Acc:  0.87773335 Val_loss =  0.44233364 Val_acc =  0.8472\n",
            "Iteration  4429 : Loss =  0.3512407  Acc:  0.87771666 Val_loss =  0.4423379 Val_acc =  0.8472\n",
            "Iteration  4430 : Loss =  0.35123184  Acc:  0.87773335 Val_loss =  0.44234213 Val_acc =  0.8472\n",
            "Iteration  4431 : Loss =  0.35122305  Acc:  0.87773335 Val_loss =  0.4423464 Val_acc =  0.8472\n",
            "Iteration  4432 : Loss =  0.35121426  Acc:  0.87773335 Val_loss =  0.4423507 Val_acc =  0.8472\n",
            "Iteration  4433 : Loss =  0.3512054  Acc:  0.87773335 Val_loss =  0.44235492 Val_acc =  0.8472\n",
            "Iteration  4434 : Loss =  0.35119662  Acc:  0.87773335 Val_loss =  0.44235924 Val_acc =  0.8472\n",
            "Iteration  4435 : Loss =  0.35118783  Acc:  0.8777 Val_loss =  0.44236344 Val_acc =  0.8472\n",
            "Iteration  4436 : Loss =  0.35117897  Acc:  0.8777 Val_loss =  0.44236776 Val_acc =  0.8472\n",
            "Iteration  4437 : Loss =  0.35117018  Acc:  0.8777 Val_loss =  0.44237202 Val_acc =  0.8472\n",
            "Iteration  4438 : Loss =  0.3511614  Acc:  0.87771666 Val_loss =  0.44237632 Val_acc =  0.8472\n",
            "Iteration  4439 : Loss =  0.35115257  Acc:  0.87771666 Val_loss =  0.44238058 Val_acc =  0.8472\n",
            "Iteration  4440 : Loss =  0.3511438  Acc:  0.87771666 Val_loss =  0.44238487 Val_acc =  0.8472\n",
            "Iteration  4441 : Loss =  0.35113502  Acc:  0.87771666 Val_loss =  0.44238916 Val_acc =  0.8472\n",
            "Iteration  4442 : Loss =  0.3511262  Acc:  0.87771666 Val_loss =  0.44239345 Val_acc =  0.8472\n",
            "Iteration  4443 : Loss =  0.3511174  Acc:  0.87771666 Val_loss =  0.4423977 Val_acc =  0.8472\n",
            "Iteration  4444 : Loss =  0.35110867  Acc:  0.8777 Val_loss =  0.44240206 Val_acc =  0.8472\n",
            "Iteration  4445 : Loss =  0.35109988  Acc:  0.87768334 Val_loss =  0.44240636 Val_acc =  0.8472\n",
            "Iteration  4446 : Loss =  0.3510911  Acc:  0.87768334 Val_loss =  0.44241065 Val_acc =  0.8472\n",
            "Iteration  4447 : Loss =  0.3510823  Acc:  0.8777 Val_loss =  0.44241494 Val_acc =  0.8472\n",
            "Iteration  4448 : Loss =  0.3510735  Acc:  0.8777 Val_loss =  0.44241923 Val_acc =  0.8472\n",
            "Iteration  4449 : Loss =  0.3510647  Acc:  0.87768334 Val_loss =  0.44242352 Val_acc =  0.8472\n",
            "Iteration  4450 : Loss =  0.35105598  Acc:  0.87766665 Val_loss =  0.44242784 Val_acc =  0.8472\n",
            "Iteration  4451 : Loss =  0.3510472  Acc:  0.87768334 Val_loss =  0.44243217 Val_acc =  0.8472\n",
            "Iteration  4452 : Loss =  0.35103843  Acc:  0.8777 Val_loss =  0.4424365 Val_acc =  0.8472\n",
            "Iteration  4453 : Loss =  0.35102966  Acc:  0.8777 Val_loss =  0.4424408 Val_acc =  0.8472\n",
            "Iteration  4454 : Loss =  0.3510209  Acc:  0.8777 Val_loss =  0.44244513 Val_acc =  0.8472\n",
            "Iteration  4455 : Loss =  0.3510121  Acc:  0.87771666 Val_loss =  0.44244942 Val_acc =  0.8472\n",
            "Iteration  4456 : Loss =  0.35100338  Acc:  0.87775 Val_loss =  0.44245377 Val_acc =  0.8472\n",
            "Iteration  4457 : Loss =  0.3509946  Acc:  0.87773335 Val_loss =  0.4424581 Val_acc =  0.8472\n",
            "Iteration  4458 : Loss =  0.35098583  Acc:  0.87773335 Val_loss =  0.44246244 Val_acc =  0.8471\n",
            "Iteration  4459 : Loss =  0.35097712  Acc:  0.8777 Val_loss =  0.4424668 Val_acc =  0.8471\n",
            "Iteration  4460 : Loss =  0.3509684  Acc:  0.87773335 Val_loss =  0.4424711 Val_acc =  0.8471\n",
            "Iteration  4461 : Loss =  0.3509596  Acc:  0.87775 Val_loss =  0.44247544 Val_acc =  0.8471\n",
            "Iteration  4462 : Loss =  0.35095087  Acc:  0.87775 Val_loss =  0.4424798 Val_acc =  0.8471\n",
            "Iteration  4463 : Loss =  0.35094213  Acc:  0.87775 Val_loss =  0.44248417 Val_acc =  0.8471\n",
            "Iteration  4464 : Loss =  0.3509334  Acc:  0.87778336 Val_loss =  0.44248846 Val_acc =  0.8471\n",
            "Iteration  4465 : Loss =  0.35092467  Acc:  0.8778 Val_loss =  0.44249287 Val_acc =  0.8471\n",
            "Iteration  4466 : Loss =  0.3509159  Acc:  0.8778 Val_loss =  0.44249722 Val_acc =  0.8471\n",
            "Iteration  4467 : Loss =  0.35090715  Acc:  0.8778 Val_loss =  0.44250157 Val_acc =  0.8471\n",
            "Iteration  4468 : Loss =  0.35089844  Acc:  0.8778 Val_loss =  0.44250596 Val_acc =  0.847\n",
            "Iteration  4469 : Loss =  0.3508897  Acc:  0.8778 Val_loss =  0.44251025 Val_acc =  0.847\n",
            "Iteration  4470 : Loss =  0.35088098  Acc:  0.8778167 Val_loss =  0.4425147 Val_acc =  0.847\n",
            "Iteration  4471 : Loss =  0.3508723  Acc:  0.8778167 Val_loss =  0.44251904 Val_acc =  0.847\n",
            "Iteration  4472 : Loss =  0.35086358  Acc:  0.8778167 Val_loss =  0.4425234 Val_acc =  0.847\n",
            "Iteration  4473 : Loss =  0.35085484  Acc:  0.8778167 Val_loss =  0.44252774 Val_acc =  0.847\n",
            "Iteration  4474 : Loss =  0.35084608  Acc:  0.8778167 Val_loss =  0.44253212 Val_acc =  0.847\n",
            "Iteration  4475 : Loss =  0.3508374  Acc:  0.8778167 Val_loss =  0.44253653 Val_acc =  0.8471\n",
            "Iteration  4476 : Loss =  0.3508287  Acc:  0.8778333 Val_loss =  0.4425409 Val_acc =  0.8471\n",
            "Iteration  4477 : Loss =  0.35081998  Acc:  0.8778333 Val_loss =  0.44254532 Val_acc =  0.8471\n",
            "Iteration  4478 : Loss =  0.35081127  Acc:  0.8778333 Val_loss =  0.4425497 Val_acc =  0.8471\n",
            "Iteration  4479 : Loss =  0.35080257  Acc:  0.8778333 Val_loss =  0.44255406 Val_acc =  0.847\n",
            "Iteration  4480 : Loss =  0.35079387  Acc:  0.87785 Val_loss =  0.44255844 Val_acc =  0.847\n",
            "Iteration  4481 : Loss =  0.35078517  Acc:  0.8778333 Val_loss =  0.44256285 Val_acc =  0.847\n",
            "Iteration  4482 : Loss =  0.35077646  Acc:  0.8778333 Val_loss =  0.4425673 Val_acc =  0.847\n",
            "Iteration  4483 : Loss =  0.35076776  Acc:  0.87785 Val_loss =  0.44257167 Val_acc =  0.847\n",
            "Iteration  4484 : Loss =  0.35075912  Acc:  0.87785 Val_loss =  0.44257608 Val_acc =  0.847\n",
            "Iteration  4485 : Loss =  0.3507504  Acc:  0.87785 Val_loss =  0.44258046 Val_acc =  0.847\n",
            "Iteration  4486 : Loss =  0.35074174  Acc:  0.87785 Val_loss =  0.44258487 Val_acc =  0.847\n",
            "Iteration  4487 : Loss =  0.35073304  Acc:  0.87785 Val_loss =  0.4425893 Val_acc =  0.847\n",
            "Iteration  4488 : Loss =  0.35072434  Acc:  0.87785 Val_loss =  0.4425937 Val_acc =  0.847\n",
            "Iteration  4489 : Loss =  0.35071567  Acc:  0.87785 Val_loss =  0.44259813 Val_acc =  0.847\n",
            "Iteration  4490 : Loss =  0.35070696  Acc:  0.87785 Val_loss =  0.44260255 Val_acc =  0.847\n",
            "Iteration  4491 : Loss =  0.35069832  Acc:  0.8778333 Val_loss =  0.442607 Val_acc =  0.847\n",
            "Iteration  4492 : Loss =  0.35068965  Acc:  0.8778667 Val_loss =  0.44261143 Val_acc =  0.847\n",
            "Iteration  4493 : Loss =  0.35068095  Acc:  0.8778667 Val_loss =  0.4426158 Val_acc =  0.847\n",
            "Iteration  4494 : Loss =  0.3506723  Acc:  0.8778667 Val_loss =  0.44262028 Val_acc =  0.847\n",
            "Iteration  4495 : Loss =  0.3506636  Acc:  0.8778667 Val_loss =  0.44262472 Val_acc =  0.847\n",
            "Iteration  4496 : Loss =  0.35065496  Acc:  0.8778667 Val_loss =  0.4426291 Val_acc =  0.847\n",
            "Iteration  4497 : Loss =  0.3506463  Acc:  0.8778667 Val_loss =  0.44263354 Val_acc =  0.847\n",
            "Iteration  4498 : Loss =  0.35063767  Acc:  0.8778667 Val_loss =  0.44263798 Val_acc =  0.847\n",
            "Iteration  4499 : Loss =  0.35062897  Acc:  0.8778667 Val_loss =  0.44264242 Val_acc =  0.847\n",
            "Iteration  4500 : Loss =  0.3506203  Acc:  0.8778833 Val_loss =  0.44264686 Val_acc =  0.847\n",
            "Iteration  4501 : Loss =  0.35061166  Acc:  0.8778833 Val_loss =  0.44265136 Val_acc =  0.8469\n",
            "Iteration  4502 : Loss =  0.35060298  Acc:  0.8778833 Val_loss =  0.4426558 Val_acc =  0.8469\n",
            "Iteration  4503 : Loss =  0.35059437  Acc:  0.8779167 Val_loss =  0.44266024 Val_acc =  0.8469\n",
            "Iteration  4504 : Loss =  0.3505857  Acc:  0.8779167 Val_loss =  0.44266474 Val_acc =  0.8468\n",
            "Iteration  4505 : Loss =  0.3505771  Acc:  0.8779167 Val_loss =  0.44266915 Val_acc =  0.8467\n",
            "Iteration  4506 : Loss =  0.3505684  Acc:  0.8779167 Val_loss =  0.44267362 Val_acc =  0.8467\n",
            "Iteration  4507 : Loss =  0.35055983  Acc:  0.87795 Val_loss =  0.44267806 Val_acc =  0.8465\n",
            "Iteration  4508 : Loss =  0.35055116  Acc:  0.8779167 Val_loss =  0.44268256 Val_acc =  0.8466\n",
            "Iteration  4509 : Loss =  0.35054255  Acc:  0.8779333 Val_loss =  0.442687 Val_acc =  0.8466\n",
            "Iteration  4510 : Loss =  0.35053387  Acc:  0.8779333 Val_loss =  0.4426915 Val_acc =  0.8466\n",
            "Iteration  4511 : Loss =  0.35052526  Acc:  0.87795 Val_loss =  0.44269595 Val_acc =  0.8466\n",
            "Iteration  4512 : Loss =  0.35051665  Acc:  0.8779333 Val_loss =  0.44270048 Val_acc =  0.8466\n",
            "Iteration  4513 : Loss =  0.350508  Acc:  0.8779333 Val_loss =  0.44270495 Val_acc =  0.8466\n",
            "Iteration  4514 : Loss =  0.3504994  Acc:  0.8779167 Val_loss =  0.44270948 Val_acc =  0.8466\n",
            "Iteration  4515 : Loss =  0.35049078  Acc:  0.87795 Val_loss =  0.44271386 Val_acc =  0.8466\n",
            "Iteration  4516 : Loss =  0.35048217  Acc:  0.8779333 Val_loss =  0.4427185 Val_acc =  0.8466\n",
            "Iteration  4517 : Loss =  0.35047352  Acc:  0.8779333 Val_loss =  0.44272286 Val_acc =  0.8466\n",
            "Iteration  4518 : Loss =  0.3504649  Acc:  0.8779333 Val_loss =  0.44272748 Val_acc =  0.8466\n",
            "Iteration  4519 : Loss =  0.35045633  Acc:  0.8779 Val_loss =  0.44273183 Val_acc =  0.8466\n",
            "Iteration  4520 : Loss =  0.3504477  Acc:  0.8779167 Val_loss =  0.44273654 Val_acc =  0.8466\n",
            "Iteration  4521 : Loss =  0.35043913  Acc:  0.8778833 Val_loss =  0.44274083 Val_acc =  0.8466\n",
            "Iteration  4522 : Loss =  0.35043046  Acc:  0.8779 Val_loss =  0.4427456 Val_acc =  0.8465\n",
            "Iteration  4523 : Loss =  0.3504219  Acc:  0.8778833 Val_loss =  0.4427497 Val_acc =  0.8466\n",
            "Iteration  4524 : Loss =  0.3504133  Acc:  0.8778833 Val_loss =  0.4427547 Val_acc =  0.8465\n",
            "Iteration  4525 : Loss =  0.35040468  Acc:  0.8778833 Val_loss =  0.44275868 Val_acc =  0.8465\n",
            "Iteration  4526 : Loss =  0.3503961  Acc:  0.8778833 Val_loss =  0.4427638 Val_acc =  0.8465\n",
            "Iteration  4527 : Loss =  0.3503875  Acc:  0.8779167 Val_loss =  0.44276762 Val_acc =  0.8465\n",
            "Iteration  4528 : Loss =  0.3503789  Acc:  0.8778833 Val_loss =  0.44277304 Val_acc =  0.8466\n",
            "Iteration  4529 : Loss =  0.35037038  Acc:  0.87795 Val_loss =  0.44277647 Val_acc =  0.8466\n",
            "Iteration  4530 : Loss =  0.3503618  Acc:  0.87795 Val_loss =  0.44278243 Val_acc =  0.8466\n",
            "Iteration  4531 : Loss =  0.35035324  Acc:  0.87796664 Val_loss =  0.44278526 Val_acc =  0.8465\n",
            "Iteration  4532 : Loss =  0.35034472  Acc:  0.87795 Val_loss =  0.442792 Val_acc =  0.8466\n",
            "Iteration  4533 : Loss =  0.35033622  Acc:  0.87795 Val_loss =  0.44279394 Val_acc =  0.8465\n",
            "Iteration  4534 : Loss =  0.3503278  Acc:  0.87796664 Val_loss =  0.44280195 Val_acc =  0.8466\n",
            "Iteration  4535 : Loss =  0.35031945  Acc:  0.8779167 Val_loss =  0.44280255 Val_acc =  0.8465\n",
            "Iteration  4536 : Loss =  0.3503112  Acc:  0.87798333 Val_loss =  0.44281268 Val_acc =  0.8466\n",
            "Iteration  4537 : Loss =  0.3503032  Acc:  0.87803334 Val_loss =  0.44281113 Val_acc =  0.8463\n",
            "Iteration  4538 : Loss =  0.35029557  Acc:  0.87796664 Val_loss =  0.44282514 Val_acc =  0.8466\n",
            "Iteration  4539 : Loss =  0.35028848  Acc:  0.87801665 Val_loss =  0.4428204 Val_acc =  0.8465\n",
            "Iteration  4540 : Loss =  0.35028237  Acc:  0.8779 Val_loss =  0.4428412 Val_acc =  0.8466\n",
            "Iteration  4541 : Loss =  0.35027772  Acc:  0.8781 Val_loss =  0.44283238 Val_acc =  0.8465\n",
            "Iteration  4542 : Loss =  0.35027528  Acc:  0.87801665 Val_loss =  0.44286543 Val_acc =  0.8466\n",
            "Iteration  4543 : Loss =  0.35027638  Acc:  0.8782 Val_loss =  0.4428518 Val_acc =  0.8469\n",
            "Iteration  4544 : Loss =  0.35028142  Acc:  0.87803334 Val_loss =  0.44290566 Val_acc =  0.8465\n",
            "Iteration  4545 : Loss =  0.35029164  Acc:  0.87825 Val_loss =  0.44288614 Val_acc =  0.8472\n",
            "Iteration  4546 : Loss =  0.35030264  Acc:  0.8778 Val_loss =  0.44296303 Val_acc =  0.8464\n",
            "Iteration  4547 : Loss =  0.35031024  Acc:  0.8782 Val_loss =  0.4429245 Val_acc =  0.8475\n",
            "Iteration  4548 : Loss =  0.35029948  Acc:  0.87773335 Val_loss =  0.44299057 Val_acc =  0.8464\n",
            "Iteration  4549 : Loss =  0.35026908  Acc:  0.8782167 Val_loss =  0.44291195 Val_acc =  0.8472\n",
            "Iteration  4550 : Loss =  0.35022402  Acc:  0.87805 Val_loss =  0.44292763 Val_acc =  0.8466\n",
            "Iteration  4551 : Loss =  0.35018778  Acc:  0.8781 Val_loss =  0.44287515 Val_acc =  0.8465\n",
            "Iteration  4552 : Loss =  0.35017502  Acc:  0.87806666 Val_loss =  0.4428796 Val_acc =  0.8465\n",
            "Iteration  4553 : Loss =  0.35018212  Acc:  0.87805 Val_loss =  0.44291857 Val_acc =  0.8467\n",
            "Iteration  4554 : Loss =  0.3501921  Acc:  0.87835 Val_loss =  0.44290712 Val_acc =  0.8471\n",
            "Iteration  4555 : Loss =  0.35018742  Acc:  0.87803334 Val_loss =  0.4429585 Val_acc =  0.8466\n",
            "Iteration  4556 : Loss =  0.35016614  Acc:  0.87831664 Val_loss =  0.44290927 Val_acc =  0.8468\n",
            "Iteration  4557 : Loss =  0.35013926  Acc:  0.878 Val_loss =  0.4429234 Val_acc =  0.8468\n",
            "Iteration  4558 : Loss =  0.35012278  Acc:  0.87796664 Val_loss =  0.44290957 Val_acc =  0.8463\n",
            "Iteration  4559 : Loss =  0.35012037  Acc:  0.8781667 Val_loss =  0.4429117 Val_acc =  0.8464\n",
            "Iteration  4560 : Loss =  0.35012263  Acc:  0.87805 Val_loss =  0.4429508 Val_acc =  0.8468\n",
            "Iteration  4561 : Loss =  0.35011798  Acc:  0.87835 Val_loss =  0.4429286 Val_acc =  0.8467\n",
            "Iteration  4562 : Loss =  0.35010272  Acc:  0.87803334 Val_loss =  0.44295585 Val_acc =  0.8468\n",
            "Iteration  4563 : Loss =  0.35008445  Acc:  0.87811667 Val_loss =  0.44292977 Val_acc =  0.8464\n",
            "Iteration  4564 : Loss =  0.350072  Acc:  0.87801665 Val_loss =  0.44293702 Val_acc =  0.8463\n",
            "Iteration  4565 : Loss =  0.35006744  Acc:  0.8781 Val_loss =  0.442953 Val_acc =  0.8467\n",
            "Iteration  4566 : Loss =  0.35006484  Acc:  0.8782167 Val_loss =  0.4429453 Val_acc =  0.8465\n",
            "Iteration  4567 : Loss =  0.35005748  Acc:  0.8781 Val_loss =  0.44297412 Val_acc =  0.8468\n",
            "Iteration  4568 : Loss =  0.35004473  Acc:  0.8781667 Val_loss =  0.44295278 Val_acc =  0.8464\n",
            "Iteration  4569 : Loss =  0.3500312  Acc:  0.87808335 Val_loss =  0.4429657 Val_acc =  0.8467\n",
            "Iteration  4570 : Loss =  0.35002148  Acc:  0.87808335 Val_loss =  0.442966 Val_acc =  0.8465\n",
            "Iteration  4571 : Loss =  0.35001576  Acc:  0.8781667 Val_loss =  0.44296578 Val_acc =  0.8465\n",
            "Iteration  4572 : Loss =  0.35001022  Acc:  0.8781 Val_loss =  0.4429881 Val_acc =  0.8467\n",
            "Iteration  4573 : Loss =  0.3500017  Acc:  0.8781667 Val_loss =  0.44297513 Val_acc =  0.8464\n",
            "Iteration  4574 : Loss =  0.34999052  Acc:  0.87806666 Val_loss =  0.44299185 Val_acc =  0.8467\n",
            "Iteration  4575 : Loss =  0.3499796  Acc:  0.87808335 Val_loss =  0.44298536 Val_acc =  0.8462\n",
            "Iteration  4576 : Loss =  0.34997103  Acc:  0.87806666 Val_loss =  0.44299003 Val_acc =  0.8462\n",
            "Iteration  4577 : Loss =  0.34996432  Acc:  0.87808335 Val_loss =  0.44300342 Val_acc =  0.8467\n",
            "Iteration  4578 : Loss =  0.34995723  Acc:  0.87815 Val_loss =  0.4429976 Val_acc =  0.8465\n",
            "Iteration  4579 : Loss =  0.3499484  Acc:  0.87808335 Val_loss =  0.44301456 Val_acc =  0.8467\n",
            "Iteration  4580 : Loss =  0.34993842  Acc:  0.87811667 Val_loss =  0.44300702 Val_acc =  0.8464\n",
            "Iteration  4581 : Loss =  0.3499288  Acc:  0.87808335 Val_loss =  0.44301564 Val_acc =  0.8464\n",
            "Iteration  4582 : Loss =  0.34992054  Acc:  0.87808335 Val_loss =  0.443021 Val_acc =  0.8465\n",
            "Iteration  4583 : Loss =  0.34991312  Acc:  0.87815 Val_loss =  0.4430207 Val_acc =  0.8464\n",
            "Iteration  4584 : Loss =  0.3499053  Acc:  0.87808335 Val_loss =  0.44303486 Val_acc =  0.8466\n",
            "Iteration  4585 : Loss =  0.34989658  Acc:  0.87813336 Val_loss =  0.44302955 Val_acc =  0.8464\n",
            "Iteration  4586 : Loss =  0.3498873  Acc:  0.87806666 Val_loss =  0.44304058 Val_acc =  0.8464\n",
            "Iteration  4587 : Loss =  0.3498783  Acc:  0.87808335 Val_loss =  0.44304103 Val_acc =  0.8463\n",
            "Iteration  4588 : Loss =  0.34987006  Acc:  0.87805 Val_loss =  0.44304487 Val_acc =  0.8463\n",
            "Iteration  4589 : Loss =  0.3498622  Acc:  0.87806666 Val_loss =  0.4430546 Val_acc =  0.8464\n",
            "Iteration  4590 : Loss =  0.3498541  Acc:  0.8781 Val_loss =  0.44305274 Val_acc =  0.8463\n",
            "Iteration  4591 : Loss =  0.3498455  Acc:  0.87808335 Val_loss =  0.44306415 Val_acc =  0.8464\n",
            "Iteration  4592 : Loss =  0.34983662  Acc:  0.87808335 Val_loss =  0.4430629 Val_acc =  0.8462\n",
            "Iteration  4593 : Loss =  0.34982792  Acc:  0.8781667 Val_loss =  0.44306967 Val_acc =  0.8463\n",
            "Iteration  4594 : Loss =  0.34981966  Acc:  0.87813336 Val_loss =  0.44307506 Val_acc =  0.8464\n",
            "Iteration  4595 : Loss =  0.34981155  Acc:  0.87811667 Val_loss =  0.44307655 Val_acc =  0.8462\n",
            "Iteration  4596 : Loss =  0.34980336  Acc:  0.8781 Val_loss =  0.44308627 Val_acc =  0.8465\n",
            "Iteration  4597 : Loss =  0.34979486  Acc:  0.87811667 Val_loss =  0.44308558 Val_acc =  0.8462\n",
            "Iteration  4598 : Loss =  0.34978625  Acc:  0.87813336 Val_loss =  0.44309404 Val_acc =  0.8465\n",
            "Iteration  4599 : Loss =  0.3497777  Acc:  0.87815 Val_loss =  0.44309634 Val_acc =  0.8463\n",
            "Iteration  4600 : Loss =  0.34976932  Acc:  0.8781667 Val_loss =  0.44310084 Val_acc =  0.8463\n",
            "Iteration  4601 : Loss =  0.3497611  Acc:  0.87813336 Val_loss =  0.4431078 Val_acc =  0.8463\n",
            "Iteration  4602 : Loss =  0.34975287  Acc:  0.8781 Val_loss =  0.44310898 Val_acc =  0.8461\n",
            "Iteration  4603 : Loss =  0.34974447  Acc:  0.8781 Val_loss =  0.44311747 Val_acc =  0.8464\n",
            "Iteration  4604 : Loss =  0.349736  Acc:  0.87811667 Val_loss =  0.4431187 Val_acc =  0.8462\n",
            "Iteration  4605 : Loss =  0.3497275  Acc:  0.8781833 Val_loss =  0.4431252 Val_acc =  0.8462\n",
            "Iteration  4606 : Loss =  0.34971914  Acc:  0.8782 Val_loss =  0.44312948 Val_acc =  0.8462\n",
            "Iteration  4607 : Loss =  0.34971085  Acc:  0.87813336 Val_loss =  0.4431329 Val_acc =  0.8461\n",
            "Iteration  4608 : Loss =  0.34970257  Acc:  0.8781833 Val_loss =  0.44314003 Val_acc =  0.8462\n",
            "Iteration  4609 : Loss =  0.3496942  Acc:  0.87815 Val_loss =  0.44314185 Val_acc =  0.8461\n",
            "Iteration  4610 : Loss =  0.34968582  Acc:  0.8781833 Val_loss =  0.44314903 Val_acc =  0.8462\n",
            "Iteration  4611 : Loss =  0.3496774  Acc:  0.87815 Val_loss =  0.44315177 Val_acc =  0.8461\n",
            "Iteration  4612 : Loss =  0.34966904  Acc:  0.8781833 Val_loss =  0.44315714 Val_acc =  0.8461\n",
            "Iteration  4613 : Loss =  0.34966075  Acc:  0.8781833 Val_loss =  0.4431622 Val_acc =  0.8461\n",
            "Iteration  4614 : Loss =  0.3496524  Acc:  0.87815 Val_loss =  0.44316554 Val_acc =  0.8461\n",
            "Iteration  4615 : Loss =  0.3496441  Acc:  0.8782167 Val_loss =  0.44317216 Val_acc =  0.8462\n",
            "Iteration  4616 : Loss =  0.34963575  Acc:  0.8781667 Val_loss =  0.4431748 Val_acc =  0.8461\n",
            "Iteration  4617 : Loss =  0.3496274  Acc:  0.8782167 Val_loss =  0.44318107 Val_acc =  0.8461\n",
            "Iteration  4618 : Loss =  0.34961903  Acc:  0.8782 Val_loss =  0.4431847 Val_acc =  0.8461\n",
            "Iteration  4619 : Loss =  0.34961072  Acc:  0.8782 Val_loss =  0.44318956 Val_acc =  0.8461\n",
            "Iteration  4620 : Loss =  0.3496024  Acc:  0.8782 Val_loss =  0.44319487 Val_acc =  0.8461\n",
            "Iteration  4621 : Loss =  0.3495941  Acc:  0.8782 Val_loss =  0.44319838 Val_acc =  0.8461\n",
            "Iteration  4622 : Loss =  0.34958574  Acc:  0.8782167 Val_loss =  0.4432045 Val_acc =  0.8461\n",
            "Iteration  4623 : Loss =  0.3495774  Acc:  0.8782167 Val_loss =  0.44320777 Val_acc =  0.8461\n",
            "Iteration  4624 : Loss =  0.34956908  Acc:  0.8782333 Val_loss =  0.44321346 Val_acc =  0.8461\n",
            "Iteration  4625 : Loss =  0.3495608  Acc:  0.8782333 Val_loss =  0.44321764 Val_acc =  0.8461\n",
            "Iteration  4626 : Loss =  0.34955248  Acc:  0.8782333 Val_loss =  0.44322225 Val_acc =  0.8461\n",
            "Iteration  4627 : Loss =  0.34954417  Acc:  0.8782333 Val_loss =  0.44322753 Val_acc =  0.8461\n",
            "Iteration  4628 : Loss =  0.34953588  Acc:  0.87825 Val_loss =  0.44323134 Val_acc =  0.8461\n",
            "Iteration  4629 : Loss =  0.34952757  Acc:  0.87825 Val_loss =  0.44323707 Val_acc =  0.8461\n",
            "Iteration  4630 : Loss =  0.34951925  Acc:  0.8782667 Val_loss =  0.44324076 Val_acc =  0.8461\n",
            "Iteration  4631 : Loss =  0.34951094  Acc:  0.87825 Val_loss =  0.4432462 Val_acc =  0.8461\n",
            "Iteration  4632 : Loss =  0.34950262  Acc:  0.87825 Val_loss =  0.44325054 Val_acc =  0.8461\n",
            "Iteration  4633 : Loss =  0.34949434  Acc:  0.87825 Val_loss =  0.44325528 Val_acc =  0.8461\n",
            "Iteration  4634 : Loss =  0.34948605  Acc:  0.8782667 Val_loss =  0.4432603 Val_acc =  0.8461\n",
            "Iteration  4635 : Loss =  0.34947774  Acc:  0.8782667 Val_loss =  0.4432644 Val_acc =  0.8461\n",
            "Iteration  4636 : Loss =  0.34946945  Acc:  0.8782833 Val_loss =  0.44326982 Val_acc =  0.8461\n",
            "Iteration  4637 : Loss =  0.3494612  Acc:  0.8782833 Val_loss =  0.44327387 Val_acc =  0.8462\n",
            "Iteration  4638 : Loss =  0.34945285  Acc:  0.8782833 Val_loss =  0.44327915 Val_acc =  0.8462\n",
            "Iteration  4639 : Loss =  0.3494446  Acc:  0.8782667 Val_loss =  0.4432835 Val_acc =  0.8462\n",
            "Iteration  4640 : Loss =  0.34943628  Acc:  0.8782833 Val_loss =  0.44328827 Val_acc =  0.8462\n",
            "Iteration  4641 : Loss =  0.34942803  Acc:  0.8782833 Val_loss =  0.44329327 Val_acc =  0.8462\n",
            "Iteration  4642 : Loss =  0.3494197  Acc:  0.8782667 Val_loss =  0.44329756 Val_acc =  0.8462\n",
            "Iteration  4643 : Loss =  0.34941146  Acc:  0.8782667 Val_loss =  0.44330284 Val_acc =  0.8462\n",
            "Iteration  4644 : Loss =  0.3494032  Acc:  0.8782667 Val_loss =  0.44330704 Val_acc =  0.8462\n",
            "Iteration  4645 : Loss =  0.34939492  Acc:  0.8782667 Val_loss =  0.4433122 Val_acc =  0.8462\n",
            "Iteration  4646 : Loss =  0.34938666  Acc:  0.87825 Val_loss =  0.4433167 Val_acc =  0.8463\n",
            "Iteration  4647 : Loss =  0.34937838  Acc:  0.8782667 Val_loss =  0.44332153 Val_acc =  0.8463\n",
            "Iteration  4648 : Loss =  0.34937012  Acc:  0.8782667 Val_loss =  0.44332632 Val_acc =  0.8463\n",
            "Iteration  4649 : Loss =  0.34936184  Acc:  0.8782833 Val_loss =  0.44333085 Val_acc =  0.8463\n",
            "Iteration  4650 : Loss =  0.34935358  Acc:  0.8782833 Val_loss =  0.44333595 Val_acc =  0.8463\n",
            "Iteration  4651 : Loss =  0.34934536  Acc:  0.8783 Val_loss =  0.44334033 Val_acc =  0.8463\n",
            "Iteration  4652 : Loss =  0.34933704  Acc:  0.87831664 Val_loss =  0.4433454 Val_acc =  0.8463\n",
            "Iteration  4653 : Loss =  0.34932882  Acc:  0.8783 Val_loss =  0.4433499 Val_acc =  0.8463\n",
            "Iteration  4654 : Loss =  0.34932056  Acc:  0.87831664 Val_loss =  0.44335485 Val_acc =  0.8463\n",
            "Iteration  4655 : Loss =  0.3493123  Acc:  0.87831664 Val_loss =  0.44335952 Val_acc =  0.8463\n",
            "Iteration  4656 : Loss =  0.34930405  Acc:  0.87831664 Val_loss =  0.44336426 Val_acc =  0.8463\n",
            "Iteration  4657 : Loss =  0.3492958  Acc:  0.87831664 Val_loss =  0.44336915 Val_acc =  0.8463\n",
            "Iteration  4658 : Loss =  0.34928757  Acc:  0.8783 Val_loss =  0.44337374 Val_acc =  0.8463\n",
            "Iteration  4659 : Loss =  0.34927928  Acc:  0.8783 Val_loss =  0.44337875 Val_acc =  0.8463\n",
            "Iteration  4660 : Loss =  0.3492711  Acc:  0.87831664 Val_loss =  0.4433833 Val_acc =  0.8463\n",
            "Iteration  4661 : Loss =  0.34926283  Acc:  0.8783 Val_loss =  0.44338828 Val_acc =  0.8463\n",
            "Iteration  4662 : Loss =  0.3492546  Acc:  0.87831664 Val_loss =  0.44339287 Val_acc =  0.8463\n",
            "Iteration  4663 : Loss =  0.34924635  Acc:  0.87835 Val_loss =  0.44339776 Val_acc =  0.8463\n",
            "Iteration  4664 : Loss =  0.34923816  Acc:  0.87835 Val_loss =  0.44340253 Val_acc =  0.8463\n",
            "Iteration  4665 : Loss =  0.3492299  Acc:  0.87835 Val_loss =  0.44340727 Val_acc =  0.8463\n",
            "Iteration  4666 : Loss =  0.34922168  Acc:  0.87833333 Val_loss =  0.44341215 Val_acc =  0.8463\n",
            "Iteration  4667 : Loss =  0.34921345  Acc:  0.87831664 Val_loss =  0.44341683 Val_acc =  0.8463\n",
            "Iteration  4668 : Loss =  0.3492052  Acc:  0.87833333 Val_loss =  0.44342178 Val_acc =  0.8464\n",
            "Iteration  4669 : Loss =  0.34919697  Acc:  0.87831664 Val_loss =  0.44342643 Val_acc =  0.8464\n",
            "Iteration  4670 : Loss =  0.3491888  Acc:  0.87831664 Val_loss =  0.44343135 Val_acc =  0.8464\n",
            "Iteration  4671 : Loss =  0.34918058  Acc:  0.87831664 Val_loss =  0.44343603 Val_acc =  0.8464\n",
            "Iteration  4672 : Loss =  0.34917235  Acc:  0.87831664 Val_loss =  0.4434409 Val_acc =  0.8464\n",
            "Iteration  4673 : Loss =  0.34916413  Acc:  0.87833333 Val_loss =  0.44344574 Val_acc =  0.8464\n",
            "Iteration  4674 : Loss =  0.34915593  Acc:  0.87833333 Val_loss =  0.44345048 Val_acc =  0.8464\n",
            "Iteration  4675 : Loss =  0.3491477  Acc:  0.87835 Val_loss =  0.44345537 Val_acc =  0.8464\n",
            "Iteration  4676 : Loss =  0.3491395  Acc:  0.87835 Val_loss =  0.44346005 Val_acc =  0.8464\n",
            "Iteration  4677 : Loss =  0.34913132  Acc:  0.87835 Val_loss =  0.44346502 Val_acc =  0.8464\n",
            "Iteration  4678 : Loss =  0.34912312  Acc:  0.87835 Val_loss =  0.44346973 Val_acc =  0.8464\n",
            "Iteration  4679 : Loss =  0.3491149  Acc:  0.87836665 Val_loss =  0.44347465 Val_acc =  0.8464\n",
            "Iteration  4680 : Loss =  0.34910667  Acc:  0.87836665 Val_loss =  0.4434794 Val_acc =  0.8464\n",
            "Iteration  4681 : Loss =  0.3490985  Acc:  0.87836665 Val_loss =  0.44348428 Val_acc =  0.8464\n",
            "Iteration  4682 : Loss =  0.3490903  Acc:  0.87836665 Val_loss =  0.44348907 Val_acc =  0.8464\n",
            "Iteration  4683 : Loss =  0.34908208  Acc:  0.87836665 Val_loss =  0.44349393 Val_acc =  0.8464\n",
            "Iteration  4684 : Loss =  0.3490739  Acc:  0.87836665 Val_loss =  0.44349882 Val_acc =  0.8465\n",
            "Iteration  4685 : Loss =  0.34906572  Acc:  0.87836665 Val_loss =  0.44350356 Val_acc =  0.8465\n",
            "Iteration  4686 : Loss =  0.34905756  Acc:  0.87836665 Val_loss =  0.4435085 Val_acc =  0.8465\n",
            "Iteration  4687 : Loss =  0.3490494  Acc:  0.87836665 Val_loss =  0.44351327 Val_acc =  0.8465\n",
            "Iteration  4688 : Loss =  0.34904113  Acc:  0.87836665 Val_loss =  0.44351816 Val_acc =  0.8465\n",
            "Iteration  4689 : Loss =  0.34903297  Acc:  0.87836665 Val_loss =  0.44352296 Val_acc =  0.8464\n",
            "Iteration  4690 : Loss =  0.3490248  Acc:  0.87841666 Val_loss =  0.44352788 Val_acc =  0.8464\n",
            "Iteration  4691 : Loss =  0.34901664  Acc:  0.87843335 Val_loss =  0.4435327 Val_acc =  0.8464\n",
            "Iteration  4692 : Loss =  0.34900847  Acc:  0.87843335 Val_loss =  0.44353756 Val_acc =  0.8464\n",
            "Iteration  4693 : Loss =  0.3490003  Acc:  0.87843335 Val_loss =  0.44354242 Val_acc =  0.8464\n",
            "Iteration  4694 : Loss =  0.3489921  Acc:  0.87845 Val_loss =  0.44354728 Val_acc =  0.8464\n",
            "Iteration  4695 : Loss =  0.34898394  Acc:  0.87845 Val_loss =  0.44355214 Val_acc =  0.8464\n",
            "Iteration  4696 : Loss =  0.34897578  Acc:  0.87845 Val_loss =  0.44355702 Val_acc =  0.8464\n",
            "Iteration  4697 : Loss =  0.34896764  Acc:  0.87845 Val_loss =  0.4435619 Val_acc =  0.8464\n",
            "Iteration  4698 : Loss =  0.34895945  Acc:  0.87843335 Val_loss =  0.44356674 Val_acc =  0.8464\n",
            "Iteration  4699 : Loss =  0.34895128  Acc:  0.87845 Val_loss =  0.4435717 Val_acc =  0.8464\n",
            "Iteration  4700 : Loss =  0.34894317  Acc:  0.87843335 Val_loss =  0.44357646 Val_acc =  0.8464\n",
            "Iteration  4701 : Loss =  0.34893495  Acc:  0.87843335 Val_loss =  0.44358143 Val_acc =  0.8464\n",
            "Iteration  4702 : Loss =  0.3489268  Acc:  0.87843335 Val_loss =  0.44358623 Val_acc =  0.8464\n",
            "Iteration  4703 : Loss =  0.34891868  Acc:  0.87841666 Val_loss =  0.44359115 Val_acc =  0.8464\n",
            "Iteration  4704 : Loss =  0.34891054  Acc:  0.87841666 Val_loss =  0.44359604 Val_acc =  0.8464\n",
            "Iteration  4705 : Loss =  0.34890234  Acc:  0.87841666 Val_loss =  0.4436009 Val_acc =  0.8464\n",
            "Iteration  4706 : Loss =  0.34889424  Acc:  0.87841666 Val_loss =  0.44360587 Val_acc =  0.8464\n",
            "Iteration  4707 : Loss =  0.34888607  Acc:  0.87841666 Val_loss =  0.4436107 Val_acc =  0.8464\n",
            "Iteration  4708 : Loss =  0.34887797  Acc:  0.8784 Val_loss =  0.44361562 Val_acc =  0.8464\n",
            "Iteration  4709 : Loss =  0.3488698  Acc:  0.8784 Val_loss =  0.4436205 Val_acc =  0.8464\n",
            "Iteration  4710 : Loss =  0.34886166  Acc:  0.87838334 Val_loss =  0.4436254 Val_acc =  0.8464\n",
            "Iteration  4711 : Loss =  0.34885356  Acc:  0.87838334 Val_loss =  0.44363028 Val_acc =  0.8464\n",
            "Iteration  4712 : Loss =  0.3488454  Acc:  0.8784 Val_loss =  0.4436352 Val_acc =  0.8464\n",
            "Iteration  4713 : Loss =  0.3488373  Acc:  0.87841666 Val_loss =  0.44364014 Val_acc =  0.8464\n",
            "Iteration  4714 : Loss =  0.34882912  Acc:  0.87841666 Val_loss =  0.44364506 Val_acc =  0.8464\n",
            "Iteration  4715 : Loss =  0.348821  Acc:  0.87841666 Val_loss =  0.44364995 Val_acc =  0.8464\n",
            "Iteration  4716 : Loss =  0.34881288  Acc:  0.8784 Val_loss =  0.4436549 Val_acc =  0.8464\n",
            "Iteration  4717 : Loss =  0.34880474  Acc:  0.8784 Val_loss =  0.44365975 Val_acc =  0.8463\n",
            "Iteration  4718 : Loss =  0.34879667  Acc:  0.87841666 Val_loss =  0.44366476 Val_acc =  0.8463\n",
            "Iteration  4719 : Loss =  0.34878853  Acc:  0.87841666 Val_loss =  0.44366962 Val_acc =  0.8463\n",
            "Iteration  4720 : Loss =  0.3487804  Acc:  0.87841666 Val_loss =  0.44367462 Val_acc =  0.8463\n",
            "Iteration  4721 : Loss =  0.3487723  Acc:  0.87843335 Val_loss =  0.44367948 Val_acc =  0.8463\n",
            "Iteration  4722 : Loss =  0.34876418  Acc:  0.87843335 Val_loss =  0.44368443 Val_acc =  0.8463\n",
            "Iteration  4723 : Loss =  0.34875607  Acc:  0.87843335 Val_loss =  0.44368935 Val_acc =  0.8463\n",
            "Iteration  4724 : Loss =  0.34874797  Acc:  0.87843335 Val_loss =  0.44369432 Val_acc =  0.8463\n",
            "Iteration  4725 : Loss =  0.34873983  Acc:  0.87843335 Val_loss =  0.4436992 Val_acc =  0.8463\n",
            "Iteration  4726 : Loss =  0.34873176  Acc:  0.87845 Val_loss =  0.44370416 Val_acc =  0.8463\n",
            "Iteration  4727 : Loss =  0.34872362  Acc:  0.87845 Val_loss =  0.44370914 Val_acc =  0.8463\n",
            "Iteration  4728 : Loss =  0.34871557  Acc:  0.87846667 Val_loss =  0.4437141 Val_acc =  0.8463\n",
            "Iteration  4729 : Loss =  0.3487074  Acc:  0.87845 Val_loss =  0.44371903 Val_acc =  0.8463\n",
            "Iteration  4730 : Loss =  0.34869936  Acc:  0.87845 Val_loss =  0.44372398 Val_acc =  0.8462\n",
            "Iteration  4731 : Loss =  0.34869125  Acc:  0.87846667 Val_loss =  0.4437289 Val_acc =  0.8462\n",
            "Iteration  4732 : Loss =  0.34868315  Acc:  0.87845 Val_loss =  0.4437339 Val_acc =  0.8462\n",
            "Iteration  4733 : Loss =  0.34867507  Acc:  0.87846667 Val_loss =  0.44373888 Val_acc =  0.8462\n",
            "Iteration  4734 : Loss =  0.348667  Acc:  0.87846667 Val_loss =  0.4437438 Val_acc =  0.8462\n",
            "Iteration  4735 : Loss =  0.34865892  Acc:  0.87846667 Val_loss =  0.44374874 Val_acc =  0.8461\n",
            "Iteration  4736 : Loss =  0.34865078  Acc:  0.87848336 Val_loss =  0.44375375 Val_acc =  0.8461\n",
            "Iteration  4737 : Loss =  0.34864274  Acc:  0.8785 Val_loss =  0.4437587 Val_acc =  0.8461\n",
            "Iteration  4738 : Loss =  0.34863463  Acc:  0.8785 Val_loss =  0.44376367 Val_acc =  0.8461\n",
            "Iteration  4739 : Loss =  0.34862655  Acc:  0.8785 Val_loss =  0.44376865 Val_acc =  0.8461\n",
            "Iteration  4740 : Loss =  0.3486185  Acc:  0.8785167 Val_loss =  0.44377363 Val_acc =  0.8461\n",
            "Iteration  4741 : Loss =  0.34861046  Acc:  0.8785167 Val_loss =  0.4437786 Val_acc =  0.8461\n",
            "Iteration  4742 : Loss =  0.34860235  Acc:  0.8785167 Val_loss =  0.44378364 Val_acc =  0.8461\n",
            "Iteration  4743 : Loss =  0.3485943  Acc:  0.8785167 Val_loss =  0.4437886 Val_acc =  0.8461\n",
            "Iteration  4744 : Loss =  0.34858623  Acc:  0.8785167 Val_loss =  0.4437936 Val_acc =  0.8461\n",
            "Iteration  4745 : Loss =  0.34857816  Acc:  0.8785167 Val_loss =  0.44379854 Val_acc =  0.8461\n",
            "Iteration  4746 : Loss =  0.34857008  Acc:  0.8785333 Val_loss =  0.44380358 Val_acc =  0.8461\n",
            "Iteration  4747 : Loss =  0.34856203  Acc:  0.8785167 Val_loss =  0.4438085 Val_acc =  0.8461\n",
            "Iteration  4748 : Loss =  0.348554  Acc:  0.8785333 Val_loss =  0.44381353 Val_acc =  0.8461\n",
            "Iteration  4749 : Loss =  0.3485459  Acc:  0.8785333 Val_loss =  0.44381845 Val_acc =  0.8461\n",
            "Iteration  4750 : Loss =  0.34853786  Acc:  0.8785333 Val_loss =  0.44382355 Val_acc =  0.8461\n",
            "Iteration  4751 : Loss =  0.34852982  Acc:  0.87855 Val_loss =  0.44382852 Val_acc =  0.8461\n",
            "Iteration  4752 : Loss =  0.34852174  Acc:  0.87855 Val_loss =  0.4438336 Val_acc =  0.846\n",
            "Iteration  4753 : Loss =  0.34851366  Acc:  0.8785167 Val_loss =  0.44383848 Val_acc =  0.846\n",
            "Iteration  4754 : Loss =  0.34850568  Acc:  0.8785667 Val_loss =  0.4438436 Val_acc =  0.846\n",
            "Iteration  4755 : Loss =  0.34849763  Acc:  0.8785333 Val_loss =  0.44384852 Val_acc =  0.8461\n",
            "Iteration  4756 : Loss =  0.34848955  Acc:  0.8785333 Val_loss =  0.44385368 Val_acc =  0.8461\n",
            "Iteration  4757 : Loss =  0.3484815  Acc:  0.8785167 Val_loss =  0.4438585 Val_acc =  0.8461\n",
            "Iteration  4758 : Loss =  0.3484735  Acc:  0.8785167 Val_loss =  0.44386372 Val_acc =  0.8461\n",
            "Iteration  4759 : Loss =  0.34846547  Acc:  0.8785333 Val_loss =  0.44386855 Val_acc =  0.8461\n",
            "Iteration  4760 : Loss =  0.3484574  Acc:  0.8785333 Val_loss =  0.4438738 Val_acc =  0.8461\n",
            "Iteration  4761 : Loss =  0.3484494  Acc:  0.8785333 Val_loss =  0.4438785 Val_acc =  0.8461\n",
            "Iteration  4762 : Loss =  0.34844133  Acc:  0.8785333 Val_loss =  0.44388393 Val_acc =  0.8461\n",
            "Iteration  4763 : Loss =  0.34843335  Acc:  0.87855 Val_loss =  0.44388852 Val_acc =  0.8461\n",
            "Iteration  4764 : Loss =  0.3484253  Acc:  0.87855 Val_loss =  0.4438941 Val_acc =  0.8461\n",
            "Iteration  4765 : Loss =  0.34841728  Acc:  0.87855 Val_loss =  0.4438985 Val_acc =  0.8461\n",
            "Iteration  4766 : Loss =  0.34840924  Acc:  0.87855 Val_loss =  0.4439043 Val_acc =  0.8461\n",
            "Iteration  4767 : Loss =  0.34840125  Acc:  0.87855 Val_loss =  0.4439084 Val_acc =  0.8461\n",
            "Iteration  4768 : Loss =  0.34839323  Acc:  0.8785167 Val_loss =  0.44391465 Val_acc =  0.8461\n",
            "Iteration  4769 : Loss =  0.3483852  Acc:  0.87855 Val_loss =  0.44391826 Val_acc =  0.8461\n",
            "Iteration  4770 : Loss =  0.34837723  Acc:  0.87855 Val_loss =  0.4439251 Val_acc =  0.8461\n",
            "Iteration  4771 : Loss =  0.34836924  Acc:  0.8785167 Val_loss =  0.44392803 Val_acc =  0.846\n",
            "Iteration  4772 : Loss =  0.34836125  Acc:  0.87855 Val_loss =  0.44393578 Val_acc =  0.8462\n",
            "Iteration  4773 : Loss =  0.3483534  Acc:  0.87855 Val_loss =  0.4439376 Val_acc =  0.846\n",
            "Iteration  4774 : Loss =  0.34834543  Acc:  0.8786 Val_loss =  0.443947 Val_acc =  0.8463\n",
            "Iteration  4775 : Loss =  0.3483377  Acc:  0.8785333 Val_loss =  0.443947 Val_acc =  0.846\n",
            "Iteration  4776 : Loss =  0.34833  Acc:  0.8786833 Val_loss =  0.443959 Val_acc =  0.8463\n",
            "Iteration  4777 : Loss =  0.34832254  Acc:  0.8786833 Val_loss =  0.44395626 Val_acc =  0.8461\n",
            "Iteration  4778 : Loss =  0.34831536  Acc:  0.87873334 Val_loss =  0.44397286 Val_acc =  0.8463\n",
            "Iteration  4779 : Loss =  0.34830874  Acc:  0.87866664 Val_loss =  0.44396582 Val_acc =  0.8461\n",
            "Iteration  4780 : Loss =  0.34830305  Acc:  0.87865 Val_loss =  0.44399044 Val_acc =  0.8465\n",
            "Iteration  4781 : Loss =  0.34829873  Acc:  0.87875 Val_loss =  0.44397736 Val_acc =  0.8462\n",
            "Iteration  4782 : Loss =  0.3482966  Acc:  0.8786833 Val_loss =  0.44401646 Val_acc =  0.8464\n",
            "Iteration  4783 : Loss =  0.3482979  Acc:  0.8788 Val_loss =  0.4439955 Val_acc =  0.8463\n",
            "Iteration  4784 : Loss =  0.34830335  Acc:  0.87846667 Val_loss =  0.44405928 Val_acc =  0.8463\n",
            "Iteration  4785 : Loss =  0.34831455  Acc:  0.8789833 Val_loss =  0.44402853 Val_acc =  0.8467\n",
            "Iteration  4786 : Loss =  0.34832802  Acc:  0.8785167 Val_loss =  0.44412315 Val_acc =  0.8464\n",
            "Iteration  4787 : Loss =  0.3483402  Acc:  0.8788667 Val_loss =  0.4440708 Val_acc =  0.8468\n",
            "Iteration  4788 : Loss =  0.34833562  Acc:  0.8786 Val_loss =  0.44416463 Val_acc =  0.8461\n",
            "Iteration  4789 : Loss =  0.34830984  Acc:  0.87885 Val_loss =  0.44406754 Val_acc =  0.8466\n",
            "Iteration  4790 : Loss =  0.34826338  Acc:  0.87845 Val_loss =  0.4441041 Val_acc =  0.8462\n",
            "Iteration  4791 : Loss =  0.34822085  Acc:  0.87883335 Val_loss =  0.4440273 Val_acc =  0.8462\n",
            "Iteration  4792 : Loss =  0.34820172  Acc:  0.8786333 Val_loss =  0.4440351 Val_acc =  0.846\n",
            "Iteration  4793 : Loss =  0.34820735  Acc:  0.8786833 Val_loss =  0.44407177 Val_acc =  0.8464\n",
            "Iteration  4794 : Loss =  0.34822083  Acc:  0.87878335 Val_loss =  0.444056 Val_acc =  0.8464\n",
            "Iteration  4795 : Loss =  0.34822142  Acc:  0.87846667 Val_loss =  0.44412667 Val_acc =  0.8464\n",
            "Iteration  4796 : Loss =  0.34820268  Acc:  0.87883335 Val_loss =  0.4440635 Val_acc =  0.8465\n",
            "Iteration  4797 : Loss =  0.34817415  Acc:  0.8786833 Val_loss =  0.44409072 Val_acc =  0.8465\n",
            "Iteration  4798 : Loss =  0.34815443  Acc:  0.87865 Val_loss =  0.44406432 Val_acc =  0.846\n",
            "Iteration  4799 : Loss =  0.34815082  Acc:  0.87873334 Val_loss =  0.4440665 Val_acc =  0.8461\n",
            "Iteration  4800 : Loss =  0.3481549  Acc:  0.87873334 Val_loss =  0.44411328 Val_acc =  0.8464\n",
            "Iteration  4801 : Loss =  0.3481531  Acc:  0.87888336 Val_loss =  0.44408348 Val_acc =  0.8462\n",
            "Iteration  4802 : Loss =  0.34813926  Acc:  0.8787 Val_loss =  0.44412413 Val_acc =  0.8464\n",
            "Iteration  4803 : Loss =  0.34812024  Acc:  0.87876666 Val_loss =  0.44408727 Val_acc =  0.8461\n",
            "Iteration  4804 : Loss =  0.3481067  Acc:  0.87866664 Val_loss =  0.44409844 Val_acc =  0.8461\n",
            "Iteration  4805 : Loss =  0.34810218  Acc:  0.8788 Val_loss =  0.44411522 Val_acc =  0.8464\n",
            "Iteration  4806 : Loss =  0.348101  Acc:  0.8788667 Val_loss =  0.44410333 Val_acc =  0.8462\n",
            "Iteration  4807 : Loss =  0.34809512  Acc:  0.87871665 Val_loss =  0.4441415 Val_acc =  0.8464\n",
            "Iteration  4808 : Loss =  0.348083  Acc:  0.87883335 Val_loss =  0.4441127 Val_acc =  0.8461\n",
            "Iteration  4809 : Loss =  0.3480692  Acc:  0.87881666 Val_loss =  0.44413126 Val_acc =  0.8463\n",
            "Iteration  4810 : Loss =  0.34805945  Acc:  0.87875 Val_loss =  0.44412926 Val_acc =  0.8462\n",
            "Iteration  4811 : Loss =  0.34805435  Acc:  0.8787 Val_loss =  0.44412774 Val_acc =  0.846\n",
            "Iteration  4812 : Loss =  0.34804982  Acc:  0.87876666 Val_loss =  0.44415575 Val_acc =  0.8464\n",
            "Iteration  4813 : Loss =  0.34804213  Acc:  0.87878335 Val_loss =  0.4441377 Val_acc =  0.8461\n",
            "Iteration  4814 : Loss =  0.34803125  Acc:  0.87876666 Val_loss =  0.44416016 Val_acc =  0.8464\n",
            "Iteration  4815 : Loss =  0.3480205  Acc:  0.87873334 Val_loss =  0.44415006 Val_acc =  0.846\n",
            "Iteration  4816 : Loss =  0.34801245  Acc:  0.87873334 Val_loss =  0.44415587 Val_acc =  0.846\n",
            "Iteration  4817 : Loss =  0.34800637  Acc:  0.87883335 Val_loss =  0.4441721 Val_acc =  0.8463\n",
            "Iteration  4818 : Loss =  0.3480001  Acc:  0.87876666 Val_loss =  0.444163 Val_acc =  0.846\n",
            "Iteration  4819 : Loss =  0.34799173  Acc:  0.87875 Val_loss =  0.44418496 Val_acc =  0.8464\n",
            "Iteration  4820 : Loss =  0.3479821  Acc:  0.87873334 Val_loss =  0.44417384 Val_acc =  0.846\n",
            "Iteration  4821 : Loss =  0.34797293  Acc:  0.87873334 Val_loss =  0.44418487 Val_acc =  0.8462\n",
            "Iteration  4822 : Loss =  0.3479653  Acc:  0.87873334 Val_loss =  0.44419122 Val_acc =  0.8463\n",
            "Iteration  4823 : Loss =  0.3479586  Acc:  0.87875 Val_loss =  0.44418895 Val_acc =  0.846\n",
            "Iteration  4824 : Loss =  0.34795135  Acc:  0.87881666 Val_loss =  0.44420722 Val_acc =  0.8464\n",
            "Iteration  4825 : Loss =  0.34794304  Acc:  0.87875 Val_loss =  0.44419882 Val_acc =  0.846\n",
            "Iteration  4826 : Loss =  0.34793425  Acc:  0.8788 Val_loss =  0.4442128 Val_acc =  0.8463\n",
            "Iteration  4827 : Loss =  0.34792578  Acc:  0.87873334 Val_loss =  0.4442128 Val_acc =  0.8461\n",
            "Iteration  4828 : Loss =  0.34791812  Acc:  0.87875 Val_loss =  0.44421625 Val_acc =  0.846\n",
            "Iteration  4829 : Loss =  0.34791094  Acc:  0.87881666 Val_loss =  0.44422892 Val_acc =  0.8463\n",
            "Iteration  4830 : Loss =  0.34790337  Acc:  0.87876666 Val_loss =  0.44422475 Val_acc =  0.846\n",
            "Iteration  4831 : Loss =  0.34789523  Acc:  0.87883335 Val_loss =  0.44423905 Val_acc =  0.8463\n",
            "Iteration  4832 : Loss =  0.34788686  Acc:  0.87878335 Val_loss =  0.44423658 Val_acc =  0.846\n",
            "Iteration  4833 : Loss =  0.34787872  Acc:  0.87873334 Val_loss =  0.44424424 Val_acc =  0.8461\n",
            "Iteration  4834 : Loss =  0.34787104  Acc:  0.87875 Val_loss =  0.44425118 Val_acc =  0.8462\n",
            "Iteration  4835 : Loss =  0.34786355  Acc:  0.87876666 Val_loss =  0.44425142 Val_acc =  0.846\n",
            "Iteration  4836 : Loss =  0.34785587  Acc:  0.87878335 Val_loss =  0.44426367 Val_acc =  0.8463\n",
            "Iteration  4837 : Loss =  0.34784788  Acc:  0.87876666 Val_loss =  0.44426167 Val_acc =  0.846\n",
            "Iteration  4838 : Loss =  0.34783977  Acc:  0.87876666 Val_loss =  0.44427162 Val_acc =  0.8463\n",
            "Iteration  4839 : Loss =  0.3478318  Acc:  0.87875 Val_loss =  0.4442743 Val_acc =  0.8461\n",
            "Iteration  4840 : Loss =  0.34782407  Acc:  0.87873334 Val_loss =  0.4442785 Val_acc =  0.8459\n",
            "Iteration  4841 : Loss =  0.3478164  Acc:  0.87876666 Val_loss =  0.4442874 Val_acc =  0.8462\n",
            "Iteration  4842 : Loss =  0.34780866  Acc:  0.8788 Val_loss =  0.4442876 Val_acc =  0.8459\n",
            "Iteration  4843 : Loss =  0.3478008  Acc:  0.87876666 Val_loss =  0.4442978 Val_acc =  0.8462\n",
            "Iteration  4844 : Loss =  0.34779283  Acc:  0.87876666 Val_loss =  0.44429874 Val_acc =  0.8459\n",
            "Iteration  4845 : Loss =  0.34778494  Acc:  0.87873334 Val_loss =  0.4443058 Val_acc =  0.846\n",
            "Iteration  4846 : Loss =  0.34777713  Acc:  0.87873334 Val_loss =  0.44431123 Val_acc =  0.846\n",
            "Iteration  4847 : Loss =  0.3477694  Acc:  0.87875 Val_loss =  0.44431415 Val_acc =  0.8459\n",
            "Iteration  4848 : Loss =  0.34776166  Acc:  0.87876666 Val_loss =  0.4443229 Val_acc =  0.8462\n",
            "Iteration  4849 : Loss =  0.34775385  Acc:  0.87876666 Val_loss =  0.44432417 Val_acc =  0.8459\n",
            "Iteration  4850 : Loss =  0.34774595  Acc:  0.87875 Val_loss =  0.4443325 Val_acc =  0.8461\n",
            "Iteration  4851 : Loss =  0.34773812  Acc:  0.87878335 Val_loss =  0.44433564 Val_acc =  0.846\n",
            "Iteration  4852 : Loss =  0.34773034  Acc:  0.87878335 Val_loss =  0.44434112 Val_acc =  0.846\n",
            "Iteration  4853 : Loss =  0.34772256  Acc:  0.87878335 Val_loss =  0.44434747 Val_acc =  0.846\n",
            "Iteration  4854 : Loss =  0.3477148  Acc:  0.87876666 Val_loss =  0.4443504 Val_acc =  0.8459\n",
            "Iteration  4855 : Loss =  0.347707  Acc:  0.8788 Val_loss =  0.44435835 Val_acc =  0.8461\n",
            "Iteration  4856 : Loss =  0.34769922  Acc:  0.87878335 Val_loss =  0.44436085 Val_acc =  0.8459\n",
            "Iteration  4857 : Loss =  0.34769142  Acc:  0.87878335 Val_loss =  0.4443679 Val_acc =  0.846\n",
            "Iteration  4858 : Loss =  0.3476836  Acc:  0.87878335 Val_loss =  0.4443722 Val_acc =  0.846\n",
            "Iteration  4859 : Loss =  0.34767577  Acc:  0.87881666 Val_loss =  0.44437706 Val_acc =  0.846\n",
            "Iteration  4860 : Loss =  0.34766802  Acc:  0.8788 Val_loss =  0.4443835 Val_acc =  0.846\n",
            "Iteration  4861 : Loss =  0.34766027  Acc:  0.87881666 Val_loss =  0.4443868 Val_acc =  0.8458\n",
            "Iteration  4862 : Loss =  0.3476525  Acc:  0.87881666 Val_loss =  0.444394 Val_acc =  0.8459\n",
            "Iteration  4863 : Loss =  0.34764472  Acc:  0.87883335 Val_loss =  0.44439745 Val_acc =  0.8459\n",
            "Iteration  4864 : Loss =  0.3476369  Acc:  0.8788 Val_loss =  0.44440365 Val_acc =  0.8459\n",
            "Iteration  4865 : Loss =  0.34762916  Acc:  0.8788 Val_loss =  0.44440854 Val_acc =  0.8459\n",
            "Iteration  4866 : Loss =  0.34762138  Acc:  0.87881666 Val_loss =  0.44441327 Val_acc =  0.8459\n",
            "Iteration  4867 : Loss =  0.34761363  Acc:  0.87881666 Val_loss =  0.4444196 Val_acc =  0.8459\n",
            "Iteration  4868 : Loss =  0.34760585  Acc:  0.87883335 Val_loss =  0.44442335 Val_acc =  0.8459\n",
            "Iteration  4869 : Loss =  0.3475981  Acc:  0.87881666 Val_loss =  0.44443 Val_acc =  0.8459\n",
            "Iteration  4870 : Loss =  0.34759036  Acc:  0.87881666 Val_loss =  0.444434 Val_acc =  0.8459\n",
            "Iteration  4871 : Loss =  0.34758255  Acc:  0.8788 Val_loss =  0.44443986 Val_acc =  0.8459\n",
            "Iteration  4872 : Loss =  0.3475748  Acc:  0.87881666 Val_loss =  0.44444492 Val_acc =  0.8459\n",
            "Iteration  4873 : Loss =  0.34756705  Acc:  0.87883335 Val_loss =  0.4444497 Val_acc =  0.8459\n",
            "Iteration  4874 : Loss =  0.3475593  Acc:  0.8788667 Val_loss =  0.44445577 Val_acc =  0.8459\n",
            "Iteration  4875 : Loss =  0.34755155  Acc:  0.87885 Val_loss =  0.44445997 Val_acc =  0.8459\n",
            "Iteration  4876 : Loss =  0.3475438  Acc:  0.8788667 Val_loss =  0.44446617 Val_acc =  0.8459\n",
            "Iteration  4877 : Loss =  0.34753606  Acc:  0.87883335 Val_loss =  0.4444705 Val_acc =  0.8459\n",
            "Iteration  4878 : Loss =  0.3475283  Acc:  0.87885 Val_loss =  0.44447628 Val_acc =  0.8459\n",
            "Iteration  4879 : Loss =  0.34752053  Acc:  0.87885 Val_loss =  0.44448134 Val_acc =  0.8459\n",
            "Iteration  4880 : Loss =  0.3475128  Acc:  0.87881666 Val_loss =  0.44448632 Val_acc =  0.8459\n",
            "Iteration  4881 : Loss =  0.3475051  Acc:  0.8788667 Val_loss =  0.44449204 Val_acc =  0.8459\n",
            "Iteration  4882 : Loss =  0.34749734  Acc:  0.87881666 Val_loss =  0.44449657 Val_acc =  0.8459\n",
            "Iteration  4883 : Loss =  0.34748963  Acc:  0.8788667 Val_loss =  0.44450253 Val_acc =  0.8459\n",
            "Iteration  4884 : Loss =  0.34748188  Acc:  0.87883335 Val_loss =  0.44450718 Val_acc =  0.8459\n",
            "Iteration  4885 : Loss =  0.34747413  Acc:  0.87883335 Val_loss =  0.44451278 Val_acc =  0.8459\n",
            "Iteration  4886 : Loss =  0.3474664  Acc:  0.87885 Val_loss =  0.44451788 Val_acc =  0.8459\n",
            "Iteration  4887 : Loss =  0.34745866  Acc:  0.87885 Val_loss =  0.44452304 Val_acc =  0.8459\n",
            "Iteration  4888 : Loss =  0.34745094  Acc:  0.87885 Val_loss =  0.44452852 Val_acc =  0.8459\n",
            "Iteration  4889 : Loss =  0.34744322  Acc:  0.87885 Val_loss =  0.44453335 Val_acc =  0.8459\n",
            "Iteration  4890 : Loss =  0.34743547  Acc:  0.87885 Val_loss =  0.44453907 Val_acc =  0.846\n",
            "Iteration  4891 : Loss =  0.34742776  Acc:  0.87885 Val_loss =  0.44454384 Val_acc =  0.8459\n",
            "Iteration  4892 : Loss =  0.34742007  Acc:  0.87885 Val_loss =  0.44454947 Val_acc =  0.846\n",
            "Iteration  4893 : Loss =  0.34741235  Acc:  0.8788667 Val_loss =  0.44455448 Val_acc =  0.846\n",
            "Iteration  4894 : Loss =  0.34740463  Acc:  0.87888336 Val_loss =  0.44455975 Val_acc =  0.846\n",
            "Iteration  4895 : Loss =  0.3473969  Acc:  0.8788667 Val_loss =  0.44456515 Val_acc =  0.8459\n",
            "Iteration  4896 : Loss =  0.3473892  Acc:  0.8788667 Val_loss =  0.4445702 Val_acc =  0.8459\n",
            "Iteration  4897 : Loss =  0.34738144  Acc:  0.8788667 Val_loss =  0.4445758 Val_acc =  0.8459\n",
            "Iteration  4898 : Loss =  0.34737375  Acc:  0.8788667 Val_loss =  0.44458067 Val_acc =  0.8459\n",
            "Iteration  4899 : Loss =  0.3473661  Acc:  0.8788667 Val_loss =  0.44458622 Val_acc =  0.8459\n",
            "Iteration  4900 : Loss =  0.34735835  Acc:  0.8788667 Val_loss =  0.44459125 Val_acc =  0.8459\n",
            "Iteration  4901 : Loss =  0.34735066  Acc:  0.8788667 Val_loss =  0.44459668 Val_acc =  0.8459\n",
            "Iteration  4902 : Loss =  0.34734297  Acc:  0.8788667 Val_loss =  0.4446019 Val_acc =  0.8459\n",
            "Iteration  4903 : Loss =  0.34733525  Acc:  0.8788667 Val_loss =  0.44460714 Val_acc =  0.8459\n",
            "Iteration  4904 : Loss =  0.34732753  Acc:  0.8788667 Val_loss =  0.4446126 Val_acc =  0.8459\n",
            "Iteration  4905 : Loss =  0.34731987  Acc:  0.87885 Val_loss =  0.44461763 Val_acc =  0.8459\n",
            "Iteration  4906 : Loss =  0.34731218  Acc:  0.87885 Val_loss =  0.44462314 Val_acc =  0.8459\n",
            "Iteration  4907 : Loss =  0.3473045  Acc:  0.87885 Val_loss =  0.44462818 Val_acc =  0.8459\n",
            "Iteration  4908 : Loss =  0.3472968  Acc:  0.8788667 Val_loss =  0.4446337 Val_acc =  0.8459\n",
            "Iteration  4909 : Loss =  0.3472891  Acc:  0.87885 Val_loss =  0.44463882 Val_acc =  0.8459\n",
            "Iteration  4910 : Loss =  0.34728143  Acc:  0.8788667 Val_loss =  0.44464415 Val_acc =  0.8459\n",
            "Iteration  4911 : Loss =  0.34727374  Acc:  0.8788667 Val_loss =  0.44464946 Val_acc =  0.8459\n",
            "Iteration  4912 : Loss =  0.34726605  Acc:  0.8788667 Val_loss =  0.44465467 Val_acc =  0.8459\n",
            "Iteration  4913 : Loss =  0.34725836  Acc:  0.8788667 Val_loss =  0.44466007 Val_acc =  0.8459\n",
            "Iteration  4914 : Loss =  0.34725067  Acc:  0.8788667 Val_loss =  0.44466522 Val_acc =  0.8459\n",
            "Iteration  4915 : Loss =  0.347243  Acc:  0.8788667 Val_loss =  0.4446707 Val_acc =  0.8459\n",
            "Iteration  4916 : Loss =  0.34723535  Acc:  0.8788667 Val_loss =  0.4446759 Val_acc =  0.8459\n",
            "Iteration  4917 : Loss =  0.34722766  Acc:  0.87885 Val_loss =  0.44468126 Val_acc =  0.8459\n",
            "Iteration  4918 : Loss =  0.34721997  Acc:  0.87885 Val_loss =  0.44468653 Val_acc =  0.8458\n",
            "Iteration  4919 : Loss =  0.3472123  Acc:  0.87885 Val_loss =  0.44469184 Val_acc =  0.8458\n",
            "Iteration  4920 : Loss =  0.34720466  Acc:  0.87885 Val_loss =  0.44469717 Val_acc =  0.8458\n",
            "Iteration  4921 : Loss =  0.34719697  Acc:  0.87885 Val_loss =  0.44470245 Val_acc =  0.8458\n",
            "Iteration  4922 : Loss =  0.34718934  Acc:  0.8788667 Val_loss =  0.4447078 Val_acc =  0.8458\n",
            "Iteration  4923 : Loss =  0.34718165  Acc:  0.8788667 Val_loss =  0.4447131 Val_acc =  0.8458\n",
            "Iteration  4924 : Loss =  0.347174  Acc:  0.8788667 Val_loss =  0.44471845 Val_acc =  0.8458\n",
            "Iteration  4925 : Loss =  0.34716633  Acc:  0.8788667 Val_loss =  0.44472373 Val_acc =  0.8458\n",
            "Iteration  4926 : Loss =  0.34715867  Acc:  0.8788667 Val_loss =  0.4447291 Val_acc =  0.8458\n",
            "Iteration  4927 : Loss =  0.34715104  Acc:  0.8788667 Val_loss =  0.44473436 Val_acc =  0.8458\n",
            "Iteration  4928 : Loss =  0.34714335  Acc:  0.87885 Val_loss =  0.44473976 Val_acc =  0.8458\n",
            "Iteration  4929 : Loss =  0.34713575  Acc:  0.8788667 Val_loss =  0.44474503 Val_acc =  0.8458\n",
            "Iteration  4930 : Loss =  0.34712806  Acc:  0.8788667 Val_loss =  0.4447504 Val_acc =  0.8457\n",
            "Iteration  4931 : Loss =  0.3471204  Acc:  0.8788667 Val_loss =  0.44475576 Val_acc =  0.8457\n",
            "Iteration  4932 : Loss =  0.34711277  Acc:  0.87885 Val_loss =  0.44476104 Val_acc =  0.8457\n",
            "Iteration  4933 : Loss =  0.34710512  Acc:  0.87885 Val_loss =  0.4447664 Val_acc =  0.8457\n",
            "Iteration  4934 : Loss =  0.34709746  Acc:  0.8788667 Val_loss =  0.44477174 Val_acc =  0.8457\n",
            "Iteration  4935 : Loss =  0.34708986  Acc:  0.8788667 Val_loss =  0.44477716 Val_acc =  0.8457\n",
            "Iteration  4936 : Loss =  0.34708223  Acc:  0.87885 Val_loss =  0.44478244 Val_acc =  0.8458\n",
            "Iteration  4937 : Loss =  0.34707457  Acc:  0.87885 Val_loss =  0.4447878 Val_acc =  0.8458\n",
            "Iteration  4938 : Loss =  0.34706694  Acc:  0.8788667 Val_loss =  0.4447931 Val_acc =  0.8458\n",
            "Iteration  4939 : Loss =  0.3470593  Acc:  0.87888336 Val_loss =  0.44479853 Val_acc =  0.8458\n",
            "Iteration  4940 : Loss =  0.34705165  Acc:  0.8789 Val_loss =  0.44480386 Val_acc =  0.8458\n",
            "Iteration  4941 : Loss =  0.34704402  Acc:  0.8789 Val_loss =  0.44480923 Val_acc =  0.8458\n",
            "Iteration  4942 : Loss =  0.3470364  Acc:  0.8789 Val_loss =  0.4448146 Val_acc =  0.8458\n",
            "Iteration  4943 : Loss =  0.34702876  Acc:  0.8789167 Val_loss =  0.44481993 Val_acc =  0.8458\n",
            "Iteration  4944 : Loss =  0.34702116  Acc:  0.8789333 Val_loss =  0.44482535 Val_acc =  0.8458\n",
            "Iteration  4945 : Loss =  0.34701353  Acc:  0.8789333 Val_loss =  0.44483066 Val_acc =  0.8458\n",
            "Iteration  4946 : Loss =  0.34700593  Acc:  0.87895 Val_loss =  0.44483608 Val_acc =  0.8458\n",
            "Iteration  4947 : Loss =  0.3469983  Acc:  0.8789333 Val_loss =  0.4448414 Val_acc =  0.8458\n",
            "Iteration  4948 : Loss =  0.3469907  Acc:  0.8789333 Val_loss =  0.44484684 Val_acc =  0.8458\n",
            "Iteration  4949 : Loss =  0.34698308  Acc:  0.8789667 Val_loss =  0.44485214 Val_acc =  0.8458\n",
            "Iteration  4950 : Loss =  0.34697545  Acc:  0.8789667 Val_loss =  0.44485757 Val_acc =  0.8458\n",
            "Iteration  4951 : Loss =  0.34696785  Acc:  0.8789833 Val_loss =  0.44486293 Val_acc =  0.8458\n",
            "Iteration  4952 : Loss =  0.34696022  Acc:  0.8789833 Val_loss =  0.44486836 Val_acc =  0.8458\n",
            "Iteration  4953 : Loss =  0.34695265  Acc:  0.879 Val_loss =  0.44487372 Val_acc =  0.8458\n",
            "Iteration  4954 : Loss =  0.34694502  Acc:  0.87901664 Val_loss =  0.4448791 Val_acc =  0.8458\n",
            "Iteration  4955 : Loss =  0.34693745  Acc:  0.8790333 Val_loss =  0.4448845 Val_acc =  0.8458\n",
            "Iteration  4956 : Loss =  0.34692982  Acc:  0.87905 Val_loss =  0.4448899 Val_acc =  0.8458\n",
            "Iteration  4957 : Loss =  0.3469222  Acc:  0.87906665 Val_loss =  0.44489533 Val_acc =  0.8458\n",
            "Iteration  4958 : Loss =  0.34691462  Acc:  0.87906665 Val_loss =  0.44490063 Val_acc =  0.8458\n",
            "Iteration  4959 : Loss =  0.34690702  Acc:  0.87906665 Val_loss =  0.44490612 Val_acc =  0.8458\n",
            "Iteration  4960 : Loss =  0.34689942  Acc:  0.87906665 Val_loss =  0.4449115 Val_acc =  0.8458\n",
            "Iteration  4961 : Loss =  0.34689182  Acc:  0.87905 Val_loss =  0.4449169 Val_acc =  0.8458\n",
            "Iteration  4962 : Loss =  0.34688425  Acc:  0.8790333 Val_loss =  0.44492227 Val_acc =  0.8458\n",
            "Iteration  4963 : Loss =  0.34687662  Acc:  0.87905 Val_loss =  0.44492772 Val_acc =  0.8458\n",
            "Iteration  4964 : Loss =  0.34686908  Acc:  0.87908334 Val_loss =  0.44493312 Val_acc =  0.8458\n",
            "Iteration  4965 : Loss =  0.34686145  Acc:  0.87908334 Val_loss =  0.44493857 Val_acc =  0.8458\n",
            "Iteration  4966 : Loss =  0.3468539  Acc:  0.87908334 Val_loss =  0.44494393 Val_acc =  0.8458\n",
            "Iteration  4967 : Loss =  0.3468463  Acc:  0.8791 Val_loss =  0.44494942 Val_acc =  0.8458\n",
            "Iteration  4968 : Loss =  0.34683874  Acc:  0.8791 Val_loss =  0.44495478 Val_acc =  0.8458\n",
            "Iteration  4969 : Loss =  0.34683114  Acc:  0.87911665 Val_loss =  0.44496027 Val_acc =  0.8458\n",
            "Iteration  4970 : Loss =  0.34682357  Acc:  0.87911665 Val_loss =  0.44496563 Val_acc =  0.8458\n",
            "Iteration  4971 : Loss =  0.346816  Acc:  0.87911665 Val_loss =  0.44497105 Val_acc =  0.8457\n",
            "Iteration  4972 : Loss =  0.34680843  Acc:  0.87911665 Val_loss =  0.4449765 Val_acc =  0.8457\n",
            "Iteration  4973 : Loss =  0.34680083  Acc:  0.87911665 Val_loss =  0.44498193 Val_acc =  0.8457\n",
            "Iteration  4974 : Loss =  0.3467933  Acc:  0.87911665 Val_loss =  0.44498742 Val_acc =  0.8457\n",
            "Iteration  4975 : Loss =  0.34678572  Acc:  0.87913334 Val_loss =  0.44499278 Val_acc =  0.8457\n",
            "Iteration  4976 : Loss =  0.34677812  Acc:  0.87918335 Val_loss =  0.44499823 Val_acc =  0.8457\n",
            "Iteration  4977 : Loss =  0.34677058  Acc:  0.87918335 Val_loss =  0.44500366 Val_acc =  0.8457\n",
            "Iteration  4978 : Loss =  0.346763  Acc:  0.87918335 Val_loss =  0.44500917 Val_acc =  0.8457\n",
            "Iteration  4979 : Loss =  0.34675547  Acc:  0.87918335 Val_loss =  0.44501454 Val_acc =  0.8457\n",
            "Iteration  4980 : Loss =  0.34674788  Acc:  0.87918335 Val_loss =  0.44502002 Val_acc =  0.8457\n",
            "Iteration  4981 : Loss =  0.34674037  Acc:  0.87918335 Val_loss =  0.44502538 Val_acc =  0.8457\n",
            "Iteration  4982 : Loss =  0.34673283  Acc:  0.87918335 Val_loss =  0.44503096 Val_acc =  0.8457\n",
            "Iteration  4983 : Loss =  0.34672523  Acc:  0.8792 Val_loss =  0.44503632 Val_acc =  0.8457\n",
            "Iteration  4984 : Loss =  0.3467177  Acc:  0.87918335 Val_loss =  0.4450419 Val_acc =  0.8457\n",
            "Iteration  4985 : Loss =  0.34671012  Acc:  0.8792167 Val_loss =  0.44504726 Val_acc =  0.8457\n",
            "Iteration  4986 : Loss =  0.34670258  Acc:  0.8792167 Val_loss =  0.44505277 Val_acc =  0.8457\n",
            "Iteration  4987 : Loss =  0.34669507  Acc:  0.8792167 Val_loss =  0.4450582 Val_acc =  0.8457\n",
            "Iteration  4988 : Loss =  0.3466875  Acc:  0.8792167 Val_loss =  0.4450637 Val_acc =  0.8457\n",
            "Iteration  4989 : Loss =  0.34667996  Acc:  0.8792 Val_loss =  0.4450691 Val_acc =  0.8457\n",
            "Iteration  4990 : Loss =  0.34667242  Acc:  0.87918335 Val_loss =  0.44507465 Val_acc =  0.8457\n",
            "Iteration  4991 : Loss =  0.34666488  Acc:  0.8792 Val_loss =  0.44508007 Val_acc =  0.8457\n",
            "Iteration  4992 : Loss =  0.34665734  Acc:  0.8792 Val_loss =  0.4450856 Val_acc =  0.8457\n",
            "Iteration  4993 : Loss =  0.34664977  Acc:  0.8792 Val_loss =  0.445091 Val_acc =  0.8457\n",
            "Iteration  4994 : Loss =  0.3466423  Acc:  0.8792 Val_loss =  0.44509658 Val_acc =  0.8457\n",
            "Iteration  4995 : Loss =  0.34663475  Acc:  0.8792 Val_loss =  0.44510195 Val_acc =  0.8457\n",
            "Iteration  4996 : Loss =  0.3466272  Acc:  0.8792167 Val_loss =  0.44510752 Val_acc =  0.8457\n",
            "Iteration  4997 : Loss =  0.34661967  Acc:  0.8792167 Val_loss =  0.44511288 Val_acc =  0.8457\n",
            "Iteration  4998 : Loss =  0.34661216  Acc:  0.8792167 Val_loss =  0.44511855 Val_acc =  0.8458\n",
            "Iteration  4999 : Loss =  0.34660462  Acc:  0.8792167 Val_loss =  0.44512382 Val_acc =  0.8457\n",
            "Iteration  5000 : Loss =  0.34659708  Acc:  0.8792167 Val_loss =  0.44512954 Val_acc =  0.8458\n",
            "Iteration  5001 : Loss =  0.3465896  Acc:  0.87923336 Val_loss =  0.44513476 Val_acc =  0.8457\n",
            "Iteration  5002 : Loss =  0.34658206  Acc:  0.87923336 Val_loss =  0.44514057 Val_acc =  0.8458\n",
            "Iteration  5003 : Loss =  0.34657454  Acc:  0.87923336 Val_loss =  0.44514576 Val_acc =  0.8457\n",
            "Iteration  5004 : Loss =  0.34656703  Acc:  0.87923336 Val_loss =  0.44515166 Val_acc =  0.8458\n",
            "Iteration  5005 : Loss =  0.3465595  Acc:  0.87923336 Val_loss =  0.44515663 Val_acc =  0.8457\n",
            "Iteration  5006 : Loss =  0.346552  Acc:  0.87925 Val_loss =  0.44516274 Val_acc =  0.8458\n",
            "Iteration  5007 : Loss =  0.34654447  Acc:  0.87923336 Val_loss =  0.44516757 Val_acc =  0.8457\n",
            "Iteration  5008 : Loss =  0.346537  Acc:  0.87925 Val_loss =  0.44517392 Val_acc =  0.8458\n",
            "Iteration  5009 : Loss =  0.34652948  Acc:  0.87923336 Val_loss =  0.44517842 Val_acc =  0.8457\n",
            "Iteration  5010 : Loss =  0.346522  Acc:  0.87925 Val_loss =  0.4451852 Val_acc =  0.8458\n",
            "Iteration  5011 : Loss =  0.34651446  Acc:  0.87923336 Val_loss =  0.44518915 Val_acc =  0.8457\n",
            "Iteration  5012 : Loss =  0.34650695  Acc:  0.8792 Val_loss =  0.44519663 Val_acc =  0.8458\n",
            "Iteration  5013 : Loss =  0.3464995  Acc:  0.87923336 Val_loss =  0.44519985 Val_acc =  0.8456\n",
            "Iteration  5014 : Loss =  0.34649205  Acc:  0.8792 Val_loss =  0.4452083 Val_acc =  0.8459\n",
            "Iteration  5015 : Loss =  0.34648463  Acc:  0.87925 Val_loss =  0.44521025 Val_acc =  0.8456\n",
            "Iteration  5016 : Loss =  0.3464772  Acc:  0.8792 Val_loss =  0.44522032 Val_acc =  0.8459\n",
            "Iteration  5017 : Loss =  0.34646985  Acc:  0.8792167 Val_loss =  0.44522047 Val_acc =  0.8456\n",
            "Iteration  5018 : Loss =  0.3464626  Acc:  0.8792833 Val_loss =  0.4452332 Val_acc =  0.8458\n",
            "Iteration  5019 : Loss =  0.34645545  Acc:  0.8792833 Val_loss =  0.44523028 Val_acc =  0.8456\n",
            "Iteration  5020 : Loss =  0.34644857  Acc:  0.87923336 Val_loss =  0.44524756 Val_acc =  0.8459\n",
            "Iteration  5021 : Loss =  0.34644198  Acc:  0.87935 Val_loss =  0.44523993 Val_acc =  0.8457\n",
            "Iteration  5022 : Loss =  0.34643602  Acc:  0.87923336 Val_loss =  0.44526502 Val_acc =  0.8459\n",
            "Iteration  5023 : Loss =  0.34643105  Acc:  0.8793167 Val_loss =  0.4452503 Val_acc =  0.8456\n",
            "Iteration  5024 : Loss =  0.34642753  Acc:  0.87911665 Val_loss =  0.44528896 Val_acc =  0.8459\n",
            "Iteration  5025 : Loss =  0.3464265  Acc:  0.8793 Val_loss =  0.44526416 Val_acc =  0.8456\n",
            "Iteration  5026 : Loss =  0.3464288  Acc:  0.87923336 Val_loss =  0.44532666 Val_acc =  0.846\n",
            "Iteration  5027 : Loss =  0.34643623  Acc:  0.8792833 Val_loss =  0.44528866 Val_acc =  0.8454\n",
            "Iteration  5028 : Loss =  0.3464483  Acc:  0.87918335 Val_loss =  0.44538736 Val_acc =  0.8461\n",
            "Iteration  5029 : Loss =  0.34646478  Acc:  0.8793333 Val_loss =  0.44532958 Val_acc =  0.8462\n",
            "Iteration  5030 : Loss =  0.346476  Acc:  0.87923336 Val_loss =  0.4454562 Val_acc =  0.8459\n",
            "Iteration  5031 : Loss =  0.34647363  Acc:  0.8793333 Val_loss =  0.44535688 Val_acc =  0.8463\n",
            "Iteration  5032 : Loss =  0.34644407  Acc:  0.87925 Val_loss =  0.44544813 Val_acc =  0.8458\n",
            "Iteration  5033 : Loss =  0.34639725  Acc:  0.8792833 Val_loss =  0.44532168 Val_acc =  0.8456\n",
            "Iteration  5034 : Loss =  0.34635392  Acc:  0.8792 Val_loss =  0.4453505 Val_acc =  0.8459\n",
            "Iteration  5035 : Loss =  0.34633556  Acc:  0.8792667 Val_loss =  0.4453251 Val_acc =  0.8458\n",
            "Iteration  5036 : Loss =  0.34634262  Acc:  0.8793 Val_loss =  0.4453245 Val_acc =  0.8456\n",
            "Iteration  5037 : Loss =  0.346357  Acc:  0.8793167 Val_loss =  0.44540587 Val_acc =  0.8461\n",
            "Iteration  5038 : Loss =  0.34635887  Acc:  0.8792833 Val_loss =  0.44534862 Val_acc =  0.8455\n",
            "Iteration  5039 : Loss =  0.34633964  Acc:  0.8793333 Val_loss =  0.44541612 Val_acc =  0.846\n",
            "Iteration  5040 : Loss =  0.3463112  Acc:  0.8793667 Val_loss =  0.4453414 Val_acc =  0.8454\n",
            "Iteration  5041 : Loss =  0.3462914  Acc:  0.8793167 Val_loss =  0.44536397 Val_acc =  0.8459\n",
            "Iteration  5042 : Loss =  0.34628806  Acc:  0.87918335 Val_loss =  0.44537812 Val_acc =  0.846\n",
            "Iteration  5043 : Loss =  0.34629297  Acc:  0.8793 Val_loss =  0.44536266 Val_acc =  0.8455\n",
            "Iteration  5044 : Loss =  0.34629193  Acc:  0.87925 Val_loss =  0.4454268 Val_acc =  0.846\n",
            "Iteration  5045 : Loss =  0.3462791  Acc:  0.8792167 Val_loss =  0.4453713 Val_acc =  0.8455\n",
            "Iteration  5046 : Loss =  0.34626043  Acc:  0.87923336 Val_loss =  0.44540986 Val_acc =  0.846\n",
            "Iteration  5047 : Loss =  0.3462467  Acc:  0.8793 Val_loss =  0.44538677 Val_acc =  0.8456\n",
            "Iteration  5048 : Loss =  0.34624213  Acc:  0.87943333 Val_loss =  0.44539052 Val_acc =  0.8457\n",
            "Iteration  5049 : Loss =  0.3462414  Acc:  0.87915 Val_loss =  0.4454302 Val_acc =  0.846\n",
            "Iteration  5050 : Loss =  0.3462368  Acc:  0.8794 Val_loss =  0.44539803 Val_acc =  0.8454\n",
            "Iteration  5051 : Loss =  0.3462256  Acc:  0.8792 Val_loss =  0.44544113 Val_acc =  0.8459\n",
            "Iteration  5052 : Loss =  0.34621218  Acc:  0.87945 Val_loss =  0.44540885 Val_acc =  0.8456\n",
            "Iteration  5053 : Loss =  0.34620222  Acc:  0.8793167 Val_loss =  0.44542506 Val_acc =  0.8458\n",
            "Iteration  5054 : Loss =  0.3461971  Acc:  0.87925 Val_loss =  0.44543993 Val_acc =  0.846\n",
            "Iteration  5055 : Loss =  0.34619325  Acc:  0.8794 Val_loss =  0.44542548 Val_acc =  0.8456\n",
            "Iteration  5056 : Loss =  0.34618667  Acc:  0.87916666 Val_loss =  0.44546354 Val_acc =  0.846\n",
            "Iteration  5057 : Loss =  0.3461767  Acc:  0.87945 Val_loss =  0.44543564 Val_acc =  0.8456\n",
            "Iteration  5058 : Loss =  0.34616622  Acc:  0.8793 Val_loss =  0.44545949 Val_acc =  0.8459\n",
            "Iteration  5059 : Loss =  0.346158  Acc:  0.87935 Val_loss =  0.44545713 Val_acc =  0.8459\n",
            "Iteration  5060 : Loss =  0.34615222  Acc:  0.8794 Val_loss =  0.44545585 Val_acc =  0.8457\n",
            "Iteration  5061 : Loss =  0.34614667  Acc:  0.87925 Val_loss =  0.445483 Val_acc =  0.846\n",
            "Iteration  5062 : Loss =  0.34613934  Acc:  0.87946665 Val_loss =  0.44546387 Val_acc =  0.8456\n",
            "Iteration  5063 : Loss =  0.3461304  Acc:  0.8793833 Val_loss =  0.4454901 Val_acc =  0.846\n",
            "Iteration  5064 : Loss =  0.34612146  Acc:  0.8793 Val_loss =  0.44547945 Val_acc =  0.8457\n",
            "Iteration  5065 : Loss =  0.3461139  Acc:  0.8793167 Val_loss =  0.4454879 Val_acc =  0.8457\n",
            "Iteration  5066 : Loss =  0.34610748  Acc:  0.8793833 Val_loss =  0.44550243 Val_acc =  0.8459\n",
            "Iteration  5067 : Loss =  0.34610105  Acc:  0.87943333 Val_loss =  0.44549277 Val_acc =  0.8456\n",
            "Iteration  5068 : Loss =  0.3460936  Acc:  0.8793667 Val_loss =  0.44551688 Val_acc =  0.846\n",
            "Iteration  5069 : Loss =  0.34608528  Acc:  0.8793333 Val_loss =  0.44550508 Val_acc =  0.8458\n",
            "Iteration  5070 : Loss =  0.34607714  Acc:  0.8793833 Val_loss =  0.44551972 Val_acc =  0.8459\n",
            "Iteration  5071 : Loss =  0.34606978  Acc:  0.8793833 Val_loss =  0.44552383 Val_acc =  0.8459\n",
            "Iteration  5072 : Loss =  0.34606296  Acc:  0.8794 Val_loss =  0.44552314 Val_acc =  0.8458\n",
            "Iteration  5073 : Loss =  0.34605607  Acc:  0.8793833 Val_loss =  0.44554156 Val_acc =  0.8459\n",
            "Iteration  5074 : Loss =  0.34604865  Acc:  0.87935 Val_loss =  0.44553292 Val_acc =  0.8458\n",
            "Iteration  5075 : Loss =  0.34604082  Acc:  0.8794 Val_loss =  0.44555005 Val_acc =  0.8459\n",
            "Iteration  5076 : Loss =  0.34603307  Acc:  0.8792833 Val_loss =  0.44554785 Val_acc =  0.8458\n",
            "Iteration  5077 : Loss =  0.3460257  Acc:  0.8793 Val_loss =  0.44555435 Val_acc =  0.8458\n",
            "Iteration  5078 : Loss =  0.34601867  Acc:  0.87941664 Val_loss =  0.44556528 Val_acc =  0.8459\n",
            "Iteration  5079 : Loss =  0.34601158  Acc:  0.8794 Val_loss =  0.44556183 Val_acc =  0.8458\n",
            "Iteration  5080 : Loss =  0.34600428  Acc:  0.87945 Val_loss =  0.44557792 Val_acc =  0.8459\n",
            "Iteration  5081 : Loss =  0.34599668  Acc:  0.8793833 Val_loss =  0.44557407 Val_acc =  0.8458\n",
            "Iteration  5082 : Loss =  0.34598914  Acc:  0.87943333 Val_loss =  0.44558507 Val_acc =  0.8458\n",
            "Iteration  5083 : Loss =  0.34598175  Acc:  0.87943333 Val_loss =  0.44558945 Val_acc =  0.8458\n",
            "Iteration  5084 : Loss =  0.34597453  Acc:  0.8793667 Val_loss =  0.4455918 Val_acc =  0.8458\n",
            "Iteration  5085 : Loss =  0.34596738  Acc:  0.87941664 Val_loss =  0.44560412 Val_acc =  0.8459\n",
            "Iteration  5086 : Loss =  0.34596008  Acc:  0.8794 Val_loss =  0.4456019 Val_acc =  0.8458\n",
            "Iteration  5087 : Loss =  0.34595266  Acc:  0.87946665 Val_loss =  0.44561437 Val_acc =  0.8459\n",
            "Iteration  5088 : Loss =  0.34594524  Acc:  0.87935 Val_loss =  0.44561505 Val_acc =  0.8459\n",
            "Iteration  5089 : Loss =  0.34593782  Acc:  0.8793833 Val_loss =  0.44562212 Val_acc =  0.8458\n",
            "Iteration  5090 : Loss =  0.3459306  Acc:  0.87943333 Val_loss =  0.44562954 Val_acc =  0.8458\n",
            "Iteration  5091 : Loss =  0.34592336  Acc:  0.8793667 Val_loss =  0.44563085 Val_acc =  0.8458\n",
            "Iteration  5092 : Loss =  0.3459161  Acc:  0.87946665 Val_loss =  0.44564208 Val_acc =  0.8459\n",
            "Iteration  5093 : Loss =  0.34590876  Acc:  0.87935 Val_loss =  0.44564217 Val_acc =  0.8457\n",
            "Iteration  5094 : Loss =  0.3459014  Acc:  0.87941664 Val_loss =  0.4456518 Val_acc =  0.8459\n",
            "Iteration  5095 : Loss =  0.34589404  Acc:  0.87935 Val_loss =  0.44565538 Val_acc =  0.8458\n",
            "Iteration  5096 : Loss =  0.3458867  Acc:  0.87935 Val_loss =  0.44566056 Val_acc =  0.8458\n",
            "Iteration  5097 : Loss =  0.3458795  Acc:  0.87941664 Val_loss =  0.44566864 Val_acc =  0.8458\n",
            "Iteration  5098 : Loss =  0.34587225  Acc:  0.87935 Val_loss =  0.4456706 Val_acc =  0.8459\n",
            "Iteration  5099 : Loss =  0.34586495  Acc:  0.87941664 Val_loss =  0.44568017 Val_acc =  0.8459\n",
            "Iteration  5100 : Loss =  0.34585762  Acc:  0.8793333 Val_loss =  0.44568232 Val_acc =  0.8459\n",
            "Iteration  5101 : Loss =  0.34585026  Acc:  0.8793833 Val_loss =  0.44569013 Val_acc =  0.8459\n",
            "Iteration  5102 : Loss =  0.34584296  Acc:  0.8793667 Val_loss =  0.44569513 Val_acc =  0.8459\n",
            "Iteration  5103 : Loss =  0.34583575  Acc:  0.87935 Val_loss =  0.44569975 Val_acc =  0.846\n",
            "Iteration  5104 : Loss =  0.34582844  Acc:  0.8794 Val_loss =  0.44570756 Val_acc =  0.8459\n",
            "Iteration  5105 : Loss =  0.3458212  Acc:  0.8793333 Val_loss =  0.44571045 Val_acc =  0.846\n",
            "Iteration  5106 : Loss =  0.3458139  Acc:  0.8794 Val_loss =  0.4457188 Val_acc =  0.8459\n",
            "Iteration  5107 : Loss =  0.34580657  Acc:  0.87935 Val_loss =  0.44572222 Val_acc =  0.846\n",
            "Iteration  5108 : Loss =  0.3457993  Acc:  0.8793667 Val_loss =  0.44572902 Val_acc =  0.8459\n",
            "Iteration  5109 : Loss =  0.34579203  Acc:  0.8793333 Val_loss =  0.44573456 Val_acc =  0.8459\n",
            "Iteration  5110 : Loss =  0.34578475  Acc:  0.8793333 Val_loss =  0.4457393 Val_acc =  0.846\n",
            "Iteration  5111 : Loss =  0.34577748  Acc:  0.8794 Val_loss =  0.44574654 Val_acc =  0.8459\n",
            "Iteration  5112 : Loss =  0.34577024  Acc:  0.8793167 Val_loss =  0.44575024 Val_acc =  0.846\n",
            "Iteration  5113 : Loss =  0.34576297  Acc:  0.8793833 Val_loss =  0.44575778 Val_acc =  0.8459\n",
            "Iteration  5114 : Loss =  0.34575567  Acc:  0.8793167 Val_loss =  0.44576192 Val_acc =  0.846\n",
            "Iteration  5115 : Loss =  0.34574842  Acc:  0.87935 Val_loss =  0.44576836 Val_acc =  0.846\n",
            "Iteration  5116 : Loss =  0.34574115  Acc:  0.8793333 Val_loss =  0.44577393 Val_acc =  0.846\n",
            "Iteration  5117 : Loss =  0.34573388  Acc:  0.8793333 Val_loss =  0.445779 Val_acc =  0.846\n",
            "Iteration  5118 : Loss =  0.34572664  Acc:  0.8793833 Val_loss =  0.4457857 Val_acc =  0.846\n",
            "Iteration  5119 : Loss =  0.34571934  Acc:  0.87935 Val_loss =  0.44579005 Val_acc =  0.8459\n",
            "Iteration  5120 : Loss =  0.3457121  Acc:  0.8794 Val_loss =  0.44579697 Val_acc =  0.8459\n",
            "Iteration  5121 : Loss =  0.34570485  Acc:  0.8793333 Val_loss =  0.44580156 Val_acc =  0.8459\n",
            "Iteration  5122 : Loss =  0.34569758  Acc:  0.87935 Val_loss =  0.44580787 Val_acc =  0.8459\n",
            "Iteration  5123 : Loss =  0.34569037  Acc:  0.8793333 Val_loss =  0.4458134 Val_acc =  0.8459\n",
            "Iteration  5124 : Loss =  0.34568307  Acc:  0.8793333 Val_loss =  0.44581875 Val_acc =  0.8459\n",
            "Iteration  5125 : Loss =  0.34567586  Acc:  0.87935 Val_loss =  0.44582504 Val_acc =  0.8459\n",
            "Iteration  5126 : Loss =  0.3456686  Acc:  0.8793167 Val_loss =  0.44582987 Val_acc =  0.8458\n",
            "Iteration  5127 : Loss =  0.34566137  Acc:  0.8793667 Val_loss =  0.44583642 Val_acc =  0.8459\n",
            "Iteration  5128 : Loss =  0.3456541  Acc:  0.8793 Val_loss =  0.4458413 Val_acc =  0.8458\n",
            "Iteration  5129 : Loss =  0.34564683  Acc:  0.87935 Val_loss =  0.44584757 Val_acc =  0.8458\n",
            "Iteration  5130 : Loss =  0.34563965  Acc:  0.8793 Val_loss =  0.44585294 Val_acc =  0.8457\n",
            "Iteration  5131 : Loss =  0.34563234  Acc:  0.8793 Val_loss =  0.44585866 Val_acc =  0.8457\n",
            "Iteration  5132 : Loss =  0.34562513  Acc:  0.8793167 Val_loss =  0.44586456 Val_acc =  0.8457\n",
            "Iteration  5133 : Loss =  0.3456179  Acc:  0.8793 Val_loss =  0.44586977 Val_acc =  0.8457\n",
            "Iteration  5134 : Loss =  0.34561068  Acc:  0.87935 Val_loss =  0.44587603 Val_acc =  0.8457\n",
            "Iteration  5135 : Loss =  0.34560344  Acc:  0.8793 Val_loss =  0.44588116 Val_acc =  0.8457\n",
            "Iteration  5136 : Loss =  0.34559622  Acc:  0.8793167 Val_loss =  0.4458873 Val_acc =  0.8457\n",
            "Iteration  5137 : Loss =  0.345589  Acc:  0.8792833 Val_loss =  0.44589266 Val_acc =  0.8457\n",
            "Iteration  5138 : Loss =  0.34558177  Acc:  0.8793167 Val_loss =  0.44589853 Val_acc =  0.8457\n",
            "Iteration  5139 : Loss =  0.3455745  Acc:  0.8793167 Val_loss =  0.4459042 Val_acc =  0.8457\n",
            "Iteration  5140 : Loss =  0.3455673  Acc:  0.8793 Val_loss =  0.44590977 Val_acc =  0.8457\n",
            "Iteration  5141 : Loss =  0.3455601  Acc:  0.8793333 Val_loss =  0.44591573 Val_acc =  0.8457\n",
            "Iteration  5142 : Loss =  0.34555286  Acc:  0.8793333 Val_loss =  0.4459211 Val_acc =  0.8457\n",
            "Iteration  5143 : Loss =  0.34554565  Acc:  0.8793333 Val_loss =  0.44592714 Val_acc =  0.8457\n",
            "Iteration  5144 : Loss =  0.3455384  Acc:  0.8793333 Val_loss =  0.4459325 Val_acc =  0.8457\n",
            "Iteration  5145 : Loss =  0.34553123  Acc:  0.87935 Val_loss =  0.44593847 Val_acc =  0.8457\n",
            "Iteration  5146 : Loss =  0.34552398  Acc:  0.8793667 Val_loss =  0.44594398 Val_acc =  0.8457\n",
            "Iteration  5147 : Loss =  0.34551677  Acc:  0.8793667 Val_loss =  0.44594976 Val_acc =  0.8457\n",
            "Iteration  5148 : Loss =  0.34550956  Acc:  0.8793667 Val_loss =  0.44595557 Val_acc =  0.8457\n",
            "Iteration  5149 : Loss =  0.34550235  Acc:  0.87935 Val_loss =  0.44596115 Val_acc =  0.8457\n",
            "Iteration  5150 : Loss =  0.3454951  Acc:  0.8793667 Val_loss =  0.445967 Val_acc =  0.8458\n",
            "Iteration  5151 : Loss =  0.34548795  Acc:  0.87935 Val_loss =  0.4459725 Val_acc =  0.8458\n",
            "Iteration  5152 : Loss =  0.34548074  Acc:  0.8793833 Val_loss =  0.44597852 Val_acc =  0.8458\n",
            "Iteration  5153 : Loss =  0.34547353  Acc:  0.8793667 Val_loss =  0.44598398 Val_acc =  0.8458\n",
            "Iteration  5154 : Loss =  0.34546635  Acc:  0.8793833 Val_loss =  0.4459899 Val_acc =  0.8458\n",
            "Iteration  5155 : Loss =  0.3454592  Acc:  0.8793833 Val_loss =  0.4459955 Val_acc =  0.8458\n",
            "Iteration  5156 : Loss =  0.34545192  Acc:  0.8794 Val_loss =  0.44600126 Val_acc =  0.8458\n",
            "Iteration  5157 : Loss =  0.34544477  Acc:  0.8794 Val_loss =  0.44600704 Val_acc =  0.8457\n",
            "Iteration  5158 : Loss =  0.34543756  Acc:  0.8794 Val_loss =  0.4460127 Val_acc =  0.8457\n",
            "Iteration  5159 : Loss =  0.34543034  Acc:  0.8794 Val_loss =  0.44601855 Val_acc =  0.8457\n",
            "Iteration  5160 : Loss =  0.3454232  Acc:  0.8794 Val_loss =  0.44602412 Val_acc =  0.8457\n",
            "Iteration  5161 : Loss =  0.34541598  Acc:  0.8794 Val_loss =  0.44603002 Val_acc =  0.8457\n",
            "Iteration  5162 : Loss =  0.3454088  Acc:  0.8794 Val_loss =  0.44603565 Val_acc =  0.8457\n",
            "Iteration  5163 : Loss =  0.34540161  Acc:  0.8793833 Val_loss =  0.4460415 Val_acc =  0.8457\n",
            "Iteration  5164 : Loss =  0.34539443  Acc:  0.8793833 Val_loss =  0.44604716 Val_acc =  0.8457\n",
            "Iteration  5165 : Loss =  0.34538725  Acc:  0.8793833 Val_loss =  0.44605294 Val_acc =  0.8457\n",
            "Iteration  5166 : Loss =  0.34538007  Acc:  0.8793833 Val_loss =  0.4460587 Val_acc =  0.8457\n",
            "Iteration  5167 : Loss =  0.3453729  Acc:  0.8793667 Val_loss =  0.44606435 Val_acc =  0.8457\n",
            "Iteration  5168 : Loss =  0.3453657  Acc:  0.8793667 Val_loss =  0.44607022 Val_acc =  0.8457\n",
            "Iteration  5169 : Loss =  0.34535852  Acc:  0.8793667 Val_loss =  0.4460759 Val_acc =  0.8457\n",
            "Iteration  5170 : Loss =  0.34535137  Acc:  0.8793667 Val_loss =  0.44608173 Val_acc =  0.8457\n",
            "Iteration  5171 : Loss =  0.3453442  Acc:  0.8793667 Val_loss =  0.4460874 Val_acc =  0.8457\n",
            "Iteration  5172 : Loss =  0.34533697  Acc:  0.8793667 Val_loss =  0.44609326 Val_acc =  0.8457\n",
            "Iteration  5173 : Loss =  0.34532982  Acc:  0.8793667 Val_loss =  0.44609892 Val_acc =  0.8457\n",
            "Iteration  5174 : Loss =  0.34532267  Acc:  0.8793833 Val_loss =  0.4461048 Val_acc =  0.8457\n",
            "Iteration  5175 : Loss =  0.3453155  Acc:  0.87943333 Val_loss =  0.4461105 Val_acc =  0.8457\n",
            "Iteration  5176 : Loss =  0.34530833  Acc:  0.87943333 Val_loss =  0.4461163 Val_acc =  0.8457\n",
            "Iteration  5177 : Loss =  0.34530118  Acc:  0.87945 Val_loss =  0.44612208 Val_acc =  0.8457\n",
            "Iteration  5178 : Loss =  0.345294  Acc:  0.87945 Val_loss =  0.44612777 Val_acc =  0.8457\n",
            "Iteration  5179 : Loss =  0.34528685  Acc:  0.87946665 Val_loss =  0.44613364 Val_acc =  0.8457\n",
            "Iteration  5180 : Loss =  0.3452797  Acc:  0.87946665 Val_loss =  0.44613937 Val_acc =  0.8457\n",
            "Iteration  5181 : Loss =  0.3452725  Acc:  0.87948334 Val_loss =  0.4461452 Val_acc =  0.8457\n",
            "Iteration  5182 : Loss =  0.34526536  Acc:  0.87948334 Val_loss =  0.44615093 Val_acc =  0.8457\n",
            "Iteration  5183 : Loss =  0.3452582  Acc:  0.87948334 Val_loss =  0.44615674 Val_acc =  0.8457\n",
            "Iteration  5184 : Loss =  0.34525108  Acc:  0.8795 Val_loss =  0.4461625 Val_acc =  0.8457\n",
            "Iteration  5185 : Loss =  0.3452439  Acc:  0.87951666 Val_loss =  0.44616836 Val_acc =  0.8457\n",
            "Iteration  5186 : Loss =  0.34523675  Acc:  0.87951666 Val_loss =  0.44617411 Val_acc =  0.8457\n",
            "Iteration  5187 : Loss =  0.34522963  Acc:  0.87953335 Val_loss =  0.4461799 Val_acc =  0.8457\n",
            "Iteration  5188 : Loss =  0.34522247  Acc:  0.87951666 Val_loss =  0.4461857 Val_acc =  0.8457\n",
            "Iteration  5189 : Loss =  0.3452153  Acc:  0.87951666 Val_loss =  0.4461915 Val_acc =  0.8457\n",
            "Iteration  5190 : Loss =  0.3452082  Acc:  0.87951666 Val_loss =  0.44619727 Val_acc =  0.8457\n",
            "Iteration  5191 : Loss =  0.34520105  Acc:  0.87951666 Val_loss =  0.4462031 Val_acc =  0.8457\n",
            "Iteration  5192 : Loss =  0.34519392  Acc:  0.87951666 Val_loss =  0.44620892 Val_acc =  0.8457\n",
            "Iteration  5193 : Loss =  0.34518677  Acc:  0.87951666 Val_loss =  0.44621474 Val_acc =  0.8457\n",
            "Iteration  5194 : Loss =  0.34517962  Acc:  0.87953335 Val_loss =  0.44622052 Val_acc =  0.8457\n",
            "Iteration  5195 : Loss =  0.3451725  Acc:  0.87955 Val_loss =  0.44622636 Val_acc =  0.8457\n",
            "Iteration  5196 : Loss =  0.34516537  Acc:  0.87955 Val_loss =  0.44623214 Val_acc =  0.8457\n",
            "Iteration  5197 : Loss =  0.34515825  Acc:  0.87955 Val_loss =  0.44623798 Val_acc =  0.8457\n",
            "Iteration  5198 : Loss =  0.3451511  Acc:  0.87955 Val_loss =  0.4462438 Val_acc =  0.8457\n",
            "Iteration  5199 : Loss =  0.345144  Acc:  0.87955 Val_loss =  0.4462496 Val_acc =  0.8457\n",
            "Iteration  5200 : Loss =  0.34513685  Acc:  0.87955 Val_loss =  0.44625542 Val_acc =  0.8458\n",
            "Iteration  5201 : Loss =  0.34512973  Acc:  0.87955 Val_loss =  0.44626123 Val_acc =  0.8458\n",
            "Iteration  5202 : Loss =  0.3451226  Acc:  0.87953335 Val_loss =  0.4462671 Val_acc =  0.8458\n",
            "Iteration  5203 : Loss =  0.34511548  Acc:  0.87955 Val_loss =  0.4462729 Val_acc =  0.8458\n",
            "Iteration  5204 : Loss =  0.34510833  Acc:  0.87955 Val_loss =  0.44627875 Val_acc =  0.8458\n",
            "Iteration  5205 : Loss =  0.34510124  Acc:  0.87956667 Val_loss =  0.44628456 Val_acc =  0.8458\n",
            "Iteration  5206 : Loss =  0.34509414  Acc:  0.87958336 Val_loss =  0.44629043 Val_acc =  0.8458\n",
            "Iteration  5207 : Loss =  0.34508702  Acc:  0.87956667 Val_loss =  0.4462962 Val_acc =  0.8458\n",
            "Iteration  5208 : Loss =  0.34507993  Acc:  0.87956667 Val_loss =  0.44630206 Val_acc =  0.8458\n",
            "Iteration  5209 : Loss =  0.34507278  Acc:  0.8796 Val_loss =  0.4463079 Val_acc =  0.8458\n",
            "Iteration  5210 : Loss =  0.34506568  Acc:  0.87958336 Val_loss =  0.44631377 Val_acc =  0.8458\n",
            "Iteration  5211 : Loss =  0.3450586  Acc:  0.8796 Val_loss =  0.44631964 Val_acc =  0.8458\n",
            "Iteration  5212 : Loss =  0.34505144  Acc:  0.8796 Val_loss =  0.4463254 Val_acc =  0.8458\n",
            "Iteration  5213 : Loss =  0.34504434  Acc:  0.8796 Val_loss =  0.44633126 Val_acc =  0.8458\n",
            "Iteration  5214 : Loss =  0.34503725  Acc:  0.8796 Val_loss =  0.4463371 Val_acc =  0.8458\n",
            "Iteration  5215 : Loss =  0.34503013  Acc:  0.8796 Val_loss =  0.44634297 Val_acc =  0.8458\n",
            "Iteration  5216 : Loss =  0.34502304  Acc:  0.8796 Val_loss =  0.44634882 Val_acc =  0.8458\n",
            "Iteration  5217 : Loss =  0.34501594  Acc:  0.8796 Val_loss =  0.4463547 Val_acc =  0.8458\n",
            "Iteration  5218 : Loss =  0.34500885  Acc:  0.87958336 Val_loss =  0.44636056 Val_acc =  0.8458\n",
            "Iteration  5219 : Loss =  0.34500176  Acc:  0.8796 Val_loss =  0.4463664 Val_acc =  0.8458\n",
            "Iteration  5220 : Loss =  0.34499466  Acc:  0.8796 Val_loss =  0.4463723 Val_acc =  0.8458\n",
            "Iteration  5221 : Loss =  0.34498757  Acc:  0.87958336 Val_loss =  0.4463781 Val_acc =  0.8458\n",
            "Iteration  5222 : Loss =  0.34498048  Acc:  0.87958336 Val_loss =  0.44638398 Val_acc =  0.8458\n",
            "Iteration  5223 : Loss =  0.34497342  Acc:  0.87958336 Val_loss =  0.44638985 Val_acc =  0.8458\n",
            "Iteration  5224 : Loss =  0.34496632  Acc:  0.87956667 Val_loss =  0.44639575 Val_acc =  0.8458\n",
            "Iteration  5225 : Loss =  0.3449592  Acc:  0.87956667 Val_loss =  0.44640157 Val_acc =  0.8459\n",
            "Iteration  5226 : Loss =  0.34495214  Acc:  0.87956667 Val_loss =  0.44640747 Val_acc =  0.8459\n",
            "Iteration  5227 : Loss =  0.34494504  Acc:  0.87956667 Val_loss =  0.44641337 Val_acc =  0.8459\n",
            "Iteration  5228 : Loss =  0.34493795  Acc:  0.87955 Val_loss =  0.44641924 Val_acc =  0.8459\n",
            "Iteration  5229 : Loss =  0.3449309  Acc:  0.87955 Val_loss =  0.4464251 Val_acc =  0.8459\n",
            "Iteration  5230 : Loss =  0.34492382  Acc:  0.87955 Val_loss =  0.44643104 Val_acc =  0.8459\n",
            "Iteration  5231 : Loss =  0.34491673  Acc:  0.87953335 Val_loss =  0.44643685 Val_acc =  0.8459\n",
            "Iteration  5232 : Loss =  0.34490967  Acc:  0.87953335 Val_loss =  0.44644278 Val_acc =  0.8459\n",
            "Iteration  5233 : Loss =  0.3449026  Acc:  0.87953335 Val_loss =  0.44644862 Val_acc =  0.8459\n",
            "Iteration  5234 : Loss =  0.3448955  Acc:  0.87953335 Val_loss =  0.44645458 Val_acc =  0.8459\n",
            "Iteration  5235 : Loss =  0.34488845  Acc:  0.87955 Val_loss =  0.4464604 Val_acc =  0.8459\n",
            "Iteration  5236 : Loss =  0.3448814  Acc:  0.87955 Val_loss =  0.44646642 Val_acc =  0.8458\n",
            "Iteration  5237 : Loss =  0.3448743  Acc:  0.87955 Val_loss =  0.44647223 Val_acc =  0.8457\n",
            "Iteration  5238 : Loss =  0.34486726  Acc:  0.87955 Val_loss =  0.4464782 Val_acc =  0.8457\n",
            "Iteration  5239 : Loss =  0.34486017  Acc:  0.87955 Val_loss =  0.44648397 Val_acc =  0.8457\n",
            "Iteration  5240 : Loss =  0.34485313  Acc:  0.87956667 Val_loss =  0.44649 Val_acc =  0.8457\n",
            "Iteration  5241 : Loss =  0.34484604  Acc:  0.87953335 Val_loss =  0.4464958 Val_acc =  0.8457\n",
            "Iteration  5242 : Loss =  0.344839  Acc:  0.87956667 Val_loss =  0.44650185 Val_acc =  0.8457\n",
            "Iteration  5243 : Loss =  0.34483194  Acc:  0.87951666 Val_loss =  0.4465075 Val_acc =  0.8457\n",
            "Iteration  5244 : Loss =  0.34482488  Acc:  0.87955 Val_loss =  0.44651368 Val_acc =  0.8457\n",
            "Iteration  5245 : Loss =  0.34481785  Acc:  0.87951666 Val_loss =  0.44651935 Val_acc =  0.8457\n",
            "Iteration  5246 : Loss =  0.34481078  Acc:  0.87955 Val_loss =  0.44652557 Val_acc =  0.8457\n",
            "Iteration  5247 : Loss =  0.34480372  Acc:  0.87951666 Val_loss =  0.44653112 Val_acc =  0.8457\n",
            "Iteration  5248 : Loss =  0.3447967  Acc:  0.87955 Val_loss =  0.4465375 Val_acc =  0.8457\n",
            "Iteration  5249 : Loss =  0.34478962  Acc:  0.8795 Val_loss =  0.44654286 Val_acc =  0.8457\n",
            "Iteration  5250 : Loss =  0.34478256  Acc:  0.87951666 Val_loss =  0.44654942 Val_acc =  0.8457\n",
            "Iteration  5251 : Loss =  0.34477553  Acc:  0.87951666 Val_loss =  0.4465546 Val_acc =  0.8457\n",
            "Iteration  5252 : Loss =  0.3447685  Acc:  0.87955 Val_loss =  0.44656143 Val_acc =  0.8457\n",
            "Iteration  5253 : Loss =  0.34476146  Acc:  0.87948334 Val_loss =  0.44656622 Val_acc =  0.8457\n",
            "Iteration  5254 : Loss =  0.34475443  Acc:  0.87953335 Val_loss =  0.44657353 Val_acc =  0.8456\n",
            "Iteration  5255 : Loss =  0.3447474  Acc:  0.8795 Val_loss =  0.4465778 Val_acc =  0.8458\n",
            "Iteration  5256 : Loss =  0.34474036  Acc:  0.87951666 Val_loss =  0.44658583 Val_acc =  0.8457\n",
            "Iteration  5257 : Loss =  0.34473333  Acc:  0.8795 Val_loss =  0.44658917 Val_acc =  0.8458\n",
            "Iteration  5258 : Loss =  0.34472632  Acc:  0.8795 Val_loss =  0.44659844 Val_acc =  0.8457\n",
            "Iteration  5259 : Loss =  0.34471938  Acc:  0.87951666 Val_loss =  0.4466003 Val_acc =  0.8458\n",
            "Iteration  5260 : Loss =  0.3447124  Acc:  0.87948334 Val_loss =  0.44661152 Val_acc =  0.8457\n",
            "Iteration  5261 : Loss =  0.34470546  Acc:  0.87946665 Val_loss =  0.44661093 Val_acc =  0.8456\n",
            "Iteration  5262 : Loss =  0.34469864  Acc:  0.87946665 Val_loss =  0.4466256 Val_acc =  0.8458\n",
            "Iteration  5263 : Loss =  0.34469196  Acc:  0.8795 Val_loss =  0.44662103 Val_acc =  0.8454\n",
            "Iteration  5264 : Loss =  0.34468544  Acc:  0.87951666 Val_loss =  0.44664142 Val_acc =  0.8458\n",
            "Iteration  5265 : Loss =  0.34467933  Acc:  0.8796333 Val_loss =  0.44663048 Val_acc =  0.8453\n",
            "Iteration  5266 : Loss =  0.34467375  Acc:  0.87956667 Val_loss =  0.44666085 Val_acc =  0.846\n",
            "Iteration  5267 : Loss =  0.34466928  Acc:  0.87956667 Val_loss =  0.4466399 Val_acc =  0.8453\n",
            "Iteration  5268 : Loss =  0.34466648  Acc:  0.87958336 Val_loss =  0.4466883 Val_acc =  0.8459\n",
            "Iteration  5269 : Loss =  0.34466636  Acc:  0.8796333 Val_loss =  0.44665214 Val_acc =  0.8455\n",
            "Iteration  5270 : Loss =  0.3446705  Acc:  0.87958336 Val_loss =  0.446733 Val_acc =  0.8458\n",
            "Iteration  5271 : Loss =  0.34468094  Acc:  0.87946665 Val_loss =  0.446676 Val_acc =  0.8459\n",
            "Iteration  5272 : Loss =  0.3446985  Acc:  0.87955 Val_loss =  0.44680914 Val_acc =  0.8458\n",
            "Iteration  5273 : Loss =  0.34472266  Acc:  0.8796 Val_loss =  0.44672218 Val_acc =  0.8461\n",
            "Iteration  5274 : Loss =  0.34474304  Acc:  0.8797167 Val_loss =  0.44690332 Val_acc =  0.8458\n",
            "Iteration  5275 : Loss =  0.34474567  Acc:  0.87978333 Val_loss =  0.4467583 Val_acc =  0.8459\n",
            "Iteration  5276 : Loss =  0.34471217  Acc:  0.8797167 Val_loss =  0.446896 Val_acc =  0.8458\n",
            "Iteration  5277 : Loss =  0.34465268  Acc:  0.87946665 Val_loss =  0.44671515 Val_acc =  0.8462\n",
            "Iteration  5278 : Loss =  0.34459856  Acc:  0.87955 Val_loss =  0.44675675 Val_acc =  0.8457\n",
            "Iteration  5279 : Loss =  0.3445806  Acc:  0.87955 Val_loss =  0.44672963 Val_acc =  0.8461\n",
            "Iteration  5280 : Loss =  0.34459674  Acc:  0.87946665 Val_loss =  0.4467208 Val_acc =  0.8456\n",
            "Iteration  5281 : Loss =  0.34461814  Acc:  0.87958336 Val_loss =  0.44683877 Val_acc =  0.8456\n",
            "Iteration  5282 : Loss =  0.3446168  Acc:  0.87945 Val_loss =  0.4467465 Val_acc =  0.8457\n",
            "Iteration  5283 : Loss =  0.34458706  Acc:  0.87958336 Val_loss =  0.4468269 Val_acc =  0.8458\n",
            "Iteration  5284 : Loss =  0.3445528  Acc:  0.8796 Val_loss =  0.4467376 Val_acc =  0.8454\n",
            "Iteration  5285 : Loss =  0.34453866  Acc:  0.87955 Val_loss =  0.44675693 Val_acc =  0.8454\n",
            "Iteration  5286 : Loss =  0.34454563  Acc:  0.8796333 Val_loss =  0.44680348 Val_acc =  0.8457\n",
            "Iteration  5287 : Loss =  0.34455383  Acc:  0.87946665 Val_loss =  0.44676572 Val_acc =  0.8454\n",
            "Iteration  5288 : Loss =  0.34454522  Acc:  0.87958336 Val_loss =  0.4468417 Val_acc =  0.8457\n",
            "Iteration  5289 : Loss =  0.34452298  Acc:  0.8796 Val_loss =  0.44677 Val_acc =  0.8454\n",
            "Iteration  5290 : Loss =  0.34450403  Acc:  0.87953335 Val_loss =  0.446799 Val_acc =  0.8459\n",
            "Iteration  5291 : Loss =  0.3444993  Acc:  0.87958336 Val_loss =  0.44680673 Val_acc =  0.8462\n",
            "Iteration  5292 : Loss =  0.34450248  Acc:  0.87956667 Val_loss =  0.44679233 Val_acc =  0.8453\n",
            "Iteration  5293 : Loss =  0.34449986  Acc:  0.87958336 Val_loss =  0.44685045 Val_acc =  0.8456\n",
            "Iteration  5294 : Loss =  0.34448692  Acc:  0.87955 Val_loss =  0.44680253 Val_acc =  0.8455\n",
            "Iteration  5295 : Loss =  0.34447092  Acc:  0.87955 Val_loss =  0.44683143 Val_acc =  0.8461\n",
            "Iteration  5296 : Loss =  0.3444617  Acc:  0.87951666 Val_loss =  0.44682598 Val_acc =  0.8458\n",
            "Iteration  5297 : Loss =  0.34445977  Acc:  0.8796 Val_loss =  0.4468214 Val_acc =  0.8454\n",
            "Iteration  5298 : Loss =  0.34445748  Acc:  0.87956667 Val_loss =  0.44686422 Val_acc =  0.8459\n",
            "Iteration  5299 : Loss =  0.3444493  Acc:  0.87958336 Val_loss =  0.44683233 Val_acc =  0.8453\n",
            "Iteration  5300 : Loss =  0.34443703  Acc:  0.8796 Val_loss =  0.44686034 Val_acc =  0.8461\n",
            "Iteration  5301 : Loss =  0.34442696  Acc:  0.87956667 Val_loss =  0.446852 Val_acc =  0.8454\n",
            "Iteration  5302 : Loss =  0.34442168  Acc:  0.8796 Val_loss =  0.44685185 Val_acc =  0.8453\n",
            "Iteration  5303 : Loss =  0.34441802  Acc:  0.8796 Val_loss =  0.4468835 Val_acc =  0.846\n",
            "Iteration  5304 : Loss =  0.34441185  Acc:  0.8796 Val_loss =  0.44686118 Val_acc =  0.8453\n",
            "Iteration  5305 : Loss =  0.34440237  Acc:  0.8796167 Val_loss =  0.4468896 Val_acc =  0.846\n",
            "Iteration  5306 : Loss =  0.34439284  Acc:  0.87956667 Val_loss =  0.4468793 Val_acc =  0.8454\n",
            "Iteration  5307 : Loss =  0.3443859  Acc:  0.87955 Val_loss =  0.44688344 Val_acc =  0.8454\n",
            "Iteration  5308 : Loss =  0.34438083  Acc:  0.8796 Val_loss =  0.44690582 Val_acc =  0.8459\n",
            "Iteration  5309 : Loss =  0.3443751  Acc:  0.8797167 Val_loss =  0.44689047 Val_acc =  0.8454\n",
            "Iteration  5310 : Loss =  0.34436733  Acc:  0.87956667 Val_loss =  0.44691807 Val_acc =  0.8459\n",
            "Iteration  5311 : Loss =  0.3443587  Acc:  0.8796333 Val_loss =  0.4469061 Val_acc =  0.8452\n",
            "Iteration  5312 : Loss =  0.3443511  Acc:  0.87951666 Val_loss =  0.44691595 Val_acc =  0.8456\n",
            "Iteration  5313 : Loss =  0.34434497  Acc:  0.8796 Val_loss =  0.4469294 Val_acc =  0.846\n",
            "Iteration  5314 : Loss =  0.3443391  Acc:  0.8796 Val_loss =  0.44692123 Val_acc =  0.8453\n",
            "Iteration  5315 : Loss =  0.34433222  Acc:  0.8796167 Val_loss =  0.4469453 Val_acc =  0.8459\n",
            "Iteration  5316 : Loss =  0.34432447  Acc:  0.87965 Val_loss =  0.44693458 Val_acc =  0.8453\n",
            "Iteration  5317 : Loss =  0.34431684  Acc:  0.8796 Val_loss =  0.44694868 Val_acc =  0.8458\n",
            "Iteration  5318 : Loss =  0.34431002  Acc:  0.8796 Val_loss =  0.44695443 Val_acc =  0.8459\n",
            "Iteration  5319 : Loss =  0.3443037  Acc:  0.8796833 Val_loss =  0.44695333 Val_acc =  0.8452\n",
            "Iteration  5320 : Loss =  0.3442972  Acc:  0.8796 Val_loss =  0.44697183 Val_acc =  0.8459\n",
            "Iteration  5321 : Loss =  0.34429005  Acc:  0.8796667 Val_loss =  0.4469648 Val_acc =  0.8453\n",
            "Iteration  5322 : Loss =  0.34428263  Acc:  0.8796333 Val_loss =  0.4469797 Val_acc =  0.8458\n",
            "Iteration  5323 : Loss =  0.34427553  Acc:  0.87953335 Val_loss =  0.44698134 Val_acc =  0.8457\n",
            "Iteration  5324 : Loss =  0.3442689  Acc:  0.8796167 Val_loss =  0.4469853 Val_acc =  0.8454\n",
            "Iteration  5325 : Loss =  0.3442623  Acc:  0.8796167 Val_loss =  0.44699848 Val_acc =  0.8457\n",
            "Iteration  5326 : Loss =  0.3442555  Acc:  0.8796833 Val_loss =  0.44699547 Val_acc =  0.8453\n",
            "Iteration  5327 : Loss =  0.34424838  Acc:  0.8796167 Val_loss =  0.44700927 Val_acc =  0.8456\n",
            "Iteration  5328 : Loss =  0.34424126  Acc:  0.87956667 Val_loss =  0.44700986 Val_acc =  0.8454\n",
            "Iteration  5329 : Loss =  0.34423438  Acc:  0.87955 Val_loss =  0.44701657 Val_acc =  0.8455\n",
            "Iteration  5330 : Loss =  0.3442277  Acc:  0.8796 Val_loss =  0.447026 Val_acc =  0.8455\n",
            "Iteration  5331 : Loss =  0.34422097  Acc:  0.8796333 Val_loss =  0.44702598 Val_acc =  0.8454\n",
            "Iteration  5332 : Loss =  0.34421405  Acc:  0.8796333 Val_loss =  0.44703868 Val_acc =  0.8456\n",
            "Iteration  5333 : Loss =  0.3442071  Acc:  0.8796333 Val_loss =  0.44703916 Val_acc =  0.8454\n",
            "Iteration  5334 : Loss =  0.3442001  Acc:  0.8796333 Val_loss =  0.4470475 Val_acc =  0.8454\n",
            "Iteration  5335 : Loss =  0.34419325  Acc:  0.87965 Val_loss =  0.44705424 Val_acc =  0.8455\n",
            "Iteration  5336 : Loss =  0.3441865  Acc:  0.8796667 Val_loss =  0.44705668 Val_acc =  0.8453\n",
            "Iteration  5337 : Loss =  0.34417975  Acc:  0.87965 Val_loss =  0.44706807 Val_acc =  0.8456\n",
            "Iteration  5338 : Loss =  0.34417287  Acc:  0.8796667 Val_loss =  0.44706854 Val_acc =  0.8453\n",
            "Iteration  5339 : Loss =  0.34416592  Acc:  0.8796833 Val_loss =  0.44707847 Val_acc =  0.8455\n",
            "Iteration  5340 : Loss =  0.34415898  Acc:  0.8796333 Val_loss =  0.4470826 Val_acc =  0.8453\n",
            "Iteration  5341 : Loss =  0.3441522  Acc:  0.8796167 Val_loss =  0.44708785 Val_acc =  0.8453\n",
            "Iteration  5342 : Loss =  0.34414545  Acc:  0.8796667 Val_loss =  0.44709677 Val_acc =  0.8454\n",
            "Iteration  5343 : Loss =  0.34413865  Acc:  0.8796333 Val_loss =  0.44709858 Val_acc =  0.8453\n",
            "Iteration  5344 : Loss =  0.34413177  Acc:  0.87965 Val_loss =  0.44710878 Val_acc =  0.8454\n",
            "Iteration  5345 : Loss =  0.3441249  Acc:  0.8796333 Val_loss =  0.44711152 Val_acc =  0.8453\n",
            "Iteration  5346 : Loss =  0.34411803  Acc:  0.8796333 Val_loss =  0.447119 Val_acc =  0.8453\n",
            "Iteration  5347 : Loss =  0.34411123  Acc:  0.8796167 Val_loss =  0.4471253 Val_acc =  0.8453\n",
            "Iteration  5348 : Loss =  0.3441044  Acc:  0.8796667 Val_loss =  0.4471295 Val_acc =  0.8453\n",
            "Iteration  5349 : Loss =  0.34409758  Acc:  0.87965 Val_loss =  0.4471382 Val_acc =  0.8454\n",
            "Iteration  5350 : Loss =  0.34409076  Acc:  0.87965 Val_loss =  0.44714132 Val_acc =  0.8453\n",
            "Iteration  5351 : Loss =  0.3440839  Acc:  0.8796333 Val_loss =  0.44714952 Val_acc =  0.8454\n",
            "Iteration  5352 : Loss =  0.34407708  Acc:  0.87965 Val_loss =  0.44715434 Val_acc =  0.8453\n",
            "Iteration  5353 : Loss =  0.34407026  Acc:  0.8796333 Val_loss =  0.4471603 Val_acc =  0.8453\n",
            "Iteration  5354 : Loss =  0.3440634  Acc:  0.8796333 Val_loss =  0.44716743 Val_acc =  0.8454\n",
            "Iteration  5355 : Loss =  0.34405664  Acc:  0.8796333 Val_loss =  0.44717163 Val_acc =  0.8453\n",
            "Iteration  5356 : Loss =  0.3440498  Acc:  0.8796167 Val_loss =  0.4471796 Val_acc =  0.8454\n",
            "Iteration  5357 : Loss =  0.344043  Acc:  0.87965 Val_loss =  0.447184 Val_acc =  0.8453\n",
            "Iteration  5358 : Loss =  0.3440362  Acc:  0.8796333 Val_loss =  0.44719082 Val_acc =  0.8453\n",
            "Iteration  5359 : Loss =  0.34402937  Acc:  0.87965 Val_loss =  0.44719687 Val_acc =  0.8453\n",
            "Iteration  5360 : Loss =  0.34402257  Acc:  0.87965 Val_loss =  0.447202 Val_acc =  0.8453\n",
            "Iteration  5361 : Loss =  0.34401575  Acc:  0.87965 Val_loss =  0.44720948 Val_acc =  0.8454\n",
            "Iteration  5362 : Loss =  0.34400895  Acc:  0.87965 Val_loss =  0.44721386 Val_acc =  0.8453\n",
            "Iteration  5363 : Loss =  0.34400216  Acc:  0.8796667 Val_loss =  0.44722128 Val_acc =  0.8453\n",
            "Iteration  5364 : Loss =  0.3439953  Acc:  0.8796333 Val_loss =  0.44722638 Val_acc =  0.8453\n",
            "Iteration  5365 : Loss =  0.34398854  Acc:  0.8796333 Val_loss =  0.44723266 Val_acc =  0.8453\n",
            "Iteration  5366 : Loss =  0.34398174  Acc:  0.87965 Val_loss =  0.44723907 Val_acc =  0.8453\n",
            "Iteration  5367 : Loss =  0.34397495  Acc:  0.8796333 Val_loss =  0.44724423 Val_acc =  0.8453\n",
            "Iteration  5368 : Loss =  0.34396812  Acc:  0.8796833 Val_loss =  0.4472514 Val_acc =  0.8453\n",
            "Iteration  5369 : Loss =  0.34396136  Acc:  0.8796667 Val_loss =  0.44725624 Val_acc =  0.8453\n",
            "Iteration  5370 : Loss =  0.34395456  Acc:  0.8797167 Val_loss =  0.44726327 Val_acc =  0.8454\n",
            "Iteration  5371 : Loss =  0.3439477  Acc:  0.8796667 Val_loss =  0.44726875 Val_acc =  0.8454\n",
            "Iteration  5372 : Loss =  0.34394094  Acc:  0.8796833 Val_loss =  0.44727486 Val_acc =  0.8454\n",
            "Iteration  5373 : Loss =  0.34393418  Acc:  0.8797333 Val_loss =  0.44728115 Val_acc =  0.8454\n",
            "Iteration  5374 : Loss =  0.34392735  Acc:  0.8796667 Val_loss =  0.44728664 Val_acc =  0.8454\n",
            "Iteration  5375 : Loss =  0.34392056  Acc:  0.8797333 Val_loss =  0.4472934 Val_acc =  0.8454\n",
            "Iteration  5376 : Loss =  0.3439138  Acc:  0.8796833 Val_loss =  0.44729877 Val_acc =  0.8454\n",
            "Iteration  5377 : Loss =  0.343907  Acc:  0.87975 Val_loss =  0.44730526 Val_acc =  0.8454\n",
            "Iteration  5378 : Loss =  0.3439002  Acc:  0.8797333 Val_loss =  0.44731113 Val_acc =  0.8454\n",
            "Iteration  5379 : Loss =  0.34389344  Acc:  0.8797167 Val_loss =  0.4473171 Val_acc =  0.8454\n",
            "Iteration  5380 : Loss =  0.34388664  Acc:  0.87975 Val_loss =  0.4473235 Val_acc =  0.8454\n",
            "Iteration  5381 : Loss =  0.34387988  Acc:  0.8797 Val_loss =  0.447329 Val_acc =  0.8454\n",
            "Iteration  5382 : Loss =  0.3438731  Acc:  0.87975 Val_loss =  0.44733563 Val_acc =  0.8454\n",
            "Iteration  5383 : Loss =  0.34386632  Acc:  0.8797167 Val_loss =  0.4473412 Val_acc =  0.8454\n",
            "Iteration  5384 : Loss =  0.34385952  Acc:  0.87975 Val_loss =  0.44734767 Val_acc =  0.8454\n",
            "Iteration  5385 : Loss =  0.34385276  Acc:  0.8797333 Val_loss =  0.4473535 Val_acc =  0.8454\n",
            "Iteration  5386 : Loss =  0.34384602  Acc:  0.8797333 Val_loss =  0.44735953 Val_acc =  0.8454\n",
            "Iteration  5387 : Loss =  0.34383926  Acc:  0.87975 Val_loss =  0.44736582 Val_acc =  0.8454\n",
            "Iteration  5388 : Loss =  0.3438325  Acc:  0.8797167 Val_loss =  0.44737154 Val_acc =  0.8454\n",
            "Iteration  5389 : Loss =  0.3438257  Acc:  0.87975 Val_loss =  0.44737804 Val_acc =  0.8454\n",
            "Iteration  5390 : Loss =  0.34381893  Acc:  0.8797167 Val_loss =  0.4473837 Val_acc =  0.8454\n",
            "Iteration  5391 : Loss =  0.34381217  Acc:  0.87975 Val_loss =  0.44739008 Val_acc =  0.8454\n",
            "Iteration  5392 : Loss =  0.3438054  Acc:  0.8797333 Val_loss =  0.447396 Val_acc =  0.8454\n",
            "Iteration  5393 : Loss =  0.34379867  Acc:  0.8797333 Val_loss =  0.4474021 Val_acc =  0.8454\n",
            "Iteration  5394 : Loss =  0.3437919  Acc:  0.8797333 Val_loss =  0.44740826 Val_acc =  0.8454\n",
            "Iteration  5395 : Loss =  0.34378514  Acc:  0.87975 Val_loss =  0.44741416 Val_acc =  0.8454\n",
            "Iteration  5396 : Loss =  0.34377837  Acc:  0.8797333 Val_loss =  0.4474205 Val_acc =  0.8454\n",
            "Iteration  5397 : Loss =  0.3437716  Acc:  0.87975 Val_loss =  0.44742632 Val_acc =  0.8454\n",
            "Iteration  5398 : Loss =  0.34376484  Acc:  0.87975 Val_loss =  0.4474326 Val_acc =  0.8454\n",
            "Iteration  5399 : Loss =  0.3437581  Acc:  0.87975 Val_loss =  0.44743857 Val_acc =  0.8454\n",
            "Iteration  5400 : Loss =  0.34375137  Acc:  0.87975 Val_loss =  0.44744468 Val_acc =  0.8454\n",
            "Iteration  5401 : Loss =  0.34374464  Acc:  0.87976664 Val_loss =  0.44745082 Val_acc =  0.8454\n",
            "Iteration  5402 : Loss =  0.3437378  Acc:  0.87978333 Val_loss =  0.44745684 Val_acc =  0.8454\n",
            "Iteration  5403 : Loss =  0.3437311  Acc:  0.87976664 Val_loss =  0.4474631 Val_acc =  0.8454\n",
            "Iteration  5404 : Loss =  0.34372434  Acc:  0.8798 Val_loss =  0.447469 Val_acc =  0.8454\n",
            "Iteration  5405 : Loss =  0.34371763  Acc:  0.87978333 Val_loss =  0.44747525 Val_acc =  0.8454\n",
            "Iteration  5406 : Loss =  0.34371087  Acc:  0.87981665 Val_loss =  0.44748124 Val_acc =  0.8454\n",
            "Iteration  5407 : Loss =  0.34370416  Acc:  0.87983334 Val_loss =  0.4474874 Val_acc =  0.8454\n",
            "Iteration  5408 : Loss =  0.3436974  Acc:  0.87985 Val_loss =  0.44749346 Val_acc =  0.8454\n",
            "Iteration  5409 : Loss =  0.3436907  Acc:  0.87985 Val_loss =  0.4474995 Val_acc =  0.8454\n",
            "Iteration  5410 : Loss =  0.34368393  Acc:  0.87986666 Val_loss =  0.44750577 Val_acc =  0.8454\n",
            "Iteration  5411 : Loss =  0.3436772  Acc:  0.87988335 Val_loss =  0.44751173 Val_acc =  0.8454\n",
            "Iteration  5412 : Loss =  0.34367046  Acc:  0.87988335 Val_loss =  0.44751796 Val_acc =  0.8454\n",
            "Iteration  5413 : Loss =  0.34366372  Acc:  0.87988335 Val_loss =  0.44752392 Val_acc =  0.8454\n",
            "Iteration  5414 : Loss =  0.343657  Acc:  0.87988335 Val_loss =  0.44753018 Val_acc =  0.8453\n",
            "Iteration  5415 : Loss =  0.34365025  Acc:  0.87988335 Val_loss =  0.44753623 Val_acc =  0.8453\n",
            "Iteration  5416 : Loss =  0.34364355  Acc:  0.87988335 Val_loss =  0.44754237 Val_acc =  0.8453\n",
            "Iteration  5417 : Loss =  0.34363678  Acc:  0.8799 Val_loss =  0.44754854 Val_acc =  0.8454\n",
            "Iteration  5418 : Loss =  0.34363008  Acc:  0.87988335 Val_loss =  0.44755465 Val_acc =  0.8454\n",
            "Iteration  5419 : Loss =  0.34362337  Acc:  0.8799 Val_loss =  0.4475608 Val_acc =  0.8454\n",
            "Iteration  5420 : Loss =  0.34361666  Acc:  0.87993336 Val_loss =  0.44756684 Val_acc =  0.8454\n",
            "Iteration  5421 : Loss =  0.3436099  Acc:  0.87993336 Val_loss =  0.44757304 Val_acc =  0.8454\n",
            "Iteration  5422 : Loss =  0.3436032  Acc:  0.87993336 Val_loss =  0.44757915 Val_acc =  0.8454\n",
            "Iteration  5423 : Loss =  0.3435965  Acc:  0.87993336 Val_loss =  0.4475853 Val_acc =  0.8454\n",
            "Iteration  5424 : Loss =  0.34358978  Acc:  0.87993336 Val_loss =  0.44759145 Val_acc =  0.8454\n",
            "Iteration  5425 : Loss =  0.34358305  Acc:  0.87993336 Val_loss =  0.4475975 Val_acc =  0.8454\n",
            "Iteration  5426 : Loss =  0.34357634  Acc:  0.87993336 Val_loss =  0.44760382 Val_acc =  0.8454\n",
            "Iteration  5427 : Loss =  0.34356964  Acc:  0.8799667 Val_loss =  0.44760975 Val_acc =  0.8454\n",
            "Iteration  5428 : Loss =  0.3435629  Acc:  0.87995 Val_loss =  0.4476161 Val_acc =  0.8454\n",
            "Iteration  5429 : Loss =  0.34355623  Acc:  0.87995 Val_loss =  0.44762197 Val_acc =  0.8454\n",
            "Iteration  5430 : Loss =  0.3435495  Acc:  0.8799667 Val_loss =  0.44762853 Val_acc =  0.8454\n",
            "Iteration  5431 : Loss =  0.34354278  Acc:  0.87995 Val_loss =  0.44763413 Val_acc =  0.8454\n",
            "Iteration  5432 : Loss =  0.34353608  Acc:  0.88 Val_loss =  0.44764093 Val_acc =  0.8454\n",
            "Iteration  5433 : Loss =  0.34352937  Acc:  0.87993336 Val_loss =  0.4476463 Val_acc =  0.8454\n",
            "Iteration  5434 : Loss =  0.3435227  Acc:  0.88 Val_loss =  0.4476534 Val_acc =  0.8454\n",
            "Iteration  5435 : Loss =  0.34351602  Acc:  0.87991667 Val_loss =  0.4476584 Val_acc =  0.8454\n",
            "Iteration  5436 : Loss =  0.3435093  Acc:  0.88 Val_loss =  0.4476661 Val_acc =  0.8454\n",
            "Iteration  5437 : Loss =  0.3435026  Acc:  0.87988335 Val_loss =  0.44767025 Val_acc =  0.8454\n",
            "Iteration  5438 : Loss =  0.34349597  Acc:  0.8800167 Val_loss =  0.4476791 Val_acc =  0.8453\n",
            "Iteration  5439 : Loss =  0.34348932  Acc:  0.87988335 Val_loss =  0.44768184 Val_acc =  0.8454\n",
            "Iteration  5440 : Loss =  0.3434827  Acc:  0.88 Val_loss =  0.44769257 Val_acc =  0.8454\n",
            "Iteration  5441 : Loss =  0.34347615  Acc:  0.87988335 Val_loss =  0.44769302 Val_acc =  0.8453\n",
            "Iteration  5442 : Loss =  0.34346968  Acc:  0.8800833 Val_loss =  0.44770724 Val_acc =  0.8454\n",
            "Iteration  5443 : Loss =  0.34346348  Acc:  0.87993336 Val_loss =  0.4477035 Val_acc =  0.8453\n",
            "Iteration  5444 : Loss =  0.34345758  Acc:  0.8799667 Val_loss =  0.44772422 Val_acc =  0.8454\n",
            "Iteration  5445 : Loss =  0.34345227  Acc:  0.87993336 Val_loss =  0.4477136 Val_acc =  0.8453\n",
            "Iteration  5446 : Loss =  0.3434481  Acc:  0.88005 Val_loss =  0.44774655 Val_acc =  0.8454\n",
            "Iteration  5447 : Loss =  0.3434459  Acc:  0.87993336 Val_loss =  0.4477251 Val_acc =  0.8455\n",
            "Iteration  5448 : Loss =  0.34344694  Acc:  0.8799833 Val_loss =  0.44778168 Val_acc =  0.8451\n",
            "Iteration  5449 : Loss =  0.3434535  Acc:  0.88 Val_loss =  0.4477454 Val_acc =  0.8455\n",
            "Iteration  5450 : Loss =  0.3434675  Acc:  0.87991667 Val_loss =  0.4478447 Val_acc =  0.8455\n",
            "Iteration  5451 : Loss =  0.3434914  Acc:  0.87995 Val_loss =  0.4477916 Val_acc =  0.8457\n",
            "Iteration  5452 : Loss =  0.3435182  Acc:  0.87978333 Val_loss =  0.44793856 Val_acc =  0.8456\n",
            "Iteration  5453 : Loss =  0.34353665  Acc:  0.87983334 Val_loss =  0.44785386 Val_acc =  0.8456\n",
            "Iteration  5454 : Loss =  0.34351894  Acc:  0.87976664 Val_loss =  0.44795796 Val_acc =  0.8458\n",
            "Iteration  5455 : Loss =  0.34346557  Acc:  0.87993336 Val_loss =  0.4478333 Val_acc =  0.8456\n",
            "Iteration  5456 : Loss =  0.34340447  Acc:  0.8800667 Val_loss =  0.44782305 Val_acc =  0.8446\n",
            "Iteration  5457 : Loss =  0.3433761  Acc:  0.8800833 Val_loss =  0.44781825 Val_acc =  0.8452\n",
            "Iteration  5458 : Loss =  0.34338686  Acc:  0.8801 Val_loss =  0.4477881 Val_acc =  0.8455\n",
            "Iteration  5459 : Loss =  0.34340626  Acc:  0.8799833 Val_loss =  0.44790137 Val_acc =  0.8453\n",
            "Iteration  5460 : Loss =  0.3434039  Acc:  0.8799667 Val_loss =  0.44783193 Val_acc =  0.8456\n",
            "Iteration  5461 : Loss =  0.34337598  Acc:  0.88011664 Val_loss =  0.44786885 Val_acc =  0.8447\n",
            "Iteration  5462 : Loss =  0.34334952  Acc:  0.8799667 Val_loss =  0.44784892 Val_acc =  0.8453\n",
            "Iteration  5463 : Loss =  0.34334356  Acc:  0.88 Val_loss =  0.44781563 Val_acc =  0.8451\n",
            "Iteration  5464 : Loss =  0.34334844  Acc:  0.88005 Val_loss =  0.44790313 Val_acc =  0.8453\n",
            "Iteration  5465 : Loss =  0.34334406  Acc:  0.8800667 Val_loss =  0.4478352 Val_acc =  0.8454\n",
            "Iteration  5466 : Loss =  0.34332585  Acc:  0.88 Val_loss =  0.44788644 Val_acc =  0.8452\n",
            "Iteration  5467 : Loss =  0.34330982  Acc:  0.87995 Val_loss =  0.44786558 Val_acc =  0.8451\n",
            "Iteration  5468 : Loss =  0.3433069  Acc:  0.88 Val_loss =  0.44784698 Val_acc =  0.845\n",
            "Iteration  5469 : Loss =  0.34330878  Acc:  0.8801 Val_loss =  0.44792315 Val_acc =  0.845\n",
            "Iteration  5470 : Loss =  0.34330148  Acc:  0.8799667 Val_loss =  0.44785795 Val_acc =  0.845\n",
            "Iteration  5471 : Loss =  0.34328464  Acc:  0.88013333 Val_loss =  0.4479088 Val_acc =  0.8454\n",
            "Iteration  5472 : Loss =  0.3432713  Acc:  0.87991667 Val_loss =  0.4478857 Val_acc =  0.8454\n",
            "Iteration  5473 : Loss =  0.34326863  Acc:  0.8799833 Val_loss =  0.4478798 Val_acc =  0.845\n",
            "Iteration  5474 : Loss =  0.34326938  Acc:  0.88013333 Val_loss =  0.44794077 Val_acc =  0.8449\n",
            "Iteration  5475 : Loss =  0.34326297  Acc:  0.87991667 Val_loss =  0.44788745 Val_acc =  0.8451\n",
            "Iteration  5476 : Loss =  0.3432494  Acc:  0.8800167 Val_loss =  0.44793525 Val_acc =  0.8452\n",
            "Iteration  5477 : Loss =  0.3432378  Acc:  0.87988335 Val_loss =  0.44791344 Val_acc =  0.8452\n",
            "Iteration  5478 : Loss =  0.34323308  Acc:  0.87993336 Val_loss =  0.44791308 Val_acc =  0.8453\n",
            "Iteration  5479 : Loss =  0.34323078  Acc:  0.8800333 Val_loss =  0.44795543 Val_acc =  0.8452\n",
            "Iteration  5480 : Loss =  0.34322467  Acc:  0.87991667 Val_loss =  0.44791874 Val_acc =  0.845\n",
            "Iteration  5481 : Loss =  0.34321472  Acc:  0.8799833 Val_loss =  0.44795898 Val_acc =  0.845\n",
            "Iteration  5482 : Loss =  0.34320578  Acc:  0.8800167 Val_loss =  0.44794306 Val_acc =  0.8453\n",
            "Iteration  5483 : Loss =  0.3432002  Acc:  0.8799667 Val_loss =  0.4479468 Val_acc =  0.8453\n",
            "Iteration  5484 : Loss =  0.3431952  Acc:  0.8800667 Val_loss =  0.4479752 Val_acc =  0.8454\n",
            "Iteration  5485 : Loss =  0.34318823  Acc:  0.8799833 Val_loss =  0.44795308 Val_acc =  0.8451\n",
            "Iteration  5486 : Loss =  0.34317988  Acc:  0.88005 Val_loss =  0.44798136 Val_acc =  0.8455\n",
            "Iteration  5487 : Loss =  0.3431728  Acc:  0.88 Val_loss =  0.4479742 Val_acc =  0.8453\n",
            "Iteration  5488 : Loss =  0.3431673  Acc:  0.87995 Val_loss =  0.4479796 Val_acc =  0.8453\n",
            "Iteration  5489 : Loss =  0.34316152  Acc:  0.8799833 Val_loss =  0.44799936 Val_acc =  0.8452\n",
            "Iteration  5490 : Loss =  0.3431541  Acc:  0.88 Val_loss =  0.4479875 Val_acc =  0.8453\n",
            "Iteration  5491 : Loss =  0.34314615  Acc:  0.88011664 Val_loss =  0.44800508 Val_acc =  0.8454\n",
            "Iteration  5492 : Loss =  0.34313938  Acc:  0.8800667 Val_loss =  0.4480063 Val_acc =  0.8452\n",
            "Iteration  5493 : Loss =  0.34313378  Acc:  0.87995 Val_loss =  0.44800892 Val_acc =  0.8454\n",
            "Iteration  5494 : Loss =  0.34312794  Acc:  0.8800333 Val_loss =  0.44802567 Val_acc =  0.8452\n",
            "Iteration  5495 : Loss =  0.34312093  Acc:  0.8799667 Val_loss =  0.4480203 Val_acc =  0.8454\n",
            "Iteration  5496 : Loss =  0.34311345  Acc:  0.8801 Val_loss =  0.44803217 Val_acc =  0.8452\n",
            "Iteration  5497 : Loss =  0.34310663  Acc:  0.88011664 Val_loss =  0.44803858 Val_acc =  0.8454\n",
            "Iteration  5498 : Loss =  0.3431005  Acc:  0.8799833 Val_loss =  0.44803768 Val_acc =  0.8452\n",
            "Iteration  5499 : Loss =  0.34309435  Acc:  0.8800667 Val_loss =  0.44805482 Val_acc =  0.8454\n",
            "Iteration  5500 : Loss =  0.34308767  Acc:  0.8799833 Val_loss =  0.44805145 Val_acc =  0.8452\n",
            "Iteration  5501 : Loss =  0.34308073  Acc:  0.8800833 Val_loss =  0.44806167 Val_acc =  0.8452\n",
            "Iteration  5502 : Loss =  0.34307405  Acc:  0.88015 Val_loss =  0.44806954 Val_acc =  0.8453\n",
            "Iteration  5503 : Loss =  0.34306777  Acc:  0.8799667 Val_loss =  0.44806778 Val_acc =  0.8451\n",
            "Iteration  5504 : Loss =  0.34306133  Acc:  0.8800667 Val_loss =  0.44808507 Val_acc =  0.8453\n",
            "Iteration  5505 : Loss =  0.34305465  Acc:  0.8799667 Val_loss =  0.4480808 Val_acc =  0.8451\n",
            "Iteration  5506 : Loss =  0.34304792  Acc:  0.8800833 Val_loss =  0.44809213 Val_acc =  0.8452\n",
            "Iteration  5507 : Loss =  0.34304133  Acc:  0.88011664 Val_loss =  0.44809872 Val_acc =  0.8453\n",
            "Iteration  5508 : Loss =  0.343035  Acc:  0.8799667 Val_loss =  0.44809893 Val_acc =  0.8451\n",
            "Iteration  5509 : Loss =  0.34302858  Acc:  0.88016665 Val_loss =  0.4481145 Val_acc =  0.8453\n",
            "Iteration  5510 : Loss =  0.34302202  Acc:  0.8799667 Val_loss =  0.44811085 Val_acc =  0.8451\n",
            "Iteration  5511 : Loss =  0.3430153  Acc:  0.8800833 Val_loss =  0.44812357 Val_acc =  0.8453\n",
            "Iteration  5512 : Loss =  0.34300867  Acc:  0.88005 Val_loss =  0.44812754 Val_acc =  0.8452\n",
            "Iteration  5513 : Loss =  0.34300226  Acc:  0.88 Val_loss =  0.44813097 Val_acc =  0.8451\n",
            "Iteration  5514 : Loss =  0.34299582  Acc:  0.8801 Val_loss =  0.4481433 Val_acc =  0.8453\n",
            "Iteration  5515 : Loss =  0.34298933  Acc:  0.88 Val_loss =  0.4481422 Val_acc =  0.8451\n",
            "Iteration  5516 : Loss =  0.3429827  Acc:  0.88011664 Val_loss =  0.44815436 Val_acc =  0.8453\n",
            "Iteration  5517 : Loss =  0.34297618  Acc:  0.8800833 Val_loss =  0.44815692 Val_acc =  0.8451\n",
            "Iteration  5518 : Loss =  0.3429697  Acc:  0.8800333 Val_loss =  0.448163 Val_acc =  0.8452\n",
            "Iteration  5519 : Loss =  0.34296322  Acc:  0.88013333 Val_loss =  0.44817206 Val_acc =  0.8453\n",
            "Iteration  5520 : Loss =  0.3429567  Acc:  0.8800167 Val_loss =  0.44817382 Val_acc =  0.8451\n",
            "Iteration  5521 : Loss =  0.34295017  Acc:  0.88013333 Val_loss =  0.4481839 Val_acc =  0.8453\n",
            "Iteration  5522 : Loss =  0.3429436  Acc:  0.8800833 Val_loss =  0.4481874 Val_acc =  0.8451\n",
            "Iteration  5523 : Loss =  0.34293714  Acc:  0.8800667 Val_loss =  0.44819418 Val_acc =  0.8452\n",
            "Iteration  5524 : Loss =  0.34293067  Acc:  0.8800833 Val_loss =  0.44820157 Val_acc =  0.8452\n",
            "Iteration  5525 : Loss =  0.34292418  Acc:  0.8800167 Val_loss =  0.4482054 Val_acc =  0.8451\n",
            "Iteration  5526 : Loss =  0.34291765  Acc:  0.8800833 Val_loss =  0.44821382 Val_acc =  0.8453\n",
            "Iteration  5527 : Loss =  0.34291112  Acc:  0.88005 Val_loss =  0.44821855 Val_acc =  0.8451\n",
            "Iteration  5528 : Loss =  0.34290466  Acc:  0.8800667 Val_loss =  0.4482247 Val_acc =  0.8451\n",
            "Iteration  5529 : Loss =  0.3428982  Acc:  0.8801 Val_loss =  0.44823202 Val_acc =  0.8453\n",
            "Iteration  5530 : Loss =  0.3428917  Acc:  0.8800167 Val_loss =  0.44823632 Val_acc =  0.8451\n",
            "Iteration  5531 : Loss =  0.34288523  Acc:  0.8801 Val_loss =  0.44824427 Val_acc =  0.8452\n",
            "Iteration  5532 : Loss =  0.3428787  Acc:  0.88005 Val_loss =  0.4482493 Val_acc =  0.8452\n",
            "Iteration  5533 : Loss =  0.3428722  Acc:  0.8800667 Val_loss =  0.44825533 Val_acc =  0.8451\n",
            "Iteration  5534 : Loss =  0.34286574  Acc:  0.8800833 Val_loss =  0.44826275 Val_acc =  0.8453\n",
            "Iteration  5535 : Loss =  0.34285924  Acc:  0.8800333 Val_loss =  0.4482669 Val_acc =  0.8451\n",
            "Iteration  5536 : Loss =  0.34285274  Acc:  0.8801 Val_loss =  0.4482752 Val_acc =  0.8453\n",
            "Iteration  5537 : Loss =  0.34284624  Acc:  0.88005 Val_loss =  0.44827968 Val_acc =  0.8451\n",
            "Iteration  5538 : Loss =  0.34283978  Acc:  0.8800833 Val_loss =  0.44828653 Val_acc =  0.8451\n",
            "Iteration  5539 : Loss =  0.3428333  Acc:  0.8800833 Val_loss =  0.44829306 Val_acc =  0.8452\n",
            "Iteration  5540 : Loss =  0.3428268  Acc:  0.8800333 Val_loss =  0.44829786 Val_acc =  0.8451\n",
            "Iteration  5541 : Loss =  0.34282038  Acc:  0.8800833 Val_loss =  0.448306 Val_acc =  0.8452\n",
            "Iteration  5542 : Loss =  0.34281388  Acc:  0.8800333 Val_loss =  0.4483102 Val_acc =  0.8451\n",
            "Iteration  5543 : Loss =  0.3428074  Acc:  0.8800667 Val_loss =  0.44831777 Val_acc =  0.8452\n",
            "Iteration  5544 : Loss =  0.34280092  Acc:  0.88005 Val_loss =  0.44832325 Val_acc =  0.8451\n",
            "Iteration  5545 : Loss =  0.34279448  Acc:  0.8800333 Val_loss =  0.44832924 Val_acc =  0.8451\n",
            "Iteration  5546 : Loss =  0.34278795  Acc:  0.8800667 Val_loss =  0.44833633 Val_acc =  0.8452\n",
            "Iteration  5547 : Loss =  0.3427815  Acc:  0.8800333 Val_loss =  0.44834122 Val_acc =  0.8451\n",
            "Iteration  5548 : Loss =  0.34277508  Acc:  0.8800667 Val_loss =  0.44834864 Val_acc =  0.8452\n",
            "Iteration  5549 : Loss =  0.34276858  Acc:  0.8800333 Val_loss =  0.44835392 Val_acc =  0.8451\n",
            "Iteration  5550 : Loss =  0.3427621  Acc:  0.8800333 Val_loss =  0.44836044 Val_acc =  0.8452\n",
            "Iteration  5551 : Loss =  0.34275568  Acc:  0.8800667 Val_loss =  0.44836676 Val_acc =  0.8451\n",
            "Iteration  5552 : Loss =  0.34274918  Acc:  0.8800333 Val_loss =  0.44837245 Val_acc =  0.8452\n",
            "Iteration  5553 : Loss =  0.34274274  Acc:  0.8800833 Val_loss =  0.4483793 Val_acc =  0.8452\n",
            "Iteration  5554 : Loss =  0.3427363  Acc:  0.8800333 Val_loss =  0.44838485 Val_acc =  0.8452\n",
            "Iteration  5555 : Loss =  0.3427298  Acc:  0.8800333 Val_loss =  0.4483914 Val_acc =  0.8453\n",
            "Iteration  5556 : Loss =  0.34272337  Acc:  0.8800333 Val_loss =  0.44839755 Val_acc =  0.8453\n",
            "Iteration  5557 : Loss =  0.34271693  Acc:  0.88005 Val_loss =  0.4484035 Val_acc =  0.8453\n",
            "Iteration  5558 : Loss =  0.3427105  Acc:  0.8801 Val_loss =  0.4484101 Val_acc =  0.8453\n",
            "Iteration  5559 : Loss =  0.342704  Acc:  0.88005 Val_loss =  0.44841582 Val_acc =  0.8453\n",
            "Iteration  5560 : Loss =  0.34269753  Acc:  0.8800833 Val_loss =  0.44842237 Val_acc =  0.8453\n",
            "Iteration  5561 : Loss =  0.34269112  Acc:  0.88005 Val_loss =  0.44842845 Val_acc =  0.8453\n",
            "Iteration  5562 : Loss =  0.34268466  Acc:  0.8800833 Val_loss =  0.44843447 Val_acc =  0.8452\n",
            "Iteration  5563 : Loss =  0.3426782  Acc:  0.8800833 Val_loss =  0.44844112 Val_acc =  0.8453\n",
            "Iteration  5564 : Loss =  0.34267175  Acc:  0.8800833 Val_loss =  0.44844678 Val_acc =  0.8452\n",
            "Iteration  5565 : Loss =  0.34266534  Acc:  0.8800833 Val_loss =  0.44845346 Val_acc =  0.8453\n",
            "Iteration  5566 : Loss =  0.34265885  Acc:  0.8800833 Val_loss =  0.44845927 Val_acc =  0.8453\n",
            "Iteration  5567 : Loss =  0.34265244  Acc:  0.8800833 Val_loss =  0.44846562 Val_acc =  0.8453\n",
            "Iteration  5568 : Loss =  0.342646  Acc:  0.8800833 Val_loss =  0.44847196 Val_acc =  0.8453\n",
            "Iteration  5569 : Loss =  0.34263957  Acc:  0.8800833 Val_loss =  0.4484779 Val_acc =  0.8453\n",
            "Iteration  5570 : Loss =  0.3426331  Acc:  0.8800833 Val_loss =  0.4484845 Val_acc =  0.8453\n",
            "Iteration  5571 : Loss =  0.3426267  Acc:  0.8800833 Val_loss =  0.44849023 Val_acc =  0.8453\n",
            "Iteration  5572 : Loss =  0.34262025  Acc:  0.8800833 Val_loss =  0.44849688 Val_acc =  0.8453\n",
            "Iteration  5573 : Loss =  0.34261382  Acc:  0.8800833 Val_loss =  0.44850284 Val_acc =  0.8453\n",
            "Iteration  5574 : Loss =  0.34260738  Acc:  0.8800833 Val_loss =  0.4485092 Val_acc =  0.8453\n",
            "Iteration  5575 : Loss =  0.34260094  Acc:  0.8801 Val_loss =  0.44851542 Val_acc =  0.8453\n",
            "Iteration  5576 : Loss =  0.34259453  Acc:  0.8800833 Val_loss =  0.4485215 Val_acc =  0.8453\n",
            "Iteration  5577 : Loss =  0.34258813  Acc:  0.8801 Val_loss =  0.44852793 Val_acc =  0.8453\n",
            "Iteration  5578 : Loss =  0.34258166  Acc:  0.8800833 Val_loss =  0.44853398 Val_acc =  0.8453\n",
            "Iteration  5579 : Loss =  0.34257525  Acc:  0.8801 Val_loss =  0.44854033 Val_acc =  0.8453\n",
            "Iteration  5580 : Loss =  0.3425688  Acc:  0.8801 Val_loss =  0.4485465 Val_acc =  0.8453\n",
            "Iteration  5581 : Loss =  0.34256238  Acc:  0.8800833 Val_loss =  0.44855273 Val_acc =  0.8453\n",
            "Iteration  5582 : Loss =  0.342556  Acc:  0.8801 Val_loss =  0.44855908 Val_acc =  0.8453\n",
            "Iteration  5583 : Loss =  0.34254953  Acc:  0.8800667 Val_loss =  0.44856513 Val_acc =  0.8453\n",
            "Iteration  5584 : Loss =  0.34254313  Acc:  0.8800833 Val_loss =  0.44857147 Val_acc =  0.8452\n",
            "Iteration  5585 : Loss =  0.34253672  Acc:  0.8800833 Val_loss =  0.44857767 Val_acc =  0.8452\n",
            "Iteration  5586 : Loss =  0.3425303  Acc:  0.8800833 Val_loss =  0.4485839 Val_acc =  0.8451\n",
            "Iteration  5587 : Loss =  0.3425239  Acc:  0.8800667 Val_loss =  0.44859025 Val_acc =  0.8451\n",
            "Iteration  5588 : Loss =  0.34251744  Acc:  0.8800667 Val_loss =  0.4485964 Val_acc =  0.8451\n",
            "Iteration  5589 : Loss =  0.34251106  Acc:  0.88005 Val_loss =  0.44860274 Val_acc =  0.8451\n",
            "Iteration  5590 : Loss =  0.34250462  Acc:  0.88005 Val_loss =  0.44860888 Val_acc =  0.8451\n",
            "Iteration  5591 : Loss =  0.34249824  Acc:  0.88005 Val_loss =  0.44861522 Val_acc =  0.8451\n",
            "Iteration  5592 : Loss =  0.3424918  Acc:  0.88005 Val_loss =  0.44862142 Val_acc =  0.8451\n",
            "Iteration  5593 : Loss =  0.34248543  Acc:  0.88005 Val_loss =  0.44862774 Val_acc =  0.8451\n",
            "Iteration  5594 : Loss =  0.34247905  Acc:  0.88005 Val_loss =  0.448634 Val_acc =  0.8451\n",
            "Iteration  5595 : Loss =  0.34247258  Acc:  0.88005 Val_loss =  0.4486402 Val_acc =  0.8451\n",
            "Iteration  5596 : Loss =  0.3424662  Acc:  0.88005 Val_loss =  0.44864655 Val_acc =  0.8451\n",
            "Iteration  5597 : Loss =  0.3424598  Acc:  0.8800667 Val_loss =  0.44865268 Val_acc =  0.8451\n",
            "Iteration  5598 : Loss =  0.3424534  Acc:  0.8800667 Val_loss =  0.4486591 Val_acc =  0.8451\n",
            "Iteration  5599 : Loss =  0.342447  Acc:  0.8800667 Val_loss =  0.4486653 Val_acc =  0.8451\n",
            "Iteration  5600 : Loss =  0.34244063  Acc:  0.8800667 Val_loss =  0.44867152 Val_acc =  0.8451\n",
            "Iteration  5601 : Loss =  0.3424342  Acc:  0.88005 Val_loss =  0.44867784 Val_acc =  0.8451\n",
            "Iteration  5602 : Loss =  0.3424278  Acc:  0.88005 Val_loss =  0.4486841 Val_acc =  0.8451\n",
            "Iteration  5603 : Loss =  0.3424214  Acc:  0.88005 Val_loss =  0.44869044 Val_acc =  0.8451\n",
            "Iteration  5604 : Loss =  0.34241503  Acc:  0.8800333 Val_loss =  0.44869664 Val_acc =  0.8451\n",
            "Iteration  5605 : Loss =  0.34240866  Acc:  0.8800167 Val_loss =  0.44870293 Val_acc =  0.8452\n",
            "Iteration  5606 : Loss =  0.34240225  Acc:  0.8800333 Val_loss =  0.4487092 Val_acc =  0.8452\n",
            "Iteration  5607 : Loss =  0.34239584  Acc:  0.8800333 Val_loss =  0.44871554 Val_acc =  0.8451\n",
            "Iteration  5608 : Loss =  0.34238946  Acc:  0.8800333 Val_loss =  0.44872177 Val_acc =  0.8452\n",
            "Iteration  5609 : Loss =  0.3423831  Acc:  0.8800333 Val_loss =  0.44872802 Val_acc =  0.8452\n",
            "Iteration  5610 : Loss =  0.34237668  Acc:  0.8800333 Val_loss =  0.44873443 Val_acc =  0.8453\n",
            "Iteration  5611 : Loss =  0.3423703  Acc:  0.8800333 Val_loss =  0.44874063 Val_acc =  0.8453\n",
            "Iteration  5612 : Loss =  0.3423639  Acc:  0.88005 Val_loss =  0.44874698 Val_acc =  0.8452\n",
            "Iteration  5613 : Loss =  0.34235752  Acc:  0.8800333 Val_loss =  0.4487532 Val_acc =  0.8452\n",
            "Iteration  5614 : Loss =  0.34235117  Acc:  0.8800333 Val_loss =  0.44875956 Val_acc =  0.8452\n",
            "Iteration  5615 : Loss =  0.34234476  Acc:  0.8800333 Val_loss =  0.44876587 Val_acc =  0.8452\n",
            "Iteration  5616 : Loss =  0.3423384  Acc:  0.8800333 Val_loss =  0.44877216 Val_acc =  0.8452\n",
            "Iteration  5617 : Loss =  0.342332  Acc:  0.8800333 Val_loss =  0.44877848 Val_acc =  0.8452\n",
            "Iteration  5618 : Loss =  0.34232566  Acc:  0.8800167 Val_loss =  0.44878477 Val_acc =  0.8452\n",
            "Iteration  5619 : Loss =  0.34231928  Acc:  0.8800167 Val_loss =  0.44879106 Val_acc =  0.8452\n",
            "Iteration  5620 : Loss =  0.34231293  Acc:  0.8800167 Val_loss =  0.44879737 Val_acc =  0.8452\n",
            "Iteration  5621 : Loss =  0.34230652  Acc:  0.8800167 Val_loss =  0.44880366 Val_acc =  0.8452\n",
            "Iteration  5622 : Loss =  0.34230018  Acc:  0.8800167 Val_loss =  0.44881 Val_acc =  0.8452\n",
            "Iteration  5623 : Loss =  0.34229383  Acc:  0.8800167 Val_loss =  0.44881627 Val_acc =  0.8452\n",
            "Iteration  5624 : Loss =  0.34228742  Acc:  0.8800167 Val_loss =  0.44882265 Val_acc =  0.8452\n",
            "Iteration  5625 : Loss =  0.34228104  Acc:  0.8800167 Val_loss =  0.4488289 Val_acc =  0.8452\n",
            "Iteration  5626 : Loss =  0.34227467  Acc:  0.8800167 Val_loss =  0.44883534 Val_acc =  0.8452\n",
            "Iteration  5627 : Loss =  0.34226835  Acc:  0.8800167 Val_loss =  0.4488415 Val_acc =  0.8452\n",
            "Iteration  5628 : Loss =  0.34226194  Acc:  0.8800167 Val_loss =  0.44884795 Val_acc =  0.8452\n",
            "Iteration  5629 : Loss =  0.3422556  Acc:  0.8800167 Val_loss =  0.44885415 Val_acc =  0.8452\n",
            "Iteration  5630 : Loss =  0.34224924  Acc:  0.88 Val_loss =  0.44886065 Val_acc =  0.8452\n",
            "Iteration  5631 : Loss =  0.3422429  Acc:  0.88 Val_loss =  0.44886675 Val_acc =  0.8452\n",
            "Iteration  5632 : Loss =  0.34223652  Acc:  0.88 Val_loss =  0.4488734 Val_acc =  0.8452\n",
            "Iteration  5633 : Loss =  0.34223017  Acc:  0.88 Val_loss =  0.44887933 Val_acc =  0.8451\n",
            "Iteration  5634 : Loss =  0.34222382  Acc:  0.88 Val_loss =  0.44888613 Val_acc =  0.8452\n",
            "Iteration  5635 : Loss =  0.34221748  Acc:  0.88 Val_loss =  0.44889194 Val_acc =  0.8451\n",
            "Iteration  5636 : Loss =  0.34221113  Acc:  0.8800167 Val_loss =  0.4488989 Val_acc =  0.8452\n",
            "Iteration  5637 : Loss =  0.34220475  Acc:  0.8800167 Val_loss =  0.44890448 Val_acc =  0.845\n",
            "Iteration  5638 : Loss =  0.34219843  Acc:  0.8799833 Val_loss =  0.44891182 Val_acc =  0.8452\n",
            "Iteration  5639 : Loss =  0.34219208  Acc:  0.8799833 Val_loss =  0.448917 Val_acc =  0.845\n",
            "Iteration  5640 : Loss =  0.34218574  Acc:  0.88 Val_loss =  0.4489248 Val_acc =  0.8452\n",
            "Iteration  5641 : Loss =  0.34217942  Acc:  0.8799667 Val_loss =  0.44892934 Val_acc =  0.845\n",
            "Iteration  5642 : Loss =  0.3421731  Acc:  0.8800167 Val_loss =  0.44893798 Val_acc =  0.8451\n",
            "Iteration  5643 : Loss =  0.34216684  Acc:  0.88 Val_loss =  0.44894156 Val_acc =  0.8451\n",
            "Iteration  5644 : Loss =  0.34216055  Acc:  0.8800833 Val_loss =  0.44895157 Val_acc =  0.8451\n",
            "Iteration  5645 : Loss =  0.34215435  Acc:  0.88 Val_loss =  0.44895357 Val_acc =  0.8449\n",
            "Iteration  5646 : Loss =  0.3421482  Acc:  0.8800667 Val_loss =  0.44896573 Val_acc =  0.8451\n",
            "Iteration  5647 : Loss =  0.3421422  Acc:  0.8800333 Val_loss =  0.44896534 Val_acc =  0.845\n",
            "Iteration  5648 : Loss =  0.34213638  Acc:  0.88013333 Val_loss =  0.44898126 Val_acc =  0.8451\n",
            "Iteration  5649 : Loss =  0.34213093  Acc:  0.8801 Val_loss =  0.44897705 Val_acc =  0.8449\n",
            "Iteration  5650 : Loss =  0.342126  Acc:  0.8801 Val_loss =  0.44899946 Val_acc =  0.8451\n",
            "Iteration  5651 : Loss =  0.34212202  Acc:  0.88021666 Val_loss =  0.44898966 Val_acc =  0.8447\n",
            "Iteration  5652 : Loss =  0.34211943  Acc:  0.8800667 Val_loss =  0.44902357 Val_acc =  0.845\n",
            "Iteration  5653 : Loss =  0.34211928  Acc:  0.88013333 Val_loss =  0.44900596 Val_acc =  0.8448\n",
            "Iteration  5654 : Loss =  0.3421222  Acc:  0.88018334 Val_loss =  0.4490602 Val_acc =  0.8448\n",
            "Iteration  5655 : Loss =  0.34213027  Acc:  0.8800667 Val_loss =  0.44903314 Val_acc =  0.8446\n",
            "Iteration  5656 : Loss =  0.34214213  Acc:  0.8800667 Val_loss =  0.44911748 Val_acc =  0.8452\n",
            "Iteration  5657 : Loss =  0.3421588  Acc:  0.8800667 Val_loss =  0.44907656 Val_acc =  0.8457\n",
            "Iteration  5658 : Loss =  0.3421676  Acc:  0.88016665 Val_loss =  0.4491792 Val_acc =  0.8453\n",
            "Iteration  5659 : Loss =  0.34216484  Acc:  0.8800833 Val_loss =  0.44910356 Val_acc =  0.8455\n",
            "Iteration  5660 : Loss =  0.34213382  Acc:  0.88015 Val_loss =  0.44916698 Val_acc =  0.8453\n",
            "Iteration  5661 : Loss =  0.34209082  Acc:  0.8801 Val_loss =  0.44906718 Val_acc =  0.8448\n",
            "Iteration  5662 : Loss =  0.34205392  Acc:  0.88018334 Val_loss =  0.4490877 Val_acc =  0.845\n",
            "Iteration  5663 : Loss =  0.342042  Acc:  0.8800833 Val_loss =  0.44907105 Val_acc =  0.8451\n",
            "Iteration  5664 : Loss =  0.3420518  Acc:  0.88026667 Val_loss =  0.44908297 Val_acc =  0.8448\n",
            "Iteration  5665 : Loss =  0.34206423  Acc:  0.8800667 Val_loss =  0.4491422 Val_acc =  0.8451\n",
            "Iteration  5666 : Loss =  0.3420629  Acc:  0.88015 Val_loss =  0.44910675 Val_acc =  0.8446\n",
            "Iteration  5667 : Loss =  0.342042  Acc:  0.8802 Val_loss =  0.4491464 Val_acc =  0.8448\n",
            "Iteration  5668 : Loss =  0.34201705  Acc:  0.8803667 Val_loss =  0.44909477 Val_acc =  0.8447\n",
            "Iteration  5669 : Loss =  0.34200338  Acc:  0.8802 Val_loss =  0.44911587 Val_acc =  0.8451\n",
            "Iteration  5670 : Loss =  0.34200424  Acc:  0.8800833 Val_loss =  0.44912627 Val_acc =  0.845\n",
            "Iteration  5671 : Loss =  0.342009  Acc:  0.8803 Val_loss =  0.44913092 Val_acc =  0.8449\n",
            "Iteration  5672 : Loss =  0.3420048  Acc:  0.88015 Val_loss =  0.4491632 Val_acc =  0.8449\n",
            "Iteration  5673 : Loss =  0.3419906  Acc:  0.88035 Val_loss =  0.44913578 Val_acc =  0.8448\n",
            "Iteration  5674 : Loss =  0.3419743  Acc:  0.8801 Val_loss =  0.4491519 Val_acc =  0.8451\n",
            "Iteration  5675 : Loss =  0.34196544  Acc:  0.8800167 Val_loss =  0.4491455 Val_acc =  0.8451\n",
            "Iteration  5676 : Loss =  0.34196442  Acc:  0.88028336 Val_loss =  0.44915643 Val_acc =  0.845\n",
            "Iteration  5677 : Loss =  0.34196374  Acc:  0.8800667 Val_loss =  0.44917762 Val_acc =  0.8451\n",
            "Iteration  5678 : Loss =  0.34195736  Acc:  0.8803667 Val_loss =  0.4491708 Val_acc =  0.8447\n",
            "Iteration  5679 : Loss =  0.34194553  Acc:  0.8801 Val_loss =  0.44918296 Val_acc =  0.8451\n",
            "Iteration  5680 : Loss =  0.34193438  Acc:  0.88005 Val_loss =  0.44917843 Val_acc =  0.8452\n",
            "Iteration  5681 : Loss =  0.34192806  Acc:  0.8801 Val_loss =  0.44918287 Val_acc =  0.8452\n",
            "Iteration  5682 : Loss =  0.34192526  Acc:  0.8800167 Val_loss =  0.44920072 Val_acc =  0.8451\n",
            "Iteration  5683 : Loss =  0.3419215  Acc:  0.88028336 Val_loss =  0.4491983 Val_acc =  0.8448\n",
            "Iteration  5684 : Loss =  0.34191406  Acc:  0.8801 Val_loss =  0.4492141 Val_acc =  0.8451\n",
            "Iteration  5685 : Loss =  0.34190455  Acc:  0.88015 Val_loss =  0.44921073 Val_acc =  0.845\n",
            "Iteration  5686 : Loss =  0.34189636  Acc:  0.8800667 Val_loss =  0.4492147 Val_acc =  0.8451\n",
            "Iteration  5687 : Loss =  0.34189084  Acc:  0.88016665 Val_loss =  0.4492291 Val_acc =  0.845\n",
            "Iteration  5688 : Loss =  0.34188658  Acc:  0.88018334 Val_loss =  0.44922525 Val_acc =  0.845\n",
            "Iteration  5689 : Loss =  0.34188107  Acc:  0.88011664 Val_loss =  0.44924596 Val_acc =  0.8451\n",
            "Iteration  5690 : Loss =  0.34187365  Acc:  0.88016665 Val_loss =  0.44923946 Val_acc =  0.845\n",
            "Iteration  5691 : Loss =  0.34186563  Acc:  0.88015 Val_loss =  0.44925064 Val_acc =  0.845\n",
            "Iteration  5692 : Loss =  0.34185877  Acc:  0.88011664 Val_loss =  0.4492561 Val_acc =  0.8451\n",
            "Iteration  5693 : Loss =  0.3418533  Acc:  0.8800667 Val_loss =  0.44925705 Val_acc =  0.8451\n",
            "Iteration  5694 : Loss =  0.3418481  Acc:  0.88011664 Val_loss =  0.44927514 Val_acc =  0.845\n",
            "Iteration  5695 : Loss =  0.341842  Acc:  0.88015 Val_loss =  0.44926932 Val_acc =  0.845\n",
            "Iteration  5696 : Loss =  0.34183493  Acc:  0.88013333 Val_loss =  0.4492859 Val_acc =  0.845\n",
            "Iteration  5697 : Loss =  0.3418278  Acc:  0.88013333 Val_loss =  0.4492839 Val_acc =  0.8451\n",
            "Iteration  5698 : Loss =  0.34182134  Acc:  0.8801 Val_loss =  0.4492927 Val_acc =  0.8451\n",
            "Iteration  5699 : Loss =  0.34181562  Acc:  0.88016665 Val_loss =  0.44930187 Val_acc =  0.845\n",
            "Iteration  5700 : Loss =  0.3418099  Acc:  0.88011664 Val_loss =  0.44930282 Val_acc =  0.8452\n",
            "Iteration  5701 : Loss =  0.34180364  Acc:  0.88015 Val_loss =  0.4493169 Val_acc =  0.8449\n",
            "Iteration  5702 : Loss =  0.34179696  Acc:  0.88011664 Val_loss =  0.4493155 Val_acc =  0.8451\n",
            "Iteration  5703 : Loss =  0.3417903  Acc:  0.88013333 Val_loss =  0.44932684 Val_acc =  0.8451\n",
            "Iteration  5704 : Loss =  0.34178397  Acc:  0.8800833 Val_loss =  0.44933048 Val_acc =  0.8451\n",
            "Iteration  5705 : Loss =  0.34177807  Acc:  0.88016665 Val_loss =  0.44933698 Val_acc =  0.8451\n",
            "Iteration  5706 : Loss =  0.3417721  Acc:  0.88016665 Val_loss =  0.44934595 Val_acc =  0.845\n",
            "Iteration  5707 : Loss =  0.34176585  Acc:  0.88013333 Val_loss =  0.449349 Val_acc =  0.8451\n",
            "Iteration  5708 : Loss =  0.34175938  Acc:  0.8801 Val_loss =  0.44935817 Val_acc =  0.845\n",
            "Iteration  5709 : Loss =  0.34175286  Acc:  0.88015 Val_loss =  0.4493624 Val_acc =  0.8451\n",
            "Iteration  5710 : Loss =  0.34174666  Acc:  0.88013333 Val_loss =  0.4493691 Val_acc =  0.845\n",
            "Iteration  5711 : Loss =  0.34174055  Acc:  0.88011664 Val_loss =  0.44937682 Val_acc =  0.845\n",
            "Iteration  5712 : Loss =  0.3417345  Acc:  0.88016665 Val_loss =  0.44938114 Val_acc =  0.8451\n",
            "Iteration  5713 : Loss =  0.34172833  Acc:  0.8801 Val_loss =  0.44938993 Val_acc =  0.845\n",
            "Iteration  5714 : Loss =  0.34172198  Acc:  0.88015 Val_loss =  0.44939452 Val_acc =  0.8451\n",
            "Iteration  5715 : Loss =  0.3417156  Acc:  0.88015 Val_loss =  0.44940126 Val_acc =  0.845\n",
            "Iteration  5716 : Loss =  0.34170938  Acc:  0.88016665 Val_loss =  0.4494086 Val_acc =  0.8451\n",
            "Iteration  5717 : Loss =  0.34170324  Acc:  0.88013333 Val_loss =  0.4494128 Val_acc =  0.8451\n",
            "Iteration  5718 : Loss =  0.34169713  Acc:  0.88011664 Val_loss =  0.44942245 Val_acc =  0.845\n",
            "Iteration  5719 : Loss =  0.3416909  Acc:  0.88016665 Val_loss =  0.44942555 Val_acc =  0.8451\n",
            "Iteration  5720 : Loss =  0.34168464  Acc:  0.88011664 Val_loss =  0.44943467 Val_acc =  0.845\n",
            "Iteration  5721 : Loss =  0.34167835  Acc:  0.8801 Val_loss =  0.44943932 Val_acc =  0.845\n",
            "Iteration  5722 : Loss =  0.34167212  Acc:  0.88013333 Val_loss =  0.44944608 Val_acc =  0.845\n",
            "Iteration  5723 : Loss =  0.34166595  Acc:  0.88015 Val_loss =  0.4494534 Val_acc =  0.8449\n",
            "Iteration  5724 : Loss =  0.34165978  Acc:  0.88013333 Val_loss =  0.4494579 Val_acc =  0.845\n",
            "Iteration  5725 : Loss =  0.34165365  Acc:  0.88015 Val_loss =  0.44946688 Val_acc =  0.8449\n",
            "Iteration  5726 : Loss =  0.3416474  Acc:  0.88013333 Val_loss =  0.4494707 Val_acc =  0.845\n",
            "Iteration  5727 : Loss =  0.3416412  Acc:  0.88015 Val_loss =  0.4494793 Val_acc =  0.8449\n",
            "Iteration  5728 : Loss =  0.34163496  Acc:  0.88011664 Val_loss =  0.44948417 Val_acc =  0.8449\n",
            "Iteration  5729 : Loss =  0.3416288  Acc:  0.88015 Val_loss =  0.44949132 Val_acc =  0.8449\n",
            "Iteration  5730 : Loss =  0.3416226  Acc:  0.88013333 Val_loss =  0.44949785 Val_acc =  0.8449\n",
            "Iteration  5731 : Loss =  0.3416164  Acc:  0.8801 Val_loss =  0.4495036 Val_acc =  0.8448\n",
            "Iteration  5732 : Loss =  0.34161025  Acc:  0.88013333 Val_loss =  0.44951102 Val_acc =  0.8449\n",
            "Iteration  5733 : Loss =  0.34160402  Acc:  0.8801 Val_loss =  0.4495165 Val_acc =  0.8448\n",
            "Iteration  5734 : Loss =  0.3415978  Acc:  0.88011664 Val_loss =  0.44952354 Val_acc =  0.8449\n",
            "Iteration  5735 : Loss =  0.3415916  Acc:  0.88013333 Val_loss =  0.4495298 Val_acc =  0.8449\n",
            "Iteration  5736 : Loss =  0.34158546  Acc:  0.88011664 Val_loss =  0.44953603 Val_acc =  0.8449\n",
            "Iteration  5737 : Loss =  0.3415793  Acc:  0.88011664 Val_loss =  0.44954303 Val_acc =  0.8449\n",
            "Iteration  5738 : Loss =  0.34157312  Acc:  0.8800833 Val_loss =  0.44954872 Val_acc =  0.8448\n",
            "Iteration  5739 : Loss =  0.34156692  Acc:  0.88011664 Val_loss =  0.44955587 Val_acc =  0.8449\n",
            "Iteration  5740 : Loss =  0.34156075  Acc:  0.88011664 Val_loss =  0.4495618 Val_acc =  0.8449\n",
            "Iteration  5741 : Loss =  0.34155452  Acc:  0.88013333 Val_loss =  0.44956836 Val_acc =  0.8449\n",
            "Iteration  5742 : Loss =  0.34154835  Acc:  0.88015 Val_loss =  0.44957516 Val_acc =  0.8449\n",
            "Iteration  5743 : Loss =  0.34154218  Acc:  0.88016665 Val_loss =  0.44958097 Val_acc =  0.8449\n",
            "Iteration  5744 : Loss =  0.34153605  Acc:  0.88015 Val_loss =  0.4495884 Val_acc =  0.8448\n",
            "Iteration  5745 : Loss =  0.34152985  Acc:  0.88013333 Val_loss =  0.4495937 Val_acc =  0.8448\n",
            "Iteration  5746 : Loss =  0.3415237  Acc:  0.88015 Val_loss =  0.44960126 Val_acc =  0.8448\n",
            "Iteration  5747 : Loss =  0.3415175  Acc:  0.88015 Val_loss =  0.44960678 Val_acc =  0.8448\n",
            "Iteration  5748 : Loss =  0.34151134  Acc:  0.88016665 Val_loss =  0.44961396 Val_acc =  0.8448\n",
            "Iteration  5749 : Loss =  0.34150514  Acc:  0.88016665 Val_loss =  0.44961998 Val_acc =  0.8448\n",
            "Iteration  5750 : Loss =  0.341499  Acc:  0.88015 Val_loss =  0.44962662 Val_acc =  0.8448\n",
            "Iteration  5751 : Loss =  0.34149283  Acc:  0.88016665 Val_loss =  0.44963315 Val_acc =  0.8448\n",
            "Iteration  5752 : Loss =  0.34148666  Acc:  0.88015 Val_loss =  0.4496394 Val_acc =  0.8448\n",
            "Iteration  5753 : Loss =  0.34148052  Acc:  0.88015 Val_loss =  0.4496461 Val_acc =  0.8448\n",
            "Iteration  5754 : Loss =  0.34147432  Acc:  0.88015 Val_loss =  0.44965243 Val_acc =  0.8448\n",
            "Iteration  5755 : Loss =  0.34146816  Acc:  0.88015 Val_loss =  0.44965893 Val_acc =  0.8448\n",
            "Iteration  5756 : Loss =  0.34146205  Acc:  0.88015 Val_loss =  0.44966552 Val_acc =  0.8448\n",
            "Iteration  5757 : Loss =  0.34145585  Acc:  0.88015 Val_loss =  0.44967172 Val_acc =  0.8448\n",
            "Iteration  5758 : Loss =  0.3414497  Acc:  0.88016665 Val_loss =  0.4496786 Val_acc =  0.8448\n",
            "Iteration  5759 : Loss =  0.34144357  Acc:  0.88016665 Val_loss =  0.44968462 Val_acc =  0.8448\n",
            "Iteration  5760 : Loss =  0.34143737  Acc:  0.88016665 Val_loss =  0.4496916 Val_acc =  0.8448\n",
            "Iteration  5761 : Loss =  0.34143126  Acc:  0.88016665 Val_loss =  0.4496976 Val_acc =  0.8448\n",
            "Iteration  5762 : Loss =  0.34142506  Acc:  0.88016665 Val_loss =  0.4497045 Val_acc =  0.8448\n",
            "Iteration  5763 : Loss =  0.34141892  Acc:  0.88016665 Val_loss =  0.44971076 Val_acc =  0.8448\n",
            "Iteration  5764 : Loss =  0.34141275  Acc:  0.88018334 Val_loss =  0.44971734 Val_acc =  0.8448\n",
            "Iteration  5765 : Loss =  0.34140664  Acc:  0.88018334 Val_loss =  0.44972384 Val_acc =  0.8448\n",
            "Iteration  5766 : Loss =  0.34140047  Acc:  0.88018334 Val_loss =  0.44973028 Val_acc =  0.8448\n",
            "Iteration  5767 : Loss =  0.34139434  Acc:  0.8802 Val_loss =  0.4497368 Val_acc =  0.8448\n",
            "Iteration  5768 : Loss =  0.3413882  Acc:  0.8802 Val_loss =  0.44974327 Val_acc =  0.8448\n",
            "Iteration  5769 : Loss =  0.34138203  Acc:  0.8802 Val_loss =  0.4497498 Val_acc =  0.8448\n",
            "Iteration  5770 : Loss =  0.3413759  Acc:  0.8802 Val_loss =  0.44975626 Val_acc =  0.8448\n",
            "Iteration  5771 : Loss =  0.34136975  Acc:  0.88021666 Val_loss =  0.4497627 Val_acc =  0.8448\n",
            "Iteration  5772 : Loss =  0.3413636  Acc:  0.88021666 Val_loss =  0.44976944 Val_acc =  0.8448\n",
            "Iteration  5773 : Loss =  0.3413575  Acc:  0.88023335 Val_loss =  0.44977558 Val_acc =  0.8447\n",
            "Iteration  5774 : Loss =  0.34135136  Acc:  0.88021666 Val_loss =  0.44978252 Val_acc =  0.8447\n",
            "Iteration  5775 : Loss =  0.3413452  Acc:  0.88021666 Val_loss =  0.44978857 Val_acc =  0.8447\n",
            "Iteration  5776 : Loss =  0.34133905  Acc:  0.88021666 Val_loss =  0.4497956 Val_acc =  0.8447\n",
            "Iteration  5777 : Loss =  0.34133294  Acc:  0.88021666 Val_loss =  0.44980156 Val_acc =  0.8447\n",
            "Iteration  5778 : Loss =  0.34132683  Acc:  0.88021666 Val_loss =  0.44980866 Val_acc =  0.8447\n",
            "Iteration  5779 : Loss =  0.34132066  Acc:  0.88021666 Val_loss =  0.44981456 Val_acc =  0.8447\n",
            "Iteration  5780 : Loss =  0.34131452  Acc:  0.88021666 Val_loss =  0.44982174 Val_acc =  0.8447\n",
            "Iteration  5781 : Loss =  0.3413084  Acc:  0.88021666 Val_loss =  0.4498275 Val_acc =  0.8447\n",
            "Iteration  5782 : Loss =  0.34130228  Acc:  0.88023335 Val_loss =  0.44983485 Val_acc =  0.8447\n",
            "Iteration  5783 : Loss =  0.34129614  Acc:  0.88021666 Val_loss =  0.44984037 Val_acc =  0.8447\n",
            "Iteration  5784 : Loss =  0.34129003  Acc:  0.88023335 Val_loss =  0.44984815 Val_acc =  0.8447\n",
            "Iteration  5785 : Loss =  0.34128392  Acc:  0.8802 Val_loss =  0.44985318 Val_acc =  0.8447\n",
            "Iteration  5786 : Loss =  0.3412778  Acc:  0.88023335 Val_loss =  0.44986153 Val_acc =  0.8447\n",
            "Iteration  5787 : Loss =  0.34127167  Acc:  0.8802 Val_loss =  0.44986588 Val_acc =  0.8447\n",
            "Iteration  5788 : Loss =  0.34126556  Acc:  0.88025 Val_loss =  0.4498751 Val_acc =  0.8447\n",
            "Iteration  5789 : Loss =  0.34125948  Acc:  0.88016665 Val_loss =  0.44987833 Val_acc =  0.8447\n",
            "Iteration  5790 : Loss =  0.3412534  Acc:  0.88025 Val_loss =  0.44988906 Val_acc =  0.8448\n",
            "Iteration  5791 : Loss =  0.34124726  Acc:  0.88016665 Val_loss =  0.44989043 Val_acc =  0.8447\n",
            "Iteration  5792 : Loss =  0.34124127  Acc:  0.88025 Val_loss =  0.44990346 Val_acc =  0.8447\n",
            "Iteration  5793 : Loss =  0.34123525  Acc:  0.88016665 Val_loss =  0.44990215 Val_acc =  0.8446\n",
            "Iteration  5794 : Loss =  0.34122935  Acc:  0.8803167 Val_loss =  0.44991884 Val_acc =  0.8447\n",
            "Iteration  5795 : Loss =  0.34122348  Acc:  0.88016665 Val_loss =  0.44991317 Val_acc =  0.8446\n",
            "Iteration  5796 : Loss =  0.34121782  Acc:  0.8803833 Val_loss =  0.4499358 Val_acc =  0.8446\n",
            "Iteration  5797 : Loss =  0.34121242  Acc:  0.88016665 Val_loss =  0.4499235 Val_acc =  0.8446\n",
            "Iteration  5798 : Loss =  0.34120744  Acc:  0.88045 Val_loss =  0.4499559 Val_acc =  0.8447\n",
            "Iteration  5799 : Loss =  0.34120318  Acc:  0.88013333 Val_loss =  0.44993314 Val_acc =  0.8447\n",
            "Iteration  5800 : Loss =  0.3412  Acc:  0.8805 Val_loss =  0.44998214 Val_acc =  0.8449\n",
            "Iteration  5801 : Loss =  0.34119856  Acc:  0.8801 Val_loss =  0.44994366 Val_acc =  0.8447\n",
            "Iteration  5802 : Loss =  0.34119955  Acc:  0.88053334 Val_loss =  0.45002002 Val_acc =  0.8451\n",
            "Iteration  5803 : Loss =  0.34120408  Acc:  0.88026667 Val_loss =  0.44995937 Val_acc =  0.8447\n",
            "Iteration  5804 : Loss =  0.34121203  Acc:  0.8804333 Val_loss =  0.45007607 Val_acc =  0.845\n",
            "Iteration  5805 : Loss =  0.34122336  Acc:  0.88035 Val_loss =  0.44998583 Val_acc =  0.845\n",
            "Iteration  5806 : Loss =  0.34123173  Acc:  0.8802 Val_loss =  0.45013848 Val_acc =  0.8452\n",
            "Iteration  5807 : Loss =  0.34123152  Acc:  0.8803333 Val_loss =  0.45000947 Val_acc =  0.845\n",
            "Iteration  5808 : Loss =  0.3412122  Acc:  0.88028336 Val_loss =  0.4501417 Val_acc =  0.8449\n",
            "Iteration  5809 : Loss =  0.34117877  Acc:  0.88035 Val_loss =  0.45000044 Val_acc =  0.8449\n",
            "Iteration  5810 : Loss =  0.34114423  Acc:  0.88055 Val_loss =  0.45006144 Val_acc =  0.8449\n",
            "Iteration  5811 : Loss =  0.34112582  Acc:  0.8802 Val_loss =  0.45002002 Val_acc =  0.8447\n",
            "Iteration  5812 : Loss =  0.34112695  Acc:  0.88011664 Val_loss =  0.45002002 Val_acc =  0.8448\n",
            "Iteration  5813 : Loss =  0.34113678  Acc:  0.8805 Val_loss =  0.45009825 Val_acc =  0.8449\n",
            "Iteration  5814 : Loss =  0.34114057  Acc:  0.88035 Val_loss =  0.45003408 Val_acc =  0.8446\n",
            "Iteration  5815 : Loss =  0.34112924  Acc:  0.8805 Val_loss =  0.45012182 Val_acc =  0.845\n",
            "Iteration  5816 : Loss =  0.34110856  Acc:  0.88011664 Val_loss =  0.45004076 Val_acc =  0.8447\n",
            "Iteration  5817 : Loss =  0.341091  Acc:  0.8804333 Val_loss =  0.450079 Val_acc =  0.8446\n",
            "Iteration  5818 : Loss =  0.34108496  Acc:  0.88045 Val_loss =  0.45007828 Val_acc =  0.8447\n",
            "Iteration  5819 : Loss =  0.34108716  Acc:  0.8802 Val_loss =  0.45006683 Val_acc =  0.8448\n",
            "Iteration  5820 : Loss =  0.34108758  Acc:  0.88046664 Val_loss =  0.450129 Val_acc =  0.8448\n",
            "Iteration  5821 : Loss =  0.3410799  Acc:  0.8800833 Val_loss =  0.45007762 Val_acc =  0.8448\n",
            "Iteration  5822 : Loss =  0.34106588  Acc:  0.8804833 Val_loss =  0.4501238 Val_acc =  0.8448\n",
            "Iteration  5823 : Loss =  0.3410535  Acc:  0.88016665 Val_loss =  0.45009628 Val_acc =  0.8446\n",
            "Iteration  5824 : Loss =  0.34104759  Acc:  0.88016665 Val_loss =  0.45010504 Val_acc =  0.8448\n",
            "Iteration  5825 : Loss =  0.34104636  Acc:  0.88046664 Val_loss =  0.45013765 Val_acc =  0.8447\n",
            "Iteration  5826 : Loss =  0.3410439  Acc:  0.88016665 Val_loss =  0.4501118 Val_acc =  0.8448\n",
            "Iteration  5827 : Loss =  0.34103647  Acc:  0.8805 Val_loss =  0.45015576 Val_acc =  0.8448\n",
            "Iteration  5828 : Loss =  0.341026  Acc:  0.88015 Val_loss =  0.45012745 Val_acc =  0.8448\n",
            "Iteration  5829 : Loss =  0.3410168  Acc:  0.88026667 Val_loss =  0.4501442 Val_acc =  0.8446\n",
            "Iteration  5830 : Loss =  0.3410112  Acc:  0.8804 Val_loss =  0.4501563 Val_acc =  0.8446\n",
            "Iteration  5831 : Loss =  0.3410078  Acc:  0.88015 Val_loss =  0.45014378 Val_acc =  0.8447\n",
            "Iteration  5832 : Loss =  0.34100336  Acc:  0.88051665 Val_loss =  0.4501824 Val_acc =  0.8448\n",
            "Iteration  5833 : Loss =  0.3409963  Acc:  0.88013333 Val_loss =  0.45015723 Val_acc =  0.8447\n",
            "Iteration  5834 : Loss =  0.34098786  Acc:  0.8803833 Val_loss =  0.45018324 Val_acc =  0.8445\n",
            "Iteration  5835 : Loss =  0.3409804  Acc:  0.8802 Val_loss =  0.4501801 Val_acc =  0.8448\n",
            "Iteration  5836 : Loss =  0.34097493  Acc:  0.88013333 Val_loss =  0.45018017 Val_acc =  0.8446\n",
            "Iteration  5837 : Loss =  0.34097037  Acc:  0.8804833 Val_loss =  0.45020726 Val_acc =  0.8446\n",
            "Iteration  5838 : Loss =  0.34096503  Acc:  0.88013333 Val_loss =  0.45018876 Val_acc =  0.8447\n",
            "Iteration  5839 : Loss =  0.34095824  Acc:  0.88046664 Val_loss =  0.45021963 Val_acc =  0.8446\n",
            "Iteration  5840 : Loss =  0.34095088  Acc:  0.88018334 Val_loss =  0.45020634 Val_acc =  0.8446\n",
            "Iteration  5841 : Loss =  0.34094417  Acc:  0.88025 Val_loss =  0.4502197 Val_acc =  0.8447\n",
            "Iteration  5842 : Loss =  0.34093854  Acc:  0.8803333 Val_loss =  0.45023033 Val_acc =  0.8444\n",
            "Iteration  5843 : Loss =  0.34093332  Acc:  0.88016665 Val_loss =  0.4502244 Val_acc =  0.8446\n",
            "Iteration  5844 : Loss =  0.34092763  Acc:  0.88045 Val_loss =  0.4502494 Val_acc =  0.8446\n",
            "Iteration  5845 : Loss =  0.34092122  Acc:  0.88016665 Val_loss =  0.4502371 Val_acc =  0.8446\n",
            "Iteration  5846 : Loss =  0.34091452  Acc:  0.88035 Val_loss =  0.4502568 Val_acc =  0.8445\n",
            "Iteration  5847 : Loss =  0.34090814  Acc:  0.88021666 Val_loss =  0.45025626 Val_acc =  0.8447\n",
            "Iteration  5848 : Loss =  0.34090236  Acc:  0.88016665 Val_loss =  0.45026168 Val_acc =  0.8448\n",
            "Iteration  5849 : Loss =  0.34089673  Acc:  0.8803333 Val_loss =  0.45027637 Val_acc =  0.8446\n",
            "Iteration  5850 : Loss =  0.3408909  Acc:  0.88018334 Val_loss =  0.4502718 Val_acc =  0.8446\n",
            "Iteration  5851 : Loss =  0.34088472  Acc:  0.88035 Val_loss =  0.45028964 Val_acc =  0.8445\n",
            "Iteration  5852 : Loss =  0.3408783  Acc:  0.88015 Val_loss =  0.450287 Val_acc =  0.8447\n",
            "Iteration  5853 : Loss =  0.34087208  Acc:  0.88023335 Val_loss =  0.45029727 Val_acc =  0.8447\n",
            "Iteration  5854 : Loss =  0.34086615  Acc:  0.88028336 Val_loss =  0.45030516 Val_acc =  0.8447\n",
            "Iteration  5855 : Loss =  0.3408604  Acc:  0.88018334 Val_loss =  0.45030606 Val_acc =  0.8447\n",
            "Iteration  5856 : Loss =  0.34085453  Acc:  0.8803667 Val_loss =  0.450321 Val_acc =  0.8446\n",
            "Iteration  5857 : Loss =  0.34084845  Acc:  0.88018334 Val_loss =  0.45031893 Val_acc =  0.8447\n",
            "Iteration  5858 : Loss =  0.34084225  Acc:  0.88028336 Val_loss =  0.4503317 Val_acc =  0.8445\n",
            "Iteration  5859 : Loss =  0.3408361  Acc:  0.88025 Val_loss =  0.45033514 Val_acc =  0.8448\n",
            "Iteration  5860 : Loss =  0.34083015  Acc:  0.88021666 Val_loss =  0.45034042 Val_acc =  0.8447\n",
            "Iteration  5861 : Loss =  0.34082425  Acc:  0.8803167 Val_loss =  0.45035186 Val_acc =  0.8445\n",
            "Iteration  5862 : Loss =  0.34081832  Acc:  0.8802 Val_loss =  0.45035148 Val_acc =  0.8446\n",
            "Iteration  5863 : Loss =  0.34081233  Acc:  0.88035 Val_loss =  0.45036557 Val_acc =  0.8445\n",
            "Iteration  5864 : Loss =  0.34080625  Acc:  0.88021666 Val_loss =  0.45036557 Val_acc =  0.8447\n",
            "Iteration  5865 : Loss =  0.3408002  Acc:  0.88028336 Val_loss =  0.45037618 Val_acc =  0.8447\n",
            "Iteration  5866 : Loss =  0.34079418  Acc:  0.88028336 Val_loss =  0.45038155 Val_acc =  0.8448\n",
            "Iteration  5867 : Loss =  0.34078822  Acc:  0.88023335 Val_loss =  0.4503863 Val_acc =  0.8448\n",
            "Iteration  5868 : Loss =  0.34078228  Acc:  0.8803333 Val_loss =  0.45039693 Val_acc =  0.8446\n",
            "Iteration  5869 : Loss =  0.34077632  Acc:  0.88021666 Val_loss =  0.4503983 Val_acc =  0.8448\n",
            "Iteration  5870 : Loss =  0.3407703  Acc:  0.8803 Val_loss =  0.45040992 Val_acc =  0.8446\n",
            "Iteration  5871 : Loss =  0.34076428  Acc:  0.88028336 Val_loss =  0.45041236 Val_acc =  0.8448\n",
            "Iteration  5872 : Loss =  0.3407583  Acc:  0.8803167 Val_loss =  0.45042115 Val_acc =  0.8447\n",
            "Iteration  5873 : Loss =  0.34075227  Acc:  0.88035 Val_loss =  0.45042744 Val_acc =  0.8448\n",
            "Iteration  5874 : Loss =  0.34074634  Acc:  0.8803 Val_loss =  0.4504325 Val_acc =  0.8449\n",
            "Iteration  5875 : Loss =  0.34074044  Acc:  0.8803667 Val_loss =  0.4504418 Val_acc =  0.8447\n",
            "Iteration  5876 : Loss =  0.34073445  Acc:  0.8803 Val_loss =  0.45044526 Val_acc =  0.8449\n",
            "Iteration  5877 : Loss =  0.34072846  Acc:  0.8803667 Val_loss =  0.45045453 Val_acc =  0.8448\n",
            "Iteration  5878 : Loss =  0.34072244  Acc:  0.8803167 Val_loss =  0.45045936 Val_acc =  0.8449\n",
            "Iteration  5879 : Loss =  0.34071648  Acc:  0.8803333 Val_loss =  0.4504663 Val_acc =  0.8448\n",
            "Iteration  5880 : Loss =  0.34071052  Acc:  0.88035 Val_loss =  0.45047382 Val_acc =  0.8448\n",
            "Iteration  5881 : Loss =  0.34070456  Acc:  0.8803167 Val_loss =  0.45047832 Val_acc =  0.8449\n",
            "Iteration  5882 : Loss =  0.34069857  Acc:  0.8803667 Val_loss =  0.45048758 Val_acc =  0.8448\n",
            "Iteration  5883 : Loss =  0.3406926  Acc:  0.8803167 Val_loss =  0.45049137 Val_acc =  0.8449\n",
            "Iteration  5884 : Loss =  0.34068665  Acc:  0.8803667 Val_loss =  0.45050034 Val_acc =  0.8448\n",
            "Iteration  5885 : Loss =  0.34068066  Acc:  0.8803333 Val_loss =  0.4505053 Val_acc =  0.8448\n",
            "Iteration  5886 : Loss =  0.34067467  Acc:  0.8803667 Val_loss =  0.4505125 Val_acc =  0.8448\n",
            "Iteration  5887 : Loss =  0.34066874  Acc:  0.8803667 Val_loss =  0.45051944 Val_acc =  0.8448\n",
            "Iteration  5888 : Loss =  0.3406628  Acc:  0.8803833 Val_loss =  0.4505248 Val_acc =  0.8448\n",
            "Iteration  5889 : Loss =  0.34065685  Acc:  0.8803833 Val_loss =  0.45053306 Val_acc =  0.8448\n",
            "Iteration  5890 : Loss =  0.3406509  Acc:  0.8803833 Val_loss =  0.4505379 Val_acc =  0.8448\n",
            "Iteration  5891 : Loss =  0.34064493  Acc:  0.8803833 Val_loss =  0.45054606 Val_acc =  0.8448\n",
            "Iteration  5892 : Loss =  0.34063894  Acc:  0.8803833 Val_loss =  0.45055145 Val_acc =  0.8448\n",
            "Iteration  5893 : Loss =  0.34063298  Acc:  0.8804 Val_loss =  0.4505586 Val_acc =  0.8448\n",
            "Iteration  5894 : Loss =  0.340627  Acc:  0.8804 Val_loss =  0.45056528 Val_acc =  0.8448\n",
            "Iteration  5895 : Loss =  0.34062108  Acc:  0.8804 Val_loss =  0.45057118 Val_acc =  0.8448\n",
            "Iteration  5896 : Loss =  0.3406151  Acc:  0.8803833 Val_loss =  0.4505788 Val_acc =  0.8448\n",
            "Iteration  5897 : Loss =  0.3406092  Acc:  0.8804 Val_loss =  0.45058426 Val_acc =  0.8448\n",
            "Iteration  5898 : Loss =  0.34060326  Acc:  0.8804 Val_loss =  0.4505919 Val_acc =  0.8448\n",
            "Iteration  5899 : Loss =  0.34059727  Acc:  0.8804 Val_loss =  0.4505977 Val_acc =  0.8448\n",
            "Iteration  5900 : Loss =  0.34059134  Acc:  0.8804167 Val_loss =  0.45060468 Val_acc =  0.8448\n",
            "Iteration  5901 : Loss =  0.3405854  Acc:  0.8804167 Val_loss =  0.4506114 Val_acc =  0.8448\n",
            "Iteration  5902 : Loss =  0.34057942  Acc:  0.8804167 Val_loss =  0.4506175 Val_acc =  0.8448\n",
            "Iteration  5903 : Loss =  0.3405735  Acc:  0.88045 Val_loss =  0.4506249 Val_acc =  0.8448\n",
            "Iteration  5904 : Loss =  0.34056756  Acc:  0.8804167 Val_loss =  0.45063052 Val_acc =  0.8448\n",
            "Iteration  5905 : Loss =  0.34056163  Acc:  0.88045 Val_loss =  0.45063823 Val_acc =  0.8448\n",
            "Iteration  5906 : Loss =  0.34055567  Acc:  0.8804167 Val_loss =  0.45064375 Val_acc =  0.8448\n",
            "Iteration  5907 : Loss =  0.34054974  Acc:  0.88045 Val_loss =  0.45065126 Val_acc =  0.8448\n",
            "Iteration  5908 : Loss =  0.3405438  Acc:  0.8804333 Val_loss =  0.45065722 Val_acc =  0.8448\n",
            "Iteration  5909 : Loss =  0.34053785  Acc:  0.88045 Val_loss =  0.4506643 Val_acc =  0.8448\n",
            "Iteration  5910 : Loss =  0.34053192  Acc:  0.8804333 Val_loss =  0.4506706 Val_acc =  0.8447\n",
            "Iteration  5911 : Loss =  0.34052598  Acc:  0.88045 Val_loss =  0.45067745 Val_acc =  0.8447\n",
            "Iteration  5912 : Loss =  0.34052005  Acc:  0.8804333 Val_loss =  0.4506839 Val_acc =  0.8447\n",
            "Iteration  5913 : Loss =  0.34051412  Acc:  0.88046664 Val_loss =  0.45069078 Val_acc =  0.8447\n",
            "Iteration  5914 : Loss =  0.3405082  Acc:  0.88045 Val_loss =  0.4506969 Val_acc =  0.8447\n",
            "Iteration  5915 : Loss =  0.3405023  Acc:  0.88046664 Val_loss =  0.45070434 Val_acc =  0.8447\n",
            "Iteration  5916 : Loss =  0.34049633  Acc:  0.88046664 Val_loss =  0.45070976 Val_acc =  0.8447\n",
            "Iteration  5917 : Loss =  0.34049046  Acc:  0.88045 Val_loss =  0.45071808 Val_acc =  0.8446\n",
            "Iteration  5918 : Loss =  0.34048453  Acc:  0.8805 Val_loss =  0.45072252 Val_acc =  0.8447\n",
            "Iteration  5919 : Loss =  0.34047866  Acc:  0.88046664 Val_loss =  0.45073193 Val_acc =  0.8448\n",
            "Iteration  5920 : Loss =  0.34047276  Acc:  0.88046664 Val_loss =  0.45073524 Val_acc =  0.8447\n",
            "Iteration  5921 : Loss =  0.3404669  Acc:  0.88045 Val_loss =  0.45074606 Val_acc =  0.8448\n",
            "Iteration  5922 : Loss =  0.34046108  Acc:  0.88045 Val_loss =  0.45074785 Val_acc =  0.8447\n",
            "Iteration  5923 : Loss =  0.34045526  Acc:  0.8804167 Val_loss =  0.45076048 Val_acc =  0.8448\n",
            "Iteration  5924 : Loss =  0.34044954  Acc:  0.8805 Val_loss =  0.4507603 Val_acc =  0.8447\n",
            "Iteration  5925 : Loss =  0.34044397  Acc:  0.8804333 Val_loss =  0.4507759 Val_acc =  0.8448\n",
            "Iteration  5926 : Loss =  0.3404386  Acc:  0.8804167 Val_loss =  0.45077252 Val_acc =  0.8448\n",
            "Iteration  5927 : Loss =  0.34043348  Acc:  0.8805 Val_loss =  0.45079297 Val_acc =  0.8448\n",
            "Iteration  5928 : Loss =  0.34042886  Acc:  0.88046664 Val_loss =  0.45078477 Val_acc =  0.845\n",
            "Iteration  5929 : Loss =  0.34042493  Acc:  0.8805 Val_loss =  0.45081368 Val_acc =  0.8448\n",
            "Iteration  5930 : Loss =  0.34042212  Acc:  0.8804333 Val_loss =  0.45079824 Val_acc =  0.8445\n",
            "Iteration  5931 : Loss =  0.34042096  Acc:  0.88055 Val_loss =  0.45084137 Val_acc =  0.8447\n",
            "Iteration  5932 : Loss =  0.3404224  Acc:  0.88058335 Val_loss =  0.45081615 Val_acc =  0.8445\n",
            "Iteration  5933 : Loss =  0.34042656  Acc:  0.88046664 Val_loss =  0.45088163 Val_acc =  0.8447\n",
            "Iteration  5934 : Loss =  0.340435  Acc:  0.8804333 Val_loss =  0.45084405 Val_acc =  0.8449\n",
            "Iteration  5935 : Loss =  0.34044433  Acc:  0.8804167 Val_loss =  0.45093614 Val_acc =  0.8449\n",
            "Iteration  5936 : Loss =  0.3404544  Acc:  0.8805 Val_loss =  0.4508796 Val_acc =  0.8451\n",
            "Iteration  5937 : Loss =  0.34045273  Acc:  0.8804333 Val_loss =  0.45097646 Val_acc =  0.8449\n",
            "Iteration  5938 : Loss =  0.34043908  Acc:  0.8805 Val_loss =  0.45088965 Val_acc =  0.845\n",
            "Iteration  5939 : Loss =  0.3404074  Acc:  0.88045 Val_loss =  0.45094648 Val_acc =  0.8448\n",
            "Iteration  5940 : Loss =  0.34037358  Acc:  0.88056666 Val_loss =  0.45086592 Val_acc =  0.8447\n",
            "Iteration  5941 : Loss =  0.3403506  Acc:  0.8804833 Val_loss =  0.45088896 Val_acc =  0.8447\n",
            "Iteration  5942 : Loss =  0.34034583  Acc:  0.88045 Val_loss =  0.45089033 Val_acc =  0.8446\n",
            "Iteration  5943 : Loss =  0.34035352  Acc:  0.88046664 Val_loss =  0.4508916 Val_acc =  0.8446\n",
            "Iteration  5944 : Loss =  0.34036034  Acc:  0.8805 Val_loss =  0.45095 Val_acc =  0.8448\n",
            "Iteration  5945 : Loss =  0.3403571  Acc:  0.8804833 Val_loss =  0.45091006 Val_acc =  0.8447\n",
            "Iteration  5946 : Loss =  0.34034088  Acc:  0.8804833 Val_loss =  0.45095548 Val_acc =  0.8446\n",
            "Iteration  5947 : Loss =  0.34032136  Acc:  0.8804167 Val_loss =  0.45090824 Val_acc =  0.8447\n",
            "Iteration  5948 : Loss =  0.34030825  Acc:  0.88056666 Val_loss =  0.45093164 Val_acc =  0.8448\n",
            "Iteration  5949 : Loss =  0.3403051  Acc:  0.8804167 Val_loss =  0.4509356 Val_acc =  0.8446\n",
            "Iteration  5950 : Loss =  0.34030703  Acc:  0.8805 Val_loss =  0.45093888 Val_acc =  0.8446\n",
            "Iteration  5951 : Loss =  0.34030572  Acc:  0.88053334 Val_loss =  0.450974 Val_acc =  0.8447\n",
            "Iteration  5952 : Loss =  0.34029767  Acc:  0.88053334 Val_loss =  0.45094952 Val_acc =  0.8447\n",
            "Iteration  5953 : Loss =  0.34028473  Acc:  0.8804833 Val_loss =  0.45097554 Val_acc =  0.8447\n",
            "Iteration  5954 : Loss =  0.34027338  Acc:  0.8803833 Val_loss =  0.45095763 Val_acc =  0.8448\n",
            "Iteration  5955 : Loss =  0.34026733  Acc:  0.88051665 Val_loss =  0.45097226 Val_acc =  0.8448\n",
            "Iteration  5956 : Loss =  0.34026527  Acc:  0.8803833 Val_loss =  0.45098516 Val_acc =  0.8446\n",
            "Iteration  5957 : Loss =  0.34026286  Acc:  0.88051665 Val_loss =  0.45098448 Val_acc =  0.8448\n",
            "Iteration  5958 : Loss =  0.34025678  Acc:  0.8803833 Val_loss =  0.45100567 Val_acc =  0.8447\n",
            "Iteration  5959 : Loss =  0.34024757  Acc:  0.8805 Val_loss =  0.4509945 Val_acc =  0.8447\n",
            "Iteration  5960 : Loss =  0.34023827  Acc:  0.88045 Val_loss =  0.45100734 Val_acc =  0.8447\n",
            "Iteration  5961 : Loss =  0.34023148  Acc:  0.88045 Val_loss =  0.45100957 Val_acc =  0.8447\n",
            "Iteration  5962 : Loss =  0.34022728  Acc:  0.88051665 Val_loss =  0.4510149 Val_acc =  0.8446\n",
            "Iteration  5963 : Loss =  0.34022358  Acc:  0.8804333 Val_loss =  0.4510316 Val_acc =  0.8446\n",
            "Iteration  5964 : Loss =  0.34021828  Acc:  0.8804833 Val_loss =  0.4510288 Val_acc =  0.8447\n",
            "Iteration  5965 : Loss =  0.340211  Acc:  0.88046664 Val_loss =  0.45104283 Val_acc =  0.8446\n",
            "Iteration  5966 : Loss =  0.3402032  Acc:  0.88055 Val_loss =  0.4510423 Val_acc =  0.8446\n",
            "Iteration  5967 : Loss =  0.3401964  Acc:  0.8804333 Val_loss =  0.4510479 Val_acc =  0.8448\n",
            "Iteration  5968 : Loss =  0.34019104  Acc:  0.8805 Val_loss =  0.45105997 Val_acc =  0.8445\n",
            "Iteration  5969 : Loss =  0.3401864  Acc:  0.8804833 Val_loss =  0.45105907 Val_acc =  0.8449\n",
            "Iteration  5970 : Loss =  0.3401811  Acc:  0.88051665 Val_loss =  0.45107657 Val_acc =  0.8447\n",
            "Iteration  5971 : Loss =  0.34017488  Acc:  0.8805 Val_loss =  0.4510735 Val_acc =  0.8448\n",
            "Iteration  5972 : Loss =  0.34016803  Acc:  0.8804 Val_loss =  0.4510852 Val_acc =  0.8446\n",
            "Iteration  5973 : Loss =  0.3401615  Acc:  0.88055 Val_loss =  0.4510896 Val_acc =  0.8448\n",
            "Iteration  5974 : Loss =  0.34015563  Acc:  0.88045 Val_loss =  0.45109296 Val_acc =  0.8448\n",
            "Iteration  5975 : Loss =  0.34015033  Acc:  0.8805 Val_loss =  0.45110747 Val_acc =  0.8445\n",
            "Iteration  5976 : Loss =  0.340145  Acc:  0.8805 Val_loss =  0.45110497 Val_acc =  0.8448\n",
            "Iteration  5977 : Loss =  0.34013915  Acc:  0.88051665 Val_loss =  0.45112178 Val_acc =  0.8445\n",
            "Iteration  5978 : Loss =  0.3401329  Acc:  0.88051665 Val_loss =  0.45111954 Val_acc =  0.8448\n",
            "Iteration  5979 : Loss =  0.34012657  Acc:  0.8804833 Val_loss =  0.45113102 Val_acc =  0.8446\n",
            "Iteration  5980 : Loss =  0.34012055  Acc:  0.8805 Val_loss =  0.45113608 Val_acc =  0.8447\n",
            "Iteration  5981 : Loss =  0.34011492  Acc:  0.8804833 Val_loss =  0.45114052 Val_acc =  0.8449\n",
            "Iteration  5982 : Loss =  0.34010935  Acc:  0.88046664 Val_loss =  0.45115292 Val_acc =  0.8445\n",
            "Iteration  5983 : Loss =  0.34010372  Acc:  0.88051665 Val_loss =  0.45115253 Val_acc =  0.8449\n",
            "Iteration  5984 : Loss =  0.34009778  Acc:  0.8804833 Val_loss =  0.4511666 Val_acc =  0.8445\n",
            "Iteration  5985 : Loss =  0.3400917  Acc:  0.8805 Val_loss =  0.45116654 Val_acc =  0.8449\n",
            "Iteration  5986 : Loss =  0.3400857  Acc:  0.88055 Val_loss =  0.45117745 Val_acc =  0.8445\n",
            "Iteration  5987 : Loss =  0.3400798  Acc:  0.8804833 Val_loss =  0.45118213 Val_acc =  0.8446\n",
            "Iteration  5988 : Loss =  0.34007415  Acc:  0.88053334 Val_loss =  0.45118842 Val_acc =  0.8448\n",
            "Iteration  5989 : Loss =  0.34006843  Acc:  0.88046664 Val_loss =  0.45119774 Val_acc =  0.8446\n",
            "Iteration  5990 : Loss =  0.3400627  Acc:  0.88055 Val_loss =  0.45120078 Val_acc =  0.8448\n",
            "Iteration  5991 : Loss =  0.34005678  Acc:  0.88051665 Val_loss =  0.45121133 Val_acc =  0.8446\n",
            "Iteration  5992 : Loss =  0.34005085  Acc:  0.88051665 Val_loss =  0.4512145 Val_acc =  0.8449\n",
            "Iteration  5993 : Loss =  0.34004495  Acc:  0.88055 Val_loss =  0.45122343 Val_acc =  0.8445\n",
            "Iteration  5994 : Loss =  0.34003913  Acc:  0.88053334 Val_loss =  0.4512291 Val_acc =  0.8447\n",
            "Iteration  5995 : Loss =  0.3400334  Acc:  0.88055 Val_loss =  0.45123565 Val_acc =  0.8447\n",
            "Iteration  5996 : Loss =  0.34002766  Acc:  0.8805 Val_loss =  0.45124355 Val_acc =  0.8446\n",
            "Iteration  5997 : Loss =  0.34002188  Acc:  0.88051665 Val_loss =  0.4512486 Val_acc =  0.8448\n",
            "Iteration  5998 : Loss =  0.340016  Acc:  0.88051665 Val_loss =  0.45125693 Val_acc =  0.8446\n",
            "Iteration  5999 : Loss =  0.34001017  Acc:  0.88053334 Val_loss =  0.45126235 Val_acc =  0.8448\n",
            "\n",
            "The final test accuracy of the Fashion MNIST dataset is 0.8446999788284302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2YT2PDOvWW5",
        "colab_type": "text"
      },
      "source": [
        "### Plot of Training accuracy, Training loss, Test Accuracy, Test Loss against the number of Iterations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZBD3jj7vYcr",
        "colab_type": "code",
        "outputId": "f75a3374-4489-4b04-8ecb-b6dd496b9367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "plt.plot(test_loss, label=\"Val Loss\")\n",
        "plt.plot(test_acc, label=\"Val Acc\")\n",
        "plt.plot(training_loss, label=\"Train Loss\")\n",
        "plt.plot(training_acc, label=\"Train Acc\")\n",
        "plt.title(\"Number of Iterations vs Training/Validation Loss and Accuracy\")\n",
        "plt.xlabel(\"Number of Iterations\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Print the test accuracy \n",
        "print()\n",
        "print(\"The final test accuracy of the Fashion MNIST dataset is {}\".format(final_test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The final test accuracy of the Fashion MNIST dataset is 0.8446999788284302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYWJLaCRdUGt",
        "colab_type": "text"
      },
      "source": [
        "### Plot of number of iterations and the test set accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVY69ijzdbJ9",
        "colab_type": "code",
        "outputId": "e15a8f59-c4e9-40ab-b83a-b55b4e59d51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "iterations= [100, 150, 200, 300, 400, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000]\n",
        "acc_test= [0.765999972820282, 0.7857999801635742, 0.8011000156402588, 0.8154000043869019, 0.8216999769210815, 0.8258000016212463, 0.8393999934196472, 0.8425999879837036, 0.8445000052452087, 0.8472999930381775, 0.8483999967575073, 0.8461999893188477, 0.8460000157356262, 0.84579998254776, 0.8449000120162964, 0.843999981880188, 0.843500018119812]\n",
        "plt.plot(iterations, acc_test)\n",
        "plt.xlabel(\"Number of Iterations\")\n",
        "plt.ylabel(\"Test Set Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRJL6/wWm2Gfs99nVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HftXujzcFfAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}